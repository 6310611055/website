{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>afftype</th>\n",
       "      <th>melanch</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>edu</th>\n",
       "      <th>marriage</th>\n",
       "      <th>work</th>\n",
       "      <th>madrs1</th>\n",
       "      <th>5days_sleep_time_activity</th>\n",
       "      <th>5days_day_time_activity</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>10693.6</td>\n",
       "      <td>228824.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>48771.2</td>\n",
       "      <td>239278.2</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>43211.0</td>\n",
       "      <td>317726.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>56892.4</td>\n",
       "      <td>194298.2</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>31303.8</td>\n",
       "      <td>200302.2</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>26634.2</td>\n",
       "      <td>240767.8</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>61643.6</td>\n",
       "      <td>335598.2</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>34374.2</td>\n",
       "      <td>284320.6</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>42992.0</td>\n",
       "      <td>203120.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>25811.0</td>\n",
       "      <td>482765.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>50147.0</td>\n",
       "      <td>153494.6</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>34576.6</td>\n",
       "      <td>228420.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>62330.8</td>\n",
       "      <td>291661.6</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>42878.0</td>\n",
       "      <td>72237.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>42016.2</td>\n",
       "      <td>164387.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>17938.8</td>\n",
       "      <td>397321.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>24344.6</td>\n",
       "      <td>85835.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>40038.4</td>\n",
       "      <td>64142.0</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>189703.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>10301.8</td>\n",
       "      <td>84496.8</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>91568.8</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>18023.6</td>\n",
       "      <td>183974.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>29581.2</td>\n",
       "      <td>235831.4</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>62703.4</td>\n",
       "      <td>257546.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>51929.0</td>\n",
       "      <td>475113.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34742.8</td>\n",
       "      <td>347817.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23481.0</td>\n",
       "      <td>255676.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>49904.8</td>\n",
       "      <td>398723.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>103205.0</td>\n",
       "      <td>431101.8</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>115329.4</td>\n",
       "      <td>479807.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124525.0</td>\n",
       "      <td>467588.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19149.8</td>\n",
       "      <td>169119.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>35635.0</td>\n",
       "      <td>293293.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>37543.8</td>\n",
       "      <td>233625.8</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30825.2</td>\n",
       "      <td>227922.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28298.2</td>\n",
       "      <td>246814.8</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>97899.4</td>\n",
       "      <td>471340.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>64710.4</td>\n",
       "      <td>373257.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50966.2</td>\n",
       "      <td>343819.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>54870.4</td>\n",
       "      <td>304521.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>54821.6</td>\n",
       "      <td>327886.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>79226.0</td>\n",
       "      <td>233218.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>62504.0</td>\n",
       "      <td>480728.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>129507.8</td>\n",
       "      <td>260240.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41799.6</td>\n",
       "      <td>326000.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43280.4</td>\n",
       "      <td>249467.8</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65133.6</td>\n",
       "      <td>584654.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>67783.8</td>\n",
       "      <td>462165.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>111668.2</td>\n",
       "      <td>464377.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>84647.2</td>\n",
       "      <td>331799.6</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>96948.4</td>\n",
       "      <td>343388.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60045.6</td>\n",
       "      <td>327889.8</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45442.2</td>\n",
       "      <td>284416.2</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60903.2</td>\n",
       "      <td>392232.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>47928.8</td>\n",
       "      <td>151957.4</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  age  afftype  melanch  inpatient  edu  marriage  work  madrs1  \\\n",
       "0        2   37        2        2          2    8         1     2      19   \n",
       "1        2   42        1        2          2    8         2     2      24   \n",
       "2        1   47        2        2          2    8         2     2      24   \n",
       "3        2   27        2        2          2   13         1     1      20   \n",
       "4        2   52        2        2          2   13         2     2      26   \n",
       "5        1   37        2        2          2    8         1     2      18   \n",
       "6        1   22        1        2          2   13         2     1      24   \n",
       "7        2   27        2        2          2   13         1     2      20   \n",
       "8        2   47        1        2          2    8         1     2      26   \n",
       "9        2   47        2        2          2    8         1     2      28   \n",
       "10       1   47        2        2          2    8         1     2      24   \n",
       "11       2   42        1        2          2    8         2     2      25   \n",
       "12       2   37        1        2          2   13         2     2      18   \n",
       "13       1   62        1        2          2    8         2     2      28   \n",
       "14       2   57        2        2          2   13         1     1      14   \n",
       "15       1   47        2        2          2   13         1     2      13   \n",
       "16       1   52        1        2          2    8         1     2      17   \n",
       "17       2   42        3        2          2   13         2     2      18   \n",
       "18       2   52        2        2          1   18         2     2      26   \n",
       "19       1   32        2        1          1    8         1     2      27   \n",
       "20       2   37        2        2          1    8         2     2      26   \n",
       "21       1   67        2        2          1    8         2     2      29   \n",
       "22       1   32        2        2          1   18         2     2      29   \n",
       "23       2   27        0        2          0   13         2     1       4   \n",
       "24       1   32        0        2          0    8         1     1       4   \n",
       "25       2   32        0        2          0   18         1     1       4   \n",
       "26       1   27        0        2          0   18         2     2       4   \n",
       "27       1   32        0        2          0    8         1     1       4   \n",
       "28       1   27        0        2          0   13         2     1       9   \n",
       "29       1   22        0        2          0   13         2     1       4   \n",
       "30       2   42        0        2          0   18         1     1       4   \n",
       "31       2   32        0        2          0   18         1     1       4   \n",
       "32       1   32        0        2          0    8         1     1       4   \n",
       "33       1   47        0        2          0    8         1     1       4   \n",
       "34       1   62        0        2          0   13         1     1       4   \n",
       "35       1   52        0        2          0    8         1     1       4   \n",
       "36       1   52        0        2          0    8         1     1       4   \n",
       "37       1   47        0        2          0    8         1     1       4   \n",
       "38       2   42        0        2          0   18         1     1       4   \n",
       "39       1   47        0        2          0    8         1     1       4   \n",
       "40       2   22        0        2          0   13         2     1       4   \n",
       "41       1   52        0        2          0    8         1     1       4   \n",
       "42       1   37        0        2          0    8         1     1       9   \n",
       "43       1   52        0        2          0    8         1     1       4   \n",
       "44       1   27        0        2          0   18         1     1       4   \n",
       "45       1   22        0        2          0   13         2     1       4   \n",
       "46       2   22        0        2          0    8         2     1       4   \n",
       "47       1   67        0        2          0   13         1     1       4   \n",
       "48       1   37        0        2          0    8         1     1       4   \n",
       "49       2   52        0        2          0    8         2     1       4   \n",
       "50       2   47        0        2          0    8         2     1       4   \n",
       "51       2   52        0        2          0   13         2     1       4   \n",
       "52       2   37        0        2          0    8         1     1       4   \n",
       "53       1   22        2        2          0    8         2     1       4   \n",
       "54       2   27        0        2          0   13         2     1       4   \n",
       "\n",
       "    5days_sleep_time_activity  5days_day_time_activity         Id  \n",
       "0                     10693.6                 228824.0  condition  \n",
       "1                     48771.2                 239278.2  condition  \n",
       "2                     43211.0                 317726.0  condition  \n",
       "3                     56892.4                 194298.2  condition  \n",
       "4                     31303.8                 200302.2  condition  \n",
       "5                     26634.2                 240767.8  condition  \n",
       "6                     61643.6                 335598.2  condition  \n",
       "7                     34374.2                 284320.6  condition  \n",
       "8                     42992.0                 203120.0  condition  \n",
       "9                     25811.0                 482765.0  condition  \n",
       "10                    50147.0                 153494.6  condition  \n",
       "11                    34576.6                 228420.4  condition  \n",
       "12                    62330.8                 291661.6  condition  \n",
       "13                    42878.0                  72237.4  condition  \n",
       "14                    42016.2                 164387.4  condition  \n",
       "15                    17938.8                 397321.0  condition  \n",
       "16                    24344.6                  85835.4  condition  \n",
       "17                    40038.4                  64142.0  condition  \n",
       "18                    17014.0                 189703.4  condition  \n",
       "19                    10301.8                  84496.8  condition  \n",
       "20                     4627.0                  91568.8  condition  \n",
       "21                    18023.6                 183974.4  condition  \n",
       "22                    29581.2                 235831.4  condition  \n",
       "23                    62703.4                 257546.4    control  \n",
       "24                    51929.0                 475113.4    control  \n",
       "25                    34742.8                 347817.0    control  \n",
       "26                    23481.0                 255676.4    control  \n",
       "27                    49904.8                 398723.0    control  \n",
       "28                   103205.0                 431101.8    control  \n",
       "29                   115329.4                 479807.0    control  \n",
       "30                   124525.0                 467588.6    control  \n",
       "31                    19149.8                 169119.2    control  \n",
       "32                    35635.0                 293293.2    control  \n",
       "33                    37543.8                 233625.8    control  \n",
       "34                    30825.2                 227922.0    control  \n",
       "35                    28298.2                 246814.8    control  \n",
       "36                    97899.4                 471340.6    control  \n",
       "37                    64710.4                 373257.6    control  \n",
       "38                    50966.2                 343819.2    control  \n",
       "39                    54870.4                 304521.0    control  \n",
       "40                    54821.6                 327886.0    control  \n",
       "41                    79226.0                 233218.6    control  \n",
       "42                    62504.0                 480728.2    control  \n",
       "43                   129507.8                 260240.4    control  \n",
       "44                    41799.6                 326000.6    control  \n",
       "45                    43280.4                 249467.8    control  \n",
       "46                    65133.6                 584654.0    control  \n",
       "47                    67783.8                 462165.4    control  \n",
       "48                   111668.2                 464377.6    control  \n",
       "49                    84647.2                 331799.6    control  \n",
       "50                    96948.4                 343388.2    control  \n",
       "51                    60045.6                 327889.8    control  \n",
       "52                    45442.2                 284416.2    control  \n",
       "53                    60903.2                 392232.0    control  \n",
       "54                    47928.8                 151957.4    control  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.read_csv(\n",
    "    \"../Dataset/dataset_filled_missing.csv\")\n",
    "ml_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "ml_df['Id'] = ['condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'condition', 'control', 'control',\n",
    "               'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'control']\n",
    "ml_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select: 55 set\n",
      "[[1.069360e+04 2.288240e+05 3.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.900000e+01\n",
      "  1.000000e+00]\n",
      " [4.877120e+04 2.392782e+05 4.200000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.400000e+01\n",
      "  2.000000e+00]\n",
      " [4.321100e+04 3.177260e+05 4.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.400000e+01\n",
      "  2.000000e+00]\n",
      " [5.689240e+04 1.942982e+05 2.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 2.000000e+01\n",
      "  1.000000e+00]\n",
      " [3.130380e+04 2.003022e+05 5.200000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 2.600000e+01\n",
      "  2.000000e+00]\n",
      " [2.663420e+04 2.407678e+05 3.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.800000e+01\n",
      "  1.000000e+00]\n",
      " [6.164360e+04 3.355982e+05 2.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 2.400000e+01\n",
      "  2.000000e+00]\n",
      " [3.437420e+04 2.843206e+05 2.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 2.000000e+01\n",
      "  1.000000e+00]\n",
      " [4.299200e+04 2.031200e+05 4.700000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.600000e+01\n",
      "  1.000000e+00]\n",
      " [2.581100e+04 4.827650e+05 4.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.800000e+01\n",
      "  1.000000e+00]\n",
      " [5.014700e+04 1.534946e+05 4.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.400000e+01\n",
      "  1.000000e+00]\n",
      " [3.457660e+04 2.284204e+05 4.200000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.500000e+01\n",
      "  2.000000e+00]\n",
      " [6.233080e+04 2.916616e+05 3.700000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.800000e+01\n",
      "  2.000000e+00]\n",
      " [4.287800e+04 7.223740e+04 6.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.800000e+01\n",
      "  2.000000e+00]\n",
      " [4.201620e+04 1.643874e+05 5.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 1.400000e+01\n",
      "  1.000000e+00]\n",
      " [1.793880e+04 3.973210e+05 4.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.300000e+01\n",
      "  1.000000e+00]\n",
      " [2.434460e+04 8.583540e+04 5.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.700000e+01\n",
      "  1.000000e+00]\n",
      " [4.003840e+04 6.414200e+04 4.200000e+01 2.000000e+00 3.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.800000e+01\n",
      "  2.000000e+00]\n",
      " [1.701400e+04 1.897034e+05 5.200000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 1.800000e+01 2.000000e+00 2.600000e+01\n",
      "  2.000000e+00]\n",
      " [1.030180e+04 8.449680e+04 3.200000e+01 1.000000e+00 2.000000e+00\n",
      "  1.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.700000e+01\n",
      "  1.000000e+00]\n",
      " [4.627000e+03 9.156880e+04 3.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.600000e+01\n",
      "  2.000000e+00]\n",
      " [1.802360e+04 1.839744e+05 6.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.900000e+01\n",
      "  2.000000e+00]\n",
      " [2.958120e+04 2.358314e+05 3.200000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 1.800000e+01 2.000000e+00 2.900000e+01\n",
      "  2.000000e+00]\n",
      " [6.270340e+04 2.575464e+05 2.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [5.192900e+04 4.751134e+05 3.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.474280e+04 3.478170e+05 3.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [2.348100e+04 2.556764e+05 2.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 2.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [4.990480e+04 3.987230e+05 3.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.032050e+05 4.311018e+05 2.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 9.000000e+00\n",
      "  2.000000e+00]\n",
      " [1.153294e+05 4.798070e+05 2.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [1.245250e+05 4.675886e+05 4.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.914980e+04 1.691192e+05 3.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.563500e+04 2.932932e+05 3.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.754380e+04 2.336258e+05 4.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.082520e+04 2.279220e+05 6.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [2.829820e+04 2.468148e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [9.789940e+04 4.713406e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.471040e+04 3.732576e+05 4.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [5.096620e+04 3.438192e+05 4.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [5.487040e+04 3.045210e+05 4.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [5.482160e+04 3.278860e+05 2.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [7.922600e+04 2.332186e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.250400e+04 4.807282e+05 3.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 9.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.295078e+05 2.602404e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.179960e+04 3.260006e+05 2.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.328040e+04 2.494678e+05 2.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [6.513360e+04 5.846540e+05 2.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [6.778380e+04 4.621654e+05 6.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.116682e+05 4.643776e+05 3.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [8.464720e+04 3.317996e+05 5.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [9.694840e+04 3.433882e+05 4.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [6.004560e+04 3.278898e+05 5.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [4.544220e+04 2.844162e+05 3.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.090320e+04 3.922320e+05 2.200000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [4.792880e+04 1.519574e+05 2.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "count = 0\n",
    "count_g = 0\n",
    "count_o = 0\n",
    "\n",
    "for i in range(len(ml_df[\"Id\"])):\n",
    "\n",
    "    if ml_df[\"Id\"][i] == \"condition\":\n",
    "        x.append(1)\n",
    "        y.append([ml_df[\"5days_sleep_time_activity\"][i],\n",
    "                  ml_df[\"5days_day_time_activity\"][i], ml_df[\"age\"][i], ml_df[\"gender\"][i], ml_df[\"afftype\"][i],\n",
    "                  ml_df[\"melanch\"][i], ml_df[\"inpatient\"][i], ml_df[\"edu\"][i], ml_df[\"work\"][i], ml_df[\"madrs1\"][i], ml_df[\"marriage\"][i]])\n",
    "\n",
    "    elif ml_df[\"Id\"][i] == \"control\":\n",
    "        x.append(0)\n",
    "        y.append([ml_df[\"5days_sleep_time_activity\"][i],\n",
    "                  ml_df[\"5days_day_time_activity\"][i], ml_df[\"age\"][i], ml_df[\"gender\"][i], ml_df[\"afftype\"][i],\n",
    "                  ml_df[\"melanch\"][i], ml_df[\"inpatient\"][i], ml_df[\"edu\"][i], ml_df[\"work\"][i], ml_df[\"madrs1\"][i], ml_df[\"marriage\"][i]])\n",
    "\n",
    "\n",
    "print(f'Select: {len(y)} set')\n",
    "y = np.array(y)\n",
    "x = np.array(x)\n",
    "\n",
    "print(y)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "\n",
    "# Train Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1\n",
      " 1 0 0 1 1 0 0]\n",
      "[[5.014700e+04 1.534946e+05 4.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.400000e+01\n",
      "  1.000000e+00]\n",
      " [1.032050e+05 4.311018e+05 2.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 9.000000e+00\n",
      "  2.000000e+00]\n",
      " [2.958120e+04 2.358314e+05 3.200000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 1.800000e+01 2.000000e+00 2.900000e+01\n",
      "  2.000000e+00]\n",
      " [1.914980e+04 1.691192e+05 3.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [8.464720e+04 3.317996e+05 5.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [6.471040e+04 3.732576e+05 4.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.437420e+04 2.843206e+05 2.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 2.000000e+01\n",
      "  1.000000e+00]\n",
      " [4.201620e+04 1.643874e+05 5.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 1.400000e+01\n",
      "  1.000000e+00]\n",
      " [4.990480e+04 3.987230e+05 3.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [2.829820e+04 2.468148e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [9.694840e+04 3.433882e+05 4.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [1.701400e+04 1.897034e+05 5.200000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 1.800000e+01 2.000000e+00 2.600000e+01\n",
      "  2.000000e+00]\n",
      " [4.544220e+04 2.844162e+05 3.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [3.082520e+04 2.279220e+05 6.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.793880e+04 3.973210e+05 4.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.300000e+01\n",
      "  1.000000e+00]\n",
      " [2.663420e+04 2.407678e+05 3.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.800000e+01\n",
      "  1.000000e+00]\n",
      " [1.153294e+05 4.798070e+05 2.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [2.434460e+04 8.583540e+04 5.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.700000e+01\n",
      "  1.000000e+00]\n",
      " [6.090320e+04 3.922320e+05 2.200000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [4.627000e+03 9.156880e+04 3.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.600000e+01\n",
      "  2.000000e+00]\n",
      " [1.116682e+05 4.643776e+05 3.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.299200e+04 2.031200e+05 4.700000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.600000e+01\n",
      "  1.000000e+00]\n",
      " [4.287800e+04 7.223740e+04 6.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.800000e+01\n",
      "  2.000000e+00]\n",
      " [3.474280e+04 3.478170e+05 3.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.003840e+04 6.414200e+04 4.200000e+01 2.000000e+00 3.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.800000e+01\n",
      "  2.000000e+00]\n",
      " [7.922600e+04 2.332186e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.792880e+04 1.519574e+05 2.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [5.096620e+04 3.438192e+05 4.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.877120e+04 2.392782e+05 4.200000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.400000e+01\n",
      "  2.000000e+00]\n",
      " [6.233080e+04 2.916616e+05 3.700000e+01 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 2.000000e+00 1.800000e+01\n",
      "  2.000000e+00]\n",
      " [6.250400e+04 4.807282e+05 3.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 9.000000e+00\n",
      "  1.000000e+00]\n",
      " [5.192900e+04 4.751134e+05 3.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.164360e+04 3.355982e+05 2.200000e+01 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 2.400000e+01\n",
      "  2.000000e+00]\n",
      " [6.270340e+04 2.575464e+05 2.700000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [9.789940e+04 4.713406e+05 5.200000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [1.802360e+04 1.839744e+05 6.700000e+01 1.000000e+00 2.000000e+00\n",
      "  2.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.900000e+01\n",
      "  2.000000e+00]\n",
      " [1.030180e+04 8.449680e+04 3.200000e+01 1.000000e+00 2.000000e+00\n",
      "  1.000000e+00 1.000000e+00 8.000000e+00 2.000000e+00 2.700000e+01\n",
      "  1.000000e+00]\n",
      " [2.581100e+04 4.827650e+05 4.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 2.800000e+01\n",
      "  1.000000e+00]\n",
      " [5.487040e+04 3.045210e+05 4.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 8.000000e+00 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [6.004560e+04 3.278898e+05 5.200000e+01 2.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  2.000000e+00]\n",
      " [5.689240e+04 1.942982e+05 2.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 1.300000e+01 1.000000e+00 2.000000e+01\n",
      "  1.000000e+00]\n",
      " [1.069360e+04 2.288240e+05 3.700000e+01 2.000000e+00 2.000000e+00\n",
      "  2.000000e+00 2.000000e+00 8.000000e+00 2.000000e+00 1.900000e+01\n",
      "  1.000000e+00]\n",
      " [6.778380e+04 4.621654e+05 6.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.300000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]\n",
      " [4.179960e+04 3.260006e+05 2.700000e+01 1.000000e+00 0.000000e+00\n",
      "  2.000000e+00 0.000000e+00 1.800000e+01 1.000000e+00 4.000000e+00\n",
      "  1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_modeling():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_shape=(11,), activation='relu'))\n",
    "    model.add(Dense(70, activation='tanh'))\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dense(90, activation='softsign'))\n",
    "    model.add(Dense(85, activation='selu'))\n",
    "    # model.add(Dense(20, activation='elu'))\n",
    "    # model.add(Dense(130, activation='softsign'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7641 - accuracy: 0.4286 - val_loss: 6.8165 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db23787e50>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_shape=(11,), activation='relu'))\n",
    "model.add(Dense(55, activation='selu'))\n",
    "model.add(Dense(85, activation='selu'))\n",
    "model.add(Dense(2, activation='tanh'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adamax', metrics=['accuracy'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(x_train)\n",
    "x_train = le.transform(x_train)\n",
    "x_train = keras.utils.to_categorical(x_train)\n",
    "\n",
    "model.fit(y_train, x_train, validation_split=0.2, epochs=50, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Epoch 1/430\n",
      "2/2 [==============================] - 1s 153ms/step - loss: 0.8039 - accuracy: 0.2857 - val_loss: 0.9440 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6123 - accuracy: 0.7143 - val_loss: 1.2897 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6100 - accuracy: 0.7143 - val_loss: 1.6090 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6098 - accuracy: 0.7143 - val_loss: 1.6879 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6062 - accuracy: 0.7143 - val_loss: 1.6177 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5820 - accuracy: 0.7143 - val_loss: 1.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5595 - accuracy: 0.7143 - val_loss: 1.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5525 - accuracy: 0.7143 - val_loss: 1.0258 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5609 - accuracy: 0.8214 - val_loss: 0.9885 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5560 - accuracy: 0.7857 - val_loss: 1.1128 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5387 - accuracy: 0.7857 - val_loss: 1.2968 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5326 - accuracy: 0.7500 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5228 - accuracy: 0.7143 - val_loss: 1.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5161 - accuracy: 0.8214 - val_loss: 1.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5077 - accuracy: 0.8214 - val_loss: 1.3529 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5021 - accuracy: 0.8214 - val_loss: 1.3471 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4976 - accuracy: 0.8214 - val_loss: 1.3658 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4939 - accuracy: 0.8214 - val_loss: 1.3828 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4840 - accuracy: 0.8214 - val_loss: 1.2893 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4938 - accuracy: 0.8214 - val_loss: 1.2347 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4814 - accuracy: 0.8214 - val_loss: 1.3814 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4650 - accuracy: 0.8214 - val_loss: 1.4620 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4592 - accuracy: 0.8214 - val_loss: 1.5924 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4641 - accuracy: 0.8214 - val_loss: 1.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4589 - accuracy: 0.8214 - val_loss: 1.5854 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4442 - accuracy: 0.8214 - val_loss: 1.4966 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4393 - accuracy: 0.7857 - val_loss: 1.4893 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4296 - accuracy: 0.8214 - val_loss: 1.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4243 - accuracy: 0.8214 - val_loss: 1.8353 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4306 - accuracy: 0.8214 - val_loss: 1.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4355 - accuracy: 0.8214 - val_loss: 1.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4098 - accuracy: 0.8214 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4036 - accuracy: 0.8214 - val_loss: 1.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4248 - accuracy: 0.7857 - val_loss: 1.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4107 - accuracy: 0.8214 - val_loss: 1.5340 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3902 - accuracy: 0.8214 - val_loss: 1.8880 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4056 - accuracy: 0.8214 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3987 - accuracy: 0.8214 - val_loss: 1.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3831 - accuracy: 0.8214 - val_loss: 1.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3874 - accuracy: 0.8214 - val_loss: 1.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3721 - accuracy: 0.8214 - val_loss: 1.3389 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3833 - accuracy: 0.8571 - val_loss: 1.3549 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3679 - accuracy: 0.8571 - val_loss: 1.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3685 - accuracy: 0.8214 - val_loss: 2.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3840 - accuracy: 0.8214 - val_loss: 1.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3865 - accuracy: 0.8214 - val_loss: 1.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3670 - accuracy: 0.8214 - val_loss: 1.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3771 - accuracy: 0.8214 - val_loss: 1.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3505 - accuracy: 0.8571 - val_loss: 1.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3619 - accuracy: 0.8571 - val_loss: 1.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3588 - accuracy: 0.8571 - val_loss: 1.7667 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3689 - accuracy: 0.8571 - val_loss: 1.7448 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3372 - accuracy: 0.8571 - val_loss: 1.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4171 - accuracy: 0.6429 - val_loss: 1.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3798 - accuracy: 0.8214 - val_loss: 1.9421 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3497 - accuracy: 0.8214 - val_loss: 2.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3754 - accuracy: 0.8214 - val_loss: 2.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3699 - accuracy: 0.8214 - val_loss: 2.2509 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3497 - accuracy: 0.8571 - val_loss: 1.8418 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3347 - accuracy: 0.8571 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3686 - accuracy: 0.8214 - val_loss: 1.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3664 - accuracy: 0.8214 - val_loss: 1.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3375 - accuracy: 0.8571 - val_loss: 2.5015 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3777 - accuracy: 0.8571 - val_loss: 2.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3743 - accuracy: 0.8571 - val_loss: 2.0952 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3489 - accuracy: 0.8571 - val_loss: 1.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3387 - accuracy: 0.8571 - val_loss: 1.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3387 - accuracy: 0.8571 - val_loss: 1.5888 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3423 - accuracy: 0.8571 - val_loss: 1.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3331 - accuracy: 0.8571 - val_loss: 1.8973 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3279 - accuracy: 0.8571 - val_loss: 2.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3520 - accuracy: 0.8571 - val_loss: 2.2023 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3300 - accuracy: 0.8571 - val_loss: 1.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3401 - accuracy: 0.8214 - val_loss: 1.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3785 - accuracy: 0.8214 - val_loss: 1.3895 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3566 - accuracy: 0.7857 - val_loss: 1.7463 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3284 - accuracy: 0.8571 - val_loss: 2.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3309 - accuracy: 0.8571 - val_loss: 2.3202 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3340 - accuracy: 0.8571 - val_loss: 2.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3253 - accuracy: 0.8571 - val_loss: 1.7735 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3307 - accuracy: 0.8214 - val_loss: 1.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3881 - accuracy: 0.7857 - val_loss: 1.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3349 - accuracy: 0.8214 - val_loss: 2.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3634 - accuracy: 0.8571 - val_loss: 3.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3876 - accuracy: 0.8571 - val_loss: 2.7529 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3723 - accuracy: 0.8571 - val_loss: 2.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3374 - accuracy: 0.8571 - val_loss: 1.8474 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3269 - accuracy: 0.8571 - val_loss: 1.9496 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3267 - accuracy: 0.8571 - val_loss: 2.2033 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3287 - accuracy: 0.8571 - val_loss: 2.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3329 - accuracy: 0.8571 - val_loss: 2.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3336 - accuracy: 0.8571 - val_loss: 2.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3312 - accuracy: 0.8571 - val_loss: 2.0225 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3321 - accuracy: 0.8571 - val_loss: 2.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3277 - accuracy: 0.8571 - val_loss: 2.1630 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3261 - accuracy: 0.8571 - val_loss: 2.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3287 - accuracy: 0.8571 - val_loss: 2.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3343 - accuracy: 0.8571 - val_loss: 2.2181 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3299 - accuracy: 0.8571 - val_loss: 1.9484 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3213 - accuracy: 0.8571 - val_loss: 1.9040 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3200 - accuracy: 0.8571 - val_loss: 1.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3213 - accuracy: 0.8571 - val_loss: 2.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3186 - accuracy: 0.8571 - val_loss: 2.2431 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3257 - accuracy: 0.8571 - val_loss: 2.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3376 - accuracy: 0.8571 - val_loss: 2.2767 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3408 - accuracy: 0.8571 - val_loss: 1.8377 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3222 - accuracy: 0.8571 - val_loss: 1.7854 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3233 - accuracy: 0.8571 - val_loss: 1.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3334 - accuracy: 0.8571 - val_loss: 1.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3074 - accuracy: 0.8571 - val_loss: 2.5663 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3448 - accuracy: 0.8571 - val_loss: 3.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3817 - accuracy: 0.8571 - val_loss: 2.7215 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3443 - accuracy: 0.8571 - val_loss: 2.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3122 - accuracy: 0.8571 - val_loss: 1.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3411 - accuracy: 0.8214 - val_loss: 1.3737 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3459 - accuracy: 0.8214 - val_loss: 1.8306 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3104 - accuracy: 0.8571 - val_loss: 2.4811 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3409 - accuracy: 0.8571 - val_loss: 2.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3543 - accuracy: 0.8571 - val_loss: 2.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3307 - accuracy: 0.8571 - val_loss: 2.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3208 - accuracy: 0.8571 - val_loss: 1.8449 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3285 - accuracy: 0.8214 - val_loss: 2.1278 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3235 - accuracy: 0.8571 - val_loss: 2.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3405 - accuracy: 0.8571 - val_loss: 2.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3343 - accuracy: 0.8571 - val_loss: 2.0535 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3153 - accuracy: 0.8571 - val_loss: 1.7560 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3235 - accuracy: 0.8571 - val_loss: 1.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3772 - accuracy: 0.7857 - val_loss: 1.4558 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3496 - accuracy: 0.7857 - val_loss: 2.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3252 - accuracy: 0.8571 - val_loss: 2.7407 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3418 - accuracy: 0.8571 - val_loss: 2.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3368 - accuracy: 0.8571 - val_loss: 2.1288 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3348 - accuracy: 0.8214 - val_loss: 1.9544 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3282 - accuracy: 0.8571 - val_loss: 2.1268 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3196 - accuracy: 0.8571 - val_loss: 2.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3295 - accuracy: 0.7857 - val_loss: 2.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3183 - accuracy: 0.8571 - val_loss: 2.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3332 - accuracy: 0.8571 - val_loss: 2.5251 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3260 - accuracy: 0.8571 - val_loss: 2.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3106 - accuracy: 0.8571 - val_loss: 1.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3401 - accuracy: 0.8214 - val_loss: 1.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3537 - accuracy: 0.8214 - val_loss: 1.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3223 - accuracy: 0.8571 - val_loss: 2.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3163 - accuracy: 0.8571 - val_loss: 2.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3329 - accuracy: 0.8571 - val_loss: 2.4403 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3262 - accuracy: 0.8571 - val_loss: 2.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3152 - accuracy: 0.8571 - val_loss: 1.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3171 - accuracy: 0.8571 - val_loss: 1.7660 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3234 - accuracy: 0.8571 - val_loss: 1.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3173 - accuracy: 0.8571 - val_loss: 2.2724 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3179 - accuracy: 0.8571 - val_loss: 2.5006 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3299 - accuracy: 0.8571 - val_loss: 2.5738 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3309 - accuracy: 0.8571 - val_loss: 2.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3483 - accuracy: 0.8571 - val_loss: 2.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3204 - accuracy: 0.8571 - val_loss: 2.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3221 - accuracy: 0.8571 - val_loss: 2.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3321 - accuracy: 0.8571 - val_loss: 2.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3371 - accuracy: 0.8571 - val_loss: 2.3853 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3215 - accuracy: 0.8571 - val_loss: 2.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3178 - accuracy: 0.8571 - val_loss: 1.6809 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3301 - accuracy: 0.7857 - val_loss: 1.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3258 - accuracy: 0.8571 - val_loss: 1.9737 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3257 - accuracy: 0.8571 - val_loss: 2.2388 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3170 - accuracy: 0.8571 - val_loss: 2.1428 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3129 - accuracy: 0.8571 - val_loss: 1.9665 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3168 - accuracy: 0.8571 - val_loss: 1.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3155 - accuracy: 0.8571 - val_loss: 1.9715 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3225 - accuracy: 0.8571 - val_loss: 2.0542 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3184 - accuracy: 0.8571 - val_loss: 2.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3167 - accuracy: 0.8571 - val_loss: 2.0571 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3149 - accuracy: 0.8571 - val_loss: 2.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3133 - accuracy: 0.8571 - val_loss: 2.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3135 - accuracy: 0.8571 - val_loss: 2.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3263 - accuracy: 0.8571 - val_loss: 2.4436 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3287 - accuracy: 0.8571 - val_loss: 2.1483 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3153 - accuracy: 0.8571 - val_loss: 2.0897 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3138 - accuracy: 0.8571 - val_loss: 2.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3151 - accuracy: 0.8571 - val_loss: 2.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3132 - accuracy: 0.8571 - val_loss: 2.2530 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3156 - accuracy: 0.8571 - val_loss: 2.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3216 - accuracy: 0.8571 - val_loss: 2.6665 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3389 - accuracy: 0.8571 - val_loss: 2.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3121 - accuracy: 0.8571 - val_loss: 1.5651 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3437 - accuracy: 0.8214 - val_loss: 1.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3532 - accuracy: 0.8214 - val_loss: 1.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3254 - accuracy: 0.8571 - val_loss: 2.4605 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3168 - accuracy: 0.8571 - val_loss: 2.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3312 - accuracy: 0.8571 - val_loss: 2.5513 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3204 - accuracy: 0.8571 - val_loss: 2.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3206 - accuracy: 0.8571 - val_loss: 1.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3216 - accuracy: 0.7857 - val_loss: 1.9410 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3218 - accuracy: 0.8571 - val_loss: 2.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3168 - accuracy: 0.8571 - val_loss: 2.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3181 - accuracy: 0.8571 - val_loss: 2.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3136 - accuracy: 0.8571 - val_loss: 2.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3163 - accuracy: 0.8571 - val_loss: 2.3843 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3206 - accuracy: 0.8571 - val_loss: 2.4509 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3271 - accuracy: 0.8571 - val_loss: 2.2994 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3250 - accuracy: 0.8571 - val_loss: 2.1278 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3145 - accuracy: 0.8571 - val_loss: 2.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3137 - accuracy: 0.8571 - val_loss: 1.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3242 - accuracy: 0.8571 - val_loss: 1.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3153 - accuracy: 0.8571 - val_loss: 2.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3118 - accuracy: 0.8571 - val_loss: 2.3309 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3174 - accuracy: 0.8571 - val_loss: 2.4057 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3162 - accuracy: 0.8571 - val_loss: 2.5049 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/430\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3196 - accuracy: 0.8571 - val_loss: 2.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3147 - accuracy: 0.8571 - val_loss: 2.2497 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3093 - accuracy: 0.8571 - val_loss: 1.9529 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3171 - accuracy: 0.8571 - val_loss: 1.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3315 - accuracy: 0.8214 - val_loss: 1.9515 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3303 - accuracy: 0.8214 - val_loss: 2.3967 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3180 - accuracy: 0.8571 - val_loss: 2.5036 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3249 - accuracy: 0.8571 - val_loss: 2.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3246 - accuracy: 0.8571 - val_loss: 2.2399 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3207 - accuracy: 0.8571 - val_loss: 1.9627 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3238 - accuracy: 0.8571 - val_loss: 1.9668 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3251 - accuracy: 0.8571 - val_loss: 2.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 2.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3131 - accuracy: 0.8571 - val_loss: 2.1998 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3098 - accuracy: 0.8571 - val_loss: 2.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3172 - accuracy: 0.8571 - val_loss: 2.3794 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3210 - accuracy: 0.8929 - val_loss: 2.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3240 - accuracy: 0.8214 - val_loss: 2.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3376 - accuracy: 0.8214 - val_loss: 2.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3313 - accuracy: 0.8214 - val_loss: 2.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3239 - accuracy: 0.8214 - val_loss: 2.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3190 - accuracy: 0.8214 - val_loss: 2.3343 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3160 - accuracy: 0.8571 - val_loss: 2.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3180 - accuracy: 0.8571 - val_loss: 2.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/430\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3364 - accuracy: 0.8571 - val_loss: 2.4672 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/430\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3438 - accuracy: 0.8214 - val_loss: 1.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/430\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3276 - accuracy: 0.8214 - val_loss: 2.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3036 - accuracy: 0.8571 - val_loss: 2.7184 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3212 - accuracy: 0.8571 - val_loss: 3.2661 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3682 - accuracy: 0.8571 - val_loss: 3.3124 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3774 - accuracy: 0.8571 - val_loss: 2.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3426 - accuracy: 0.8571 - val_loss: 2.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3075 - accuracy: 0.8571 - val_loss: 1.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3264 - accuracy: 0.8929 - val_loss: 1.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3507 - accuracy: 0.8214 - val_loss: 1.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3265 - accuracy: 0.8214 - val_loss: 2.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3251 - accuracy: 0.8571 - val_loss: 2.7866 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3393 - accuracy: 0.8571 - val_loss: 2.6674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3279 - accuracy: 0.8571 - val_loss: 2.2763 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3122 - accuracy: 0.8571 - val_loss: 1.8299 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3244 - accuracy: 0.8214 - val_loss: 1.5901 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3415 - accuracy: 0.7857 - val_loss: 1.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3143 - accuracy: 0.8571 - val_loss: 2.4154 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3169 - accuracy: 0.8571 - val_loss: 2.8248 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3392 - accuracy: 0.8571 - val_loss: 2.7896 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3372 - accuracy: 0.8571 - val_loss: 2.3852 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 1.9573 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3322 - accuracy: 0.8214 - val_loss: 1.8578 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3206 - accuracy: 0.8571 - val_loss: 2.1959 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/430\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3137 - accuracy: 0.8571 - val_loss: 2.4318 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3197 - accuracy: 0.8571 - val_loss: 2.5123 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3209 - accuracy: 0.8571 - val_loss: 2.3701 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3184 - accuracy: 0.8571 - val_loss: 2.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/430\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3124 - accuracy: 0.8571 - val_loss: 2.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3158 - accuracy: 0.8571 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3189 - accuracy: 0.8571 - val_loss: 2.0491 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3160 - accuracy: 0.8571 - val_loss: 2.2575 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3146 - accuracy: 0.8571 - val_loss: 2.3061 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3145 - accuracy: 0.8571 - val_loss: 2.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3160 - accuracy: 0.8571 - val_loss: 2.2690 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3141 - accuracy: 0.8571 - val_loss: 2.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3153 - accuracy: 0.8571 - val_loss: 2.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3155 - accuracy: 0.8571 - val_loss: 2.0877 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3121 - accuracy: 0.8571 - val_loss: 2.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3105 - accuracy: 0.8571 - val_loss: 2.3863 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3164 - accuracy: 0.8571 - val_loss: 2.3924 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3123 - accuracy: 0.8571 - val_loss: 2.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3100 - accuracy: 0.8571 - val_loss: 1.7707 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3269 - accuracy: 0.8214 - val_loss: 1.8046 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3232 - accuracy: 0.8571 - val_loss: 2.1803 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3090 - accuracy: 0.8571 - val_loss: 2.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3158 - accuracy: 0.8571 - val_loss: 2.7548 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3278 - accuracy: 0.8571 - val_loss: 2.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3321 - accuracy: 0.8571 - val_loss: 2.5763 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3095 - accuracy: 0.8571 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3524 - accuracy: 0.8214 - val_loss: 1.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3563 - accuracy: 0.8214 - val_loss: 2.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3122 - accuracy: 0.8571 - val_loss: 2.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3123 - accuracy: 0.8571 - val_loss: 2.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3255 - accuracy: 0.8571 - val_loss: 2.8010 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3479 - accuracy: 0.8571 - val_loss: 2.7004 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3157 - accuracy: 0.8571 - val_loss: 1.9857 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3150 - accuracy: 0.8571 - val_loss: 1.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3695 - accuracy: 0.7857 - val_loss: 1.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3296 - accuracy: 0.8214 - val_loss: 2.4043 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3355 - accuracy: 0.8571 - val_loss: 2.8663 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3470 - accuracy: 0.8571 - val_loss: 2.6826 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3311 - accuracy: 0.8571 - val_loss: 2.1480 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3310 - accuracy: 0.8571 - val_loss: 1.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3429 - accuracy: 0.8571 - val_loss: 1.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3338 - accuracy: 0.8571 - val_loss: 1.8527 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3207 - accuracy: 0.8571 - val_loss: 2.2650 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3195 - accuracy: 0.8571 - val_loss: 2.4415 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3293 - accuracy: 0.8571 - val_loss: 2.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3302 - accuracy: 0.8571 - val_loss: 2.2779 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3173 - accuracy: 0.8571 - val_loss: 1.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3243 - accuracy: 0.8571 - val_loss: 1.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3538 - accuracy: 0.8214 - val_loss: 1.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3336 - accuracy: 0.8929 - val_loss: 1.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 2.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3425 - accuracy: 0.8571 - val_loss: 2.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3454 - accuracy: 0.8571 - val_loss: 2.4854 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3174 - accuracy: 0.8571 - val_loss: 2.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3042 - accuracy: 0.8571 - val_loss: 1.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3541 - accuracy: 0.8214 - val_loss: 1.3518 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3564 - accuracy: 0.8214 - val_loss: 1.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3163 - accuracy: 0.8571 - val_loss: 2.2539 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3141 - accuracy: 0.8571 - val_loss: 2.7291 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3484 - accuracy: 0.8571 - val_loss: 2.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3383 - accuracy: 0.8571 - val_loss: 2.4036 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3249 - accuracy: 0.8571 - val_loss: 1.7462 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3326 - accuracy: 0.8214 - val_loss: 1.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3464 - accuracy: 0.7857 - val_loss: 1.6686 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3244 - accuracy: 0.8571 - val_loss: 2.0933 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3095 - accuracy: 0.8571 - val_loss: 2.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3350 - accuracy: 0.8571 - val_loss: 2.8268 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3443 - accuracy: 0.8571 - val_loss: 2.6690 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3312 - accuracy: 0.8571 - val_loss: 2.3724 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3291 - accuracy: 0.8571 - val_loss: 1.9745 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3255 - accuracy: 0.8571 - val_loss: 1.8601 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3205 - accuracy: 0.8571 - val_loss: 2.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3173 - accuracy: 0.8571 - val_loss: 2.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3161 - accuracy: 0.8571 - val_loss: 2.3346 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3209 - accuracy: 0.8571 - val_loss: 2.4858 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3275 - accuracy: 0.8571 - val_loss: 2.4007 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3217 - accuracy: 0.8571 - val_loss: 2.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3194 - accuracy: 0.8571 - val_loss: 1.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3174 - accuracy: 0.8571 - val_loss: 1.8849 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3187 - accuracy: 0.8571 - val_loss: 1.8892 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3141 - accuracy: 0.8571 - val_loss: 2.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3128 - accuracy: 0.8571 - val_loss: 2.3132 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3214 - accuracy: 0.8571 - val_loss: 2.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3244 - accuracy: 0.8571 - val_loss: 2.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3132 - accuracy: 0.8571 - val_loss: 2.2042 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3186 - accuracy: 0.8571 - val_loss: 2.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3126 - accuracy: 0.8571 - val_loss: 2.0585 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3154 - accuracy: 0.8571 - val_loss: 1.9490 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3155 - accuracy: 0.8571 - val_loss: 2.0442 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3122 - accuracy: 0.8571 - val_loss: 2.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3103 - accuracy: 0.8571 - val_loss: 2.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3142 - accuracy: 0.8571 - val_loss: 2.3737 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3166 - accuracy: 0.8571 - val_loss: 2.2887 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3104 - accuracy: 0.8571 - val_loss: 1.9533 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3276 - accuracy: 0.7857 - val_loss: 1.6600 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3334 - accuracy: 0.8214 - val_loss: 1.8166 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3201 - accuracy: 0.8571 - val_loss: 2.0338 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3114 - accuracy: 0.8571 - val_loss: 2.2395 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3176 - accuracy: 0.8571 - val_loss: 2.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3122 - accuracy: 0.8571 - val_loss: 2.1575 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 1.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/430\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3175 - accuracy: 0.8571 - val_loss: 1.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/430\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3288 - accuracy: 0.8571 - val_loss: 1.5370 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3436 - accuracy: 0.8571 - val_loss: 1.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3206 - accuracy: 0.8571 - val_loss: 2.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3085 - accuracy: 0.8571 - val_loss: 2.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3413 - accuracy: 0.8571 - val_loss: 2.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3218 - accuracy: 0.8571 - val_loss: 2.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3153 - accuracy: 0.8214 - val_loss: 1.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3397 - accuracy: 0.8214 - val_loss: 1.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3458 - accuracy: 0.8214 - val_loss: 1.8015 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3119 - accuracy: 0.8571 - val_loss: 2.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3386 - accuracy: 0.8571 - val_loss: 2.7655 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3370 - accuracy: 0.8571 - val_loss: 2.5749 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3174 - accuracy: 0.8571 - val_loss: 2.1145 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3162 - accuracy: 0.8571 - val_loss: 1.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3303 - accuracy: 0.8571 - val_loss: 1.6623 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3320 - accuracy: 0.8571 - val_loss: 1.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3175 - accuracy: 0.8571 - val_loss: 2.1485 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3153 - accuracy: 0.8571 - val_loss: 2.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3129 - accuracy: 0.8571 - val_loss: 2.1599 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3165 - accuracy: 0.8571 - val_loss: 2.0623 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3154 - accuracy: 0.8571 - val_loss: 2.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3161 - accuracy: 0.8571 - val_loss: 2.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3129 - accuracy: 0.8571 - val_loss: 2.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3108 - accuracy: 0.8571 - val_loss: 2.3814 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3276 - accuracy: 0.8571 - val_loss: 2.5913 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3243 - accuracy: 0.8571 - val_loss: 2.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3144 - accuracy: 0.8571 - val_loss: 2.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3119 - accuracy: 0.8571 - val_loss: 1.9829 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3155 - accuracy: 0.8571 - val_loss: 1.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3180 - accuracy: 0.8571 - val_loss: 2.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3061 - accuracy: 0.8571 - val_loss: 2.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3152 - accuracy: 0.8571 - val_loss: 2.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3467 - accuracy: 0.8571 - val_loss: 2.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3311 - accuracy: 0.8571 - val_loss: 2.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3124 - accuracy: 0.8571 - val_loss: 1.7756 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3263 - accuracy: 0.8571 - val_loss: 1.4952 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3542 - accuracy: 0.8214 - val_loss: 1.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3225 - accuracy: 0.8571 - val_loss: 2.2834 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3115 - accuracy: 0.8571 - val_loss: 2.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3292 - accuracy: 0.8571 - val_loss: 2.9941 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3538 - accuracy: 0.8571 - val_loss: 2.9462 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3435 - accuracy: 0.8571 - val_loss: 2.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3163 - accuracy: 0.8571 - val_loss: 1.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3221 - accuracy: 0.8214 - val_loss: 1.6861 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3318 - accuracy: 0.8214 - val_loss: 1.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3209 - accuracy: 0.8214 - val_loss: 2.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3131 - accuracy: 0.8571 - val_loss: 2.4937 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3196 - accuracy: 0.8571 - val_loss: 2.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3291 - accuracy: 0.8571 - val_loss: 2.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3247 - accuracy: 0.8571 - val_loss: 2.3520 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3273 - accuracy: 0.8571 - val_loss: 1.9674 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3155 - accuracy: 0.8571 - val_loss: 1.8319 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3222 - accuracy: 0.8571 - val_loss: 1.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3219 - accuracy: 0.8571 - val_loss: 1.9298 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3143 - accuracy: 0.8571 - val_loss: 2.1586 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3145 - accuracy: 0.8571 - val_loss: 2.4763 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3218 - accuracy: 0.8571 - val_loss: 2.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3240 - accuracy: 0.8571 - val_loss: 2.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3229 - accuracy: 0.8571 - val_loss: 2.2925 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3151 - accuracy: 0.8571 - val_loss: 2.2047 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 2.1351 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 2.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3136 - accuracy: 0.8571 - val_loss: 1.8056 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3159 - accuracy: 0.8571 - val_loss: 1.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3519 - accuracy: 0.7857 - val_loss: 1.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3175 - accuracy: 0.8571 - val_loss: 2.3081 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3258 - accuracy: 0.8571 - val_loss: 2.8601 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3433 - accuracy: 0.8571 - val_loss: 2.8725 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3328 - accuracy: 0.8571 - val_loss: 2.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3163 - accuracy: 0.8571 - val_loss: 2.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3307 - accuracy: 0.8571 - val_loss: 1.8336 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3174 - accuracy: 0.8571 - val_loss: 2.1037 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ram://cc15a95e-403c-4272-9caa-c4eb572352fa/assets\n",
      "Epoch 1/430\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.7892 - accuracy: 0.3214 - val_loss: 0.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/430\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6593 - accuracy: 0.6786 - val_loss: 1.3805 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6427 - accuracy: 0.6786 - val_loss: 1.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6482 - accuracy: 0.6786 - val_loss: 1.4700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6330 - accuracy: 0.6786 - val_loss: 1.3821 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6163 - accuracy: 0.6786 - val_loss: 1.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6007 - accuracy: 0.6786 - val_loss: 1.0846 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5882 - accuracy: 0.6786 - val_loss: 1.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5884 - accuracy: 0.6786 - val_loss: 0.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5944 - accuracy: 0.6786 - val_loss: 0.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5879 - accuracy: 0.6786 - val_loss: 0.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5734 - accuracy: 0.6786 - val_loss: 1.0991 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5625 - accuracy: 0.6786 - val_loss: 1.2209 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5674 - accuracy: 0.6786 - val_loss: 1.3060 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5611 - accuracy: 0.6786 - val_loss: 1.2487 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5550 - accuracy: 0.6786 - val_loss: 1.1663 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/430\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5509 - accuracy: 0.6786 - val_loss: 1.1502 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5435 - accuracy: 0.6786 - val_loss: 1.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5391 - accuracy: 0.6786 - val_loss: 1.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5360 - accuracy: 0.6786 - val_loss: 1.2829 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5408 - accuracy: 0.6786 - val_loss: 1.3608 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5298 - accuracy: 0.6786 - val_loss: 1.2531 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5218 - accuracy: 0.6786 - val_loss: 1.1286 - val_accuracy: 0.1429\n",
      "Epoch 24/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5255 - accuracy: 0.7143 - val_loss: 1.0567 - val_accuracy: 0.4286\n",
      "Epoch 25/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5331 - accuracy: 0.6071 - val_loss: 1.0774 - val_accuracy: 0.4286\n",
      "Epoch 26/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5277 - accuracy: 0.6429 - val_loss: 1.1394 - val_accuracy: 0.1429\n",
      "Epoch 27/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5273 - accuracy: 0.5357 - val_loss: 1.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5160 - accuracy: 0.6786 - val_loss: 1.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5334 - accuracy: 0.6786 - val_loss: 1.6502 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5418 - accuracy: 0.6786 - val_loss: 1.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5037 - accuracy: 0.6786 - val_loss: 1.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5036 - accuracy: 0.7500 - val_loss: 1.3213 - val_accuracy: 0.1429\n",
      "Epoch 33/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5025 - accuracy: 0.7143 - val_loss: 1.3514 - val_accuracy: 0.1429\n",
      "Epoch 34/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5052 - accuracy: 0.7143 - val_loss: 1.5011 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5110 - accuracy: 0.6786 - val_loss: 1.7511 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/430\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5125 - accuracy: 0.6786 - val_loss: 1.7064 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5026 - accuracy: 0.6786 - val_loss: 1.5403 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5087 - accuracy: 0.6071 - val_loss: 1.4250 - val_accuracy: 0.1429\n",
      "Epoch 39/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4922 - accuracy: 0.7143 - val_loss: 1.5070 - val_accuracy: 0.1429\n",
      "Epoch 40/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4890 - accuracy: 0.7143 - val_loss: 1.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5088 - accuracy: 0.6786 - val_loss: 1.6622 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4867 - accuracy: 0.6786 - val_loss: 1.4606 - val_accuracy: 0.1429\n",
      "Epoch 43/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4943 - accuracy: 0.7143 - val_loss: 1.3494 - val_accuracy: 0.4286\n",
      "Epoch 44/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5027 - accuracy: 0.6786 - val_loss: 1.4623 - val_accuracy: 0.4286\n",
      "Epoch 45/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4869 - accuracy: 0.6429 - val_loss: 1.7436 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4820 - accuracy: 0.6786 - val_loss: 2.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5108 - accuracy: 0.6786 - val_loss: 2.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5368 - accuracy: 0.6786 - val_loss: 2.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5203 - accuracy: 0.6786 - val_loss: 1.8193 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4849 - accuracy: 0.6786 - val_loss: 1.5689 - val_accuracy: 0.4286\n",
      "Epoch 51/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4910 - accuracy: 0.6786 - val_loss: 1.4557 - val_accuracy: 0.4286\n",
      "Epoch 52/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4947 - accuracy: 0.6786 - val_loss: 1.5377 - val_accuracy: 0.4286\n",
      "Epoch 53/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4882 - accuracy: 0.6786 - val_loss: 1.6693 - val_accuracy: 0.1429\n",
      "Epoch 54/430\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4798 - accuracy: 0.7143 - val_loss: 1.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4826 - accuracy: 0.6786 - val_loss: 1.8700 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4866 - accuracy: 0.6786 - val_loss: 1.8482 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4799 - accuracy: 0.6786 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4790 - accuracy: 0.7143 - val_loss: 1.7957 - val_accuracy: 0.1429\n",
      "Epoch 59/430\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.4765 - accuracy: 0.7143 - val_loss: 1.7854 - val_accuracy: 0.1429\n",
      "Epoch 60/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4836 - accuracy: 0.7143 - val_loss: 1.8795 - val_accuracy: 0.1429\n",
      "Epoch 61/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4708 - accuracy: 0.7143 - val_loss: 2.1542 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5096 - accuracy: 0.6786 - val_loss: 2.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5022 - accuracy: 0.6786 - val_loss: 1.8650 - val_accuracy: 0.1429\n",
      "Epoch 64/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5043 - accuracy: 0.7143 - val_loss: 1.5439 - val_accuracy: 0.4286\n",
      "Epoch 65/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4898 - accuracy: 0.6429 - val_loss: 1.5680 - val_accuracy: 0.1429\n",
      "Epoch 66/430\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4868 - accuracy: 0.7143 - val_loss: 1.6358 - val_accuracy: 0.1429\n",
      "Epoch 67/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4802 - accuracy: 0.7143 - val_loss: 1.7872 - val_accuracy: 0.1429\n",
      "Epoch 68/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4830 - accuracy: 0.7143 - val_loss: 1.9983 - val_accuracy: 0.1429\n",
      "Epoch 69/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4766 - accuracy: 0.7143 - val_loss: 1.9992 - val_accuracy: 0.1429\n",
      "Epoch 70/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4794 - accuracy: 0.7143 - val_loss: 1.9889 - val_accuracy: 0.1429\n",
      "Epoch 71/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4749 - accuracy: 0.7143 - val_loss: 1.9919 - val_accuracy: 0.1429\n",
      "Epoch 72/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4746 - accuracy: 0.7143 - val_loss: 1.9927 - val_accuracy: 0.1429\n",
      "Epoch 73/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4735 - accuracy: 0.7143 - val_loss: 1.9148 - val_accuracy: 0.1429\n",
      "Epoch 74/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4757 - accuracy: 0.7500 - val_loss: 1.8884 - val_accuracy: 0.4286\n",
      "Epoch 75/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4753 - accuracy: 0.6786 - val_loss: 1.9978 - val_accuracy: 0.1429\n",
      "Epoch 76/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4733 - accuracy: 0.7143 - val_loss: 2.1746 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4811 - accuracy: 0.6786 - val_loss: 2.2407 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4868 - accuracy: 0.6786 - val_loss: 2.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4832 - accuracy: 0.6786 - val_loss: 2.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4759 - accuracy: 0.6786 - val_loss: 2.0161 - val_accuracy: 0.1429\n",
      "Epoch 81/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4696 - accuracy: 0.7143 - val_loss: 1.8850 - val_accuracy: 0.4286\n",
      "Epoch 82/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4770 - accuracy: 0.6786 - val_loss: 1.8106 - val_accuracy: 0.4286\n",
      "Epoch 83/430\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4760 - accuracy: 0.6786 - val_loss: 1.9788 - val_accuracy: 0.1429\n",
      "Epoch 84/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4735 - accuracy: 0.7143 - val_loss: 2.1755 - val_accuracy: 0.1429\n",
      "Epoch 85/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4734 - accuracy: 0.7143 - val_loss: 2.1459 - val_accuracy: 0.1429\n",
      "Epoch 86/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4728 - accuracy: 0.7143 - val_loss: 2.0438 - val_accuracy: 0.1429\n",
      "Epoch 87/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4679 - accuracy: 0.7143 - val_loss: 1.9479 - val_accuracy: 0.1429\n",
      "Epoch 88/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4753 - accuracy: 0.7143 - val_loss: 1.9275 - val_accuracy: 0.1429\n",
      "Epoch 89/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4721 - accuracy: 0.7143 - val_loss: 2.0791 - val_accuracy: 0.1429\n",
      "Epoch 90/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4700 - accuracy: 0.7143 - val_loss: 2.1092 - val_accuracy: 0.1429\n",
      "Epoch 91/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4705 - accuracy: 0.7143 - val_loss: 1.9934 - val_accuracy: 0.1429\n",
      "Epoch 92/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4832 - accuracy: 0.6786 - val_loss: 1.8726 - val_accuracy: 0.4286\n",
      "Epoch 93/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4801 - accuracy: 0.6429 - val_loss: 2.0493 - val_accuracy: 0.1429\n",
      "Epoch 94/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4669 - accuracy: 0.7143 - val_loss: 2.1670 - val_accuracy: 0.1429\n",
      "Epoch 95/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4670 - accuracy: 0.7143 - val_loss: 2.2521 - val_accuracy: 0.1429\n",
      "Epoch 96/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4683 - accuracy: 0.7143 - val_loss: 2.3344 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4740 - accuracy: 0.6786 - val_loss: 2.2457 - val_accuracy: 0.1429\n",
      "Epoch 98/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4662 - accuracy: 0.7143 - val_loss: 2.0180 - val_accuracy: 0.4286\n",
      "Epoch 99/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4741 - accuracy: 0.6786 - val_loss: 1.9283 - val_accuracy: 0.4286\n",
      "Epoch 100/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4860 - accuracy: 0.6786 - val_loss: 2.0155 - val_accuracy: 0.4286\n",
      "Epoch 101/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4716 - accuracy: 0.6786 - val_loss: 2.1557 - val_accuracy: 0.1429\n",
      "Epoch 102/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4738 - accuracy: 0.7143 - val_loss: 2.3343 - val_accuracy: 0.1429\n",
      "Epoch 103/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4781 - accuracy: 0.6429 - val_loss: 2.2015 - val_accuracy: 0.1429\n",
      "Epoch 104/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4687 - accuracy: 0.6786 - val_loss: 1.9133 - val_accuracy: 0.4286\n",
      "Epoch 105/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4850 - accuracy: 0.6786 - val_loss: 1.9606 - val_accuracy: 0.4286\n",
      "Epoch 106/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4773 - accuracy: 0.6429 - val_loss: 2.2422 - val_accuracy: 0.1429\n",
      "Epoch 107/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4707 - accuracy: 0.7143 - val_loss: 2.3759 - val_accuracy: 0.1429\n",
      "Epoch 108/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4755 - accuracy: 0.7143 - val_loss: 2.2990 - val_accuracy: 0.1429\n",
      "Epoch 109/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4662 - accuracy: 0.7143 - val_loss: 2.2674 - val_accuracy: 0.1429\n",
      "Epoch 110/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4697 - accuracy: 0.7143 - val_loss: 2.1636 - val_accuracy: 0.1429\n",
      "Epoch 111/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4870 - accuracy: 0.6786 - val_loss: 2.0444 - val_accuracy: 0.4286\n",
      "Epoch 112/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4711 - accuracy: 0.6786 - val_loss: 2.3276 - val_accuracy: 0.1429\n",
      "Epoch 113/430\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.7041 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5069 - accuracy: 0.6786 - val_loss: 2.6605 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5012 - accuracy: 0.7143 - val_loss: 2.3236 - val_accuracy: 0.1429\n",
      "Epoch 116/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4799 - accuracy: 0.7143 - val_loss: 2.0950 - val_accuracy: 0.1429\n",
      "Epoch 117/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4690 - accuracy: 0.7143 - val_loss: 2.1271 - val_accuracy: 0.1429\n",
      "Epoch 118/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4767 - accuracy: 0.7143 - val_loss: 2.2047 - val_accuracy: 0.1429\n",
      "Epoch 119/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4667 - accuracy: 0.7143 - val_loss: 2.0853 - val_accuracy: 0.1429\n",
      "Epoch 120/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4679 - accuracy: 0.7143 - val_loss: 1.9700 - val_accuracy: 0.1429\n",
      "Epoch 121/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4760 - accuracy: 0.7857 - val_loss: 1.9297 - val_accuracy: 0.4286\n",
      "Epoch 122/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4794 - accuracy: 0.7143 - val_loss: 2.0375 - val_accuracy: 0.1429\n",
      "Epoch 123/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4687 - accuracy: 0.7143 - val_loss: 2.2104 - val_accuracy: 0.1429\n",
      "Epoch 124/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4721 - accuracy: 0.7143 - val_loss: 2.3406 - val_accuracy: 0.1429\n",
      "Epoch 125/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4848 - accuracy: 0.7143 - val_loss: 2.1436 - val_accuracy: 0.1429\n",
      "Epoch 126/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4617 - accuracy: 0.7500 - val_loss: 1.7603 - val_accuracy: 0.5714\n",
      "Epoch 127/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5257 - accuracy: 0.6429 - val_loss: 1.7591 - val_accuracy: 0.5714\n",
      "Epoch 128/430\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.4963 - accuracy: 0.6429 - val_loss: 2.2108 - val_accuracy: 0.1429\n",
      "Epoch 129/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4640 - accuracy: 0.6786 - val_loss: 2.6827 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5144 - accuracy: 0.6786 - val_loss: 2.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5100 - accuracy: 0.6786 - val_loss: 2.2819 - val_accuracy: 0.1429\n",
      "Epoch 132/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4656 - accuracy: 0.7143 - val_loss: 1.9712 - val_accuracy: 0.4286\n",
      "Epoch 133/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4749 - accuracy: 0.6786 - val_loss: 1.8231 - val_accuracy: 0.4286\n",
      "Epoch 134/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4885 - accuracy: 0.6786 - val_loss: 1.8766 - val_accuracy: 0.4286\n",
      "Epoch 135/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4756 - accuracy: 0.6786 - val_loss: 2.0959 - val_accuracy: 0.1429\n",
      "Epoch 136/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7143 - val_loss: 2.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4770 - accuracy: 0.6786 - val_loss: 2.3705 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4864 - accuracy: 0.6786 - val_loss: 2.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4795 - accuracy: 0.6786 - val_loss: 2.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4708 - accuracy: 0.6429 - val_loss: 2.0954 - val_accuracy: 0.1429\n",
      "Epoch 141/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4676 - accuracy: 0.7143 - val_loss: 1.8887 - val_accuracy: 0.4286\n",
      "Epoch 142/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4792 - accuracy: 0.6786 - val_loss: 1.8635 - val_accuracy: 0.4286\n",
      "Epoch 143/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4805 - accuracy: 0.6786 - val_loss: 2.0031 - val_accuracy: 0.4286\n",
      "Epoch 144/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4667 - accuracy: 0.6786 - val_loss: 2.2416 - val_accuracy: 0.1429\n",
      "Epoch 145/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4915 - accuracy: 0.6786 - val_loss: 2.4849 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/430\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4955 - accuracy: 0.6786 - val_loss: 2.2788 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4607 - accuracy: 0.7500 - val_loss: 1.8330 - val_accuracy: 0.4286\n",
      "Epoch 148/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5087 - accuracy: 0.6429 - val_loss: 1.6270 - val_accuracy: 0.5714\n",
      "Epoch 149/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5122 - accuracy: 0.6429 - val_loss: 1.8260 - val_accuracy: 0.4286\n",
      "Epoch 150/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4759 - accuracy: 0.6786 - val_loss: 2.2462 - val_accuracy: 0.1429\n",
      "Epoch 151/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4695 - accuracy: 0.7500 - val_loss: 2.5481 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5067 - accuracy: 0.6786 - val_loss: 2.6224 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5198 - accuracy: 0.6786 - val_loss: 2.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5117 - accuracy: 0.6786 - val_loss: 2.2464 - val_accuracy: 0.1429\n",
      "Epoch 155/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4716 - accuracy: 0.7143 - val_loss: 2.0245 - val_accuracy: 0.1429\n",
      "Epoch 156/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4606 - accuracy: 0.7143 - val_loss: 1.7598 - val_accuracy: 0.4286\n",
      "Epoch 157/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4873 - accuracy: 0.6786 - val_loss: 1.6068 - val_accuracy: 0.5714\n",
      "Epoch 158/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5109 - accuracy: 0.6071 - val_loss: 1.6586 - val_accuracy: 0.4286\n",
      "Epoch 159/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4989 - accuracy: 0.6786 - val_loss: 1.7642 - val_accuracy: 0.4286\n",
      "Epoch 160/430\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4794 - accuracy: 0.6786 - val_loss: 1.9675 - val_accuracy: 0.1429\n",
      "Epoch 161/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4808 - accuracy: 0.7143 - val_loss: 2.2200 - val_accuracy: 0.1429\n",
      "Epoch 162/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4750 - accuracy: 0.7143 - val_loss: 2.2596 - val_accuracy: 0.1429\n",
      "Epoch 163/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4729 - accuracy: 0.7143 - val_loss: 2.1359 - val_accuracy: 0.1429\n",
      "Epoch 164/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4671 - accuracy: 0.7143 - val_loss: 1.9860 - val_accuracy: 0.4286\n",
      "Epoch 165/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4688 - accuracy: 0.6786 - val_loss: 1.9118 - val_accuracy: 0.4286\n",
      "Epoch 166/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5041 - accuracy: 0.6786 - val_loss: 1.9584 - val_accuracy: 0.4286\n",
      "Epoch 167/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4608 - accuracy: 0.6786 - val_loss: 2.3303 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4779 - accuracy: 0.6786 - val_loss: 2.6854 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5234 - accuracy: 0.6786 - val_loss: 2.6761 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/430\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5403 - accuracy: 0.6786 - val_loss: 2.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4882 - accuracy: 0.6786 - val_loss: 2.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4696 - accuracy: 0.6429 - val_loss: 2.0349 - val_accuracy: 0.1429\n",
      "Epoch 173/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4643 - accuracy: 0.7500 - val_loss: 1.7838 - val_accuracy: 0.4286\n",
      "Epoch 174/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5061 - accuracy: 0.6786 - val_loss: 1.7110 - val_accuracy: 0.4286\n",
      "Epoch 175/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5039 - accuracy: 0.6786 - val_loss: 1.8924 - val_accuracy: 0.4286\n",
      "Epoch 176/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4769 - accuracy: 0.6429 - val_loss: 2.0304 - val_accuracy: 0.1429\n",
      "Epoch 177/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4747 - accuracy: 0.7143 - val_loss: 2.0887 - val_accuracy: 0.1429\n",
      "Epoch 178/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4687 - accuracy: 0.7143 - val_loss: 2.0181 - val_accuracy: 0.1429\n",
      "Epoch 179/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4696 - accuracy: 0.7143 - val_loss: 1.9157 - val_accuracy: 0.4286\n",
      "Epoch 180/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4733 - accuracy: 0.6786 - val_loss: 1.9236 - val_accuracy: 0.4286\n",
      "Epoch 181/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4712 - accuracy: 0.6786 - val_loss: 2.0384 - val_accuracy: 0.1429\n",
      "Epoch 182/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.2378 - val_accuracy: 0.1429\n",
      "Epoch 183/430\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4675 - accuracy: 0.6429 - val_loss: 2.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4819 - accuracy: 0.6786 - val_loss: 2.4976 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4912 - accuracy: 0.6786 - val_loss: 2.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4862 - accuracy: 0.6429 - val_loss: 2.1960 - val_accuracy: 0.1429\n",
      "Epoch 187/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.0560 - val_accuracy: 0.1429\n",
      "Epoch 188/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4659 - accuracy: 0.7143 - val_loss: 1.9615 - val_accuracy: 0.4286\n",
      "Epoch 189/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4778 - accuracy: 0.6786 - val_loss: 1.9496 - val_accuracy: 0.4286\n",
      "Epoch 190/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4727 - accuracy: 0.7143 - val_loss: 2.0935 - val_accuracy: 0.1429\n",
      "Epoch 191/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4643 - accuracy: 0.7143 - val_loss: 2.2754 - val_accuracy: 0.1429\n",
      "Epoch 192/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4712 - accuracy: 0.6786 - val_loss: 2.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4901 - accuracy: 0.6786 - val_loss: 2.5538 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4968 - accuracy: 0.6786 - val_loss: 2.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4905 - accuracy: 0.6786 - val_loss: 2.1820 - val_accuracy: 0.1429\n",
      "Epoch 196/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4751 - accuracy: 0.7143 - val_loss: 2.0592 - val_accuracy: 0.1429\n",
      "Epoch 197/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4735 - accuracy: 0.7143 - val_loss: 2.1222 - val_accuracy: 0.1429\n",
      "Epoch 198/430\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.2916 - val_accuracy: 0.1429\n",
      "Epoch 199/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4682 - accuracy: 0.7143 - val_loss: 2.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4778 - accuracy: 0.6786 - val_loss: 2.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4877 - accuracy: 0.6786 - val_loss: 2.4638 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4853 - accuracy: 0.6071 - val_loss: 2.3628 - val_accuracy: 0.1429\n",
      "Epoch 203/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4755 - accuracy: 0.7143 - val_loss: 2.2962 - val_accuracy: 0.1429\n",
      "Epoch 204/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4714 - accuracy: 0.7143 - val_loss: 2.2897 - val_accuracy: 0.1429\n",
      "Epoch 205/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4691 - accuracy: 0.7143 - val_loss: 2.3525 - val_accuracy: 0.1429\n",
      "Epoch 206/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4716 - accuracy: 0.7143 - val_loss: 2.4131 - val_accuracy: 0.1429\n",
      "Epoch 207/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4744 - accuracy: 0.7143 - val_loss: 2.3514 - val_accuracy: 0.1429\n",
      "Epoch 208/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4696 - accuracy: 0.7143 - val_loss: 2.2898 - val_accuracy: 0.1429\n",
      "Epoch 209/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4685 - accuracy: 0.7143 - val_loss: 2.2409 - val_accuracy: 0.1429\n",
      "Epoch 210/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4741 - accuracy: 0.7143 - val_loss: 2.2899 - val_accuracy: 0.1429\n",
      "Epoch 211/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4757 - accuracy: 0.7143 - val_loss: 2.4182 - val_accuracy: 0.1429\n",
      "Epoch 212/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4767 - accuracy: 0.7143 - val_loss: 2.3723 - val_accuracy: 0.1429\n",
      "Epoch 213/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4708 - accuracy: 0.7143 - val_loss: 2.3495 - val_accuracy: 0.1429\n",
      "Epoch 214/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4729 - accuracy: 0.7143 - val_loss: 2.2357 - val_accuracy: 0.1429\n",
      "Epoch 215/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4649 - accuracy: 0.7143 - val_loss: 2.2180 - val_accuracy: 0.1429\n",
      "Epoch 216/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4653 - accuracy: 0.7143 - val_loss: 2.2018 - val_accuracy: 0.1429\n",
      "Epoch 217/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4663 - accuracy: 0.7143 - val_loss: 2.2211 - val_accuracy: 0.1429\n",
      "Epoch 218/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4653 - accuracy: 0.7143 - val_loss: 2.2008 - val_accuracy: 0.1429\n",
      "Epoch 219/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4662 - accuracy: 0.7143 - val_loss: 2.2413 - val_accuracy: 0.1429\n",
      "Epoch 220/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4762 - accuracy: 0.7143 - val_loss: 2.2469 - val_accuracy: 0.1429\n",
      "Epoch 221/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4670 - accuracy: 0.7143 - val_loss: 2.1160 - val_accuracy: 0.1429\n",
      "Epoch 222/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4699 - accuracy: 0.7143 - val_loss: 2.1047 - val_accuracy: 0.1429\n",
      "Epoch 223/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4712 - accuracy: 0.7143 - val_loss: 2.2072 - val_accuracy: 0.1429\n",
      "Epoch 224/430\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4699 - accuracy: 0.7143 - val_loss: 2.3981 - val_accuracy: 0.1429\n",
      "Epoch 225/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4669 - accuracy: 0.7143 - val_loss: 2.4662 - val_accuracy: 0.1429\n",
      "Epoch 226/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4709 - accuracy: 0.7143 - val_loss: 2.4911 - val_accuracy: 0.1429\n",
      "Epoch 227/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4740 - accuracy: 0.7143 - val_loss: 2.3894 - val_accuracy: 0.1429\n",
      "Epoch 228/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4768 - accuracy: 0.7143 - val_loss: 2.1755 - val_accuracy: 0.1429\n",
      "Epoch 229/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4684 - accuracy: 0.7143 - val_loss: 2.1654 - val_accuracy: 0.1429\n",
      "Epoch 230/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.2876 - val_accuracy: 0.1429\n",
      "Epoch 231/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4695 - accuracy: 0.7143 - val_loss: 2.4242 - val_accuracy: 0.1429\n",
      "Epoch 232/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4671 - accuracy: 0.7143 - val_loss: 2.4066 - val_accuracy: 0.1429\n",
      "Epoch 233/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4658 - accuracy: 0.7143 - val_loss: 2.3269 - val_accuracy: 0.1429\n",
      "Epoch 234/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4638 - accuracy: 0.7143 - val_loss: 2.1912 - val_accuracy: 0.1429\n",
      "Epoch 235/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.0954 - val_accuracy: 0.4286\n",
      "Epoch 236/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4718 - accuracy: 0.6786 - val_loss: 2.1060 - val_accuracy: 0.4286\n",
      "Epoch 237/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4687 - accuracy: 0.7857 - val_loss: 2.2477 - val_accuracy: 0.1429\n",
      "Epoch 238/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4709 - accuracy: 0.7143 - val_loss: 2.4286 - val_accuracy: 0.1429\n",
      "Epoch 239/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.4812 - val_accuracy: 0.1429\n",
      "Epoch 240/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4807 - accuracy: 0.7143 - val_loss: 2.5434 - val_accuracy: 0.1429\n",
      "Epoch 241/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4843 - accuracy: 0.6429 - val_loss: 2.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4834 - accuracy: 0.7500 - val_loss: 2.4515 - val_accuracy: 0.1429\n",
      "Epoch 243/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4628 - accuracy: 0.7143 - val_loss: 2.2169 - val_accuracy: 0.1429\n",
      "Epoch 244/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4611 - accuracy: 0.7500 - val_loss: 1.9768 - val_accuracy: 0.5714\n",
      "Epoch 245/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4883 - accuracy: 0.6429 - val_loss: 1.8978 - val_accuracy: 0.5714\n",
      "Epoch 246/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5004 - accuracy: 0.6071 - val_loss: 2.0202 - val_accuracy: 0.4286\n",
      "Epoch 247/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4893 - accuracy: 0.6786 - val_loss: 2.1632 - val_accuracy: 0.4286\n",
      "Epoch 248/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4709 - accuracy: 0.6071 - val_loss: 2.2549 - val_accuracy: 0.1429\n",
      "Epoch 249/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.3642 - val_accuracy: 0.1429\n",
      "Epoch 250/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4755 - accuracy: 0.7143 - val_loss: 2.5349 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4698 - accuracy: 0.6786 - val_loss: 2.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4643 - accuracy: 0.6786 - val_loss: 2.3263 - val_accuracy: 0.4286\n",
      "Epoch 253/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4679 - accuracy: 0.6786 - val_loss: 2.2045 - val_accuracy: 0.4286\n",
      "Epoch 254/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4730 - accuracy: 0.6786 - val_loss: 2.1897 - val_accuracy: 0.4286\n",
      "Epoch 255/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4746 - accuracy: 0.6786 - val_loss: 2.2314 - val_accuracy: 0.4286\n",
      "Epoch 256/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4683 - accuracy: 0.6786 - val_loss: 2.3977 - val_accuracy: 0.1429\n",
      "Epoch 257/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4649 - accuracy: 0.6786 - val_loss: 2.6213 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4790 - accuracy: 0.6786 - val_loss: 2.6549 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4782 - accuracy: 0.7143 - val_loss: 2.5206 - val_accuracy: 0.1429\n",
      "Epoch 260/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4725 - accuracy: 0.7143 - val_loss: 2.3867 - val_accuracy: 0.1429\n",
      "Epoch 261/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4630 - accuracy: 0.7143 - val_loss: 2.3198 - val_accuracy: 0.1429\n",
      "Epoch 262/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4630 - accuracy: 0.7143 - val_loss: 2.2394 - val_accuracy: 0.1429\n",
      "Epoch 263/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4657 - accuracy: 0.7143 - val_loss: 2.2197 - val_accuracy: 0.1429\n",
      "Epoch 264/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4679 - accuracy: 0.6429 - val_loss: 2.2696 - val_accuracy: 0.1429\n",
      "Epoch 265/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4642 - accuracy: 0.7143 - val_loss: 2.4120 - val_accuracy: 0.1429\n",
      "Epoch 266/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.5094 - val_accuracy: 0.1429\n",
      "Epoch 267/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4724 - accuracy: 0.7143 - val_loss: 2.4589 - val_accuracy: 0.1429\n",
      "Epoch 268/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4656 - accuracy: 0.7143 - val_loss: 2.2557 - val_accuracy: 0.1429\n",
      "Epoch 269/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4707 - accuracy: 0.6786 - val_loss: 2.1767 - val_accuracy: 0.4286\n",
      "Epoch 270/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4726 - accuracy: 0.6786 - val_loss: 2.2950 - val_accuracy: 0.1429\n",
      "Epoch 271/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4731 - accuracy: 0.7143 - val_loss: 2.5100 - val_accuracy: 0.1429\n",
      "Epoch 272/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4662 - accuracy: 0.7143 - val_loss: 2.5658 - val_accuracy: 0.1429\n",
      "Epoch 273/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4703 - accuracy: 0.7143 - val_loss: 2.5994 - val_accuracy: 0.1429\n",
      "Epoch 274/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4717 - accuracy: 0.7143 - val_loss: 2.5968 - val_accuracy: 0.1429\n",
      "Epoch 275/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4696 - accuracy: 0.7143 - val_loss: 2.4528 - val_accuracy: 0.1429\n",
      "Epoch 276/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4629 - accuracy: 0.7143 - val_loss: 2.3063 - val_accuracy: 0.1429\n",
      "Epoch 277/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4645 - accuracy: 0.7143 - val_loss: 2.2378 - val_accuracy: 0.4286\n",
      "Epoch 278/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4693 - accuracy: 0.6786 - val_loss: 2.2525 - val_accuracy: 0.4286\n",
      "Epoch 279/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4689 - accuracy: 0.6429 - val_loss: 2.3674 - val_accuracy: 0.1429\n",
      "Epoch 280/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4633 - accuracy: 0.7143 - val_loss: 2.4756 - val_accuracy: 0.1429\n",
      "Epoch 281/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4683 - accuracy: 0.7143 - val_loss: 2.5375 - val_accuracy: 0.1429\n",
      "Epoch 282/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.4501 - val_accuracy: 0.1429\n",
      "Epoch 283/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4624 - accuracy: 0.7143 - val_loss: 2.3356 - val_accuracy: 0.1429\n",
      "Epoch 284/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4704 - accuracy: 0.6071 - val_loss: 2.3284 - val_accuracy: 0.1429\n",
      "Epoch 285/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4617 - accuracy: 0.7143 - val_loss: 2.4941 - val_accuracy: 0.1429\n",
      "Epoch 286/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4617 - accuracy: 0.7143 - val_loss: 2.6830 - val_accuracy: 0.1429\n",
      "Epoch 287/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4746 - accuracy: 0.7143 - val_loss: 2.7849 - val_accuracy: 0.1429\n",
      "Epoch 288/430\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4872 - accuracy: 0.7143 - val_loss: 2.6885 - val_accuracy: 0.1429\n",
      "Epoch 289/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4751 - accuracy: 0.7143 - val_loss: 2.4284 - val_accuracy: 0.1429\n",
      "Epoch 290/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4646 - accuracy: 0.7143 - val_loss: 2.2126 - val_accuracy: 0.1429\n",
      "Epoch 291/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4776 - accuracy: 0.6429 - val_loss: 2.1722 - val_accuracy: 0.4286\n",
      "Epoch 292/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4849 - accuracy: 0.5714 - val_loss: 2.2924 - val_accuracy: 0.1429\n",
      "Epoch 293/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4650 - accuracy: 0.7143 - val_loss: 2.3223 - val_accuracy: 0.1429\n",
      "Epoch 294/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 2.4348 - val_accuracy: 0.1429\n",
      "Epoch 295/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4645 - accuracy: 0.7143 - val_loss: 2.5735 - val_accuracy: 0.1429\n",
      "Epoch 296/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4700 - accuracy: 0.7143 - val_loss: 2.5706 - val_accuracy: 0.1429\n",
      "Epoch 297/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4720 - accuracy: 0.7143 - val_loss: 2.4512 - val_accuracy: 0.1429\n",
      "Epoch 298/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4627 - accuracy: 0.7143 - val_loss: 2.3925 - val_accuracy: 0.1429\n",
      "Epoch 299/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.3637 - val_accuracy: 0.1429\n",
      "Epoch 300/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4702 - accuracy: 0.7143 - val_loss: 2.4128 - val_accuracy: 0.1429\n",
      "Epoch 301/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4618 - accuracy: 0.7143 - val_loss: 2.3471 - val_accuracy: 0.1429\n",
      "Epoch 302/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4665 - accuracy: 0.6786 - val_loss: 2.3485 - val_accuracy: 0.1429\n",
      "Epoch 303/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4705 - accuracy: 0.7143 - val_loss: 2.4225 - val_accuracy: 0.1429\n",
      "Epoch 304/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.3593 - val_accuracy: 0.4286\n",
      "Epoch 305/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4619 - accuracy: 0.6786 - val_loss: 2.2007 - val_accuracy: 0.4286\n",
      "Epoch 306/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4759 - accuracy: 0.6786 - val_loss: 2.1113 - val_accuracy: 0.4286\n",
      "Epoch 307/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4893 - accuracy: 0.6786 - val_loss: 2.1832 - val_accuracy: 0.4286\n",
      "Epoch 308/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4738 - accuracy: 0.6786 - val_loss: 2.4460 - val_accuracy: 0.1429\n",
      "Epoch 309/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4557 - accuracy: 0.7143 - val_loss: 2.7363 - val_accuracy: 0.1429\n",
      "Epoch 310/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4733 - accuracy: 0.7500 - val_loss: 2.9562 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5064 - accuracy: 0.6786 - val_loss: 2.8725 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4896 - accuracy: 0.6786 - val_loss: 2.5235 - val_accuracy: 0.1429\n",
      "Epoch 313/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4775 - accuracy: 0.7143 - val_loss: 2.2676 - val_accuracy: 0.4286\n",
      "Epoch 314/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4701 - accuracy: 0.6786 - val_loss: 2.2584 - val_accuracy: 0.4286\n",
      "Epoch 315/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4684 - accuracy: 0.6429 - val_loss: 2.3728 - val_accuracy: 0.1429\n",
      "Epoch 316/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4682 - accuracy: 0.7143 - val_loss: 2.4280 - val_accuracy: 0.1429\n",
      "Epoch 317/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4646 - accuracy: 0.7143 - val_loss: 2.3999 - val_accuracy: 0.1429\n",
      "Epoch 318/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4629 - accuracy: 0.7143 - val_loss: 2.4528 - val_accuracy: 0.1429\n",
      "Epoch 319/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4621 - accuracy: 0.7143 - val_loss: 2.5469 - val_accuracy: 0.1429\n",
      "Epoch 320/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4654 - accuracy: 0.7143 - val_loss: 2.6114 - val_accuracy: 0.1429\n",
      "Epoch 321/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4693 - accuracy: 0.7143 - val_loss: 2.5728 - val_accuracy: 0.1429\n",
      "Epoch 322/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4651 - accuracy: 0.7143 - val_loss: 2.4343 - val_accuracy: 0.1429\n",
      "Epoch 323/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4629 - accuracy: 0.7143 - val_loss: 2.3350 - val_accuracy: 0.1429\n",
      "Epoch 324/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 2.3506 - val_accuracy: 0.1429\n",
      "Epoch 325/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4733 - accuracy: 0.7143 - val_loss: 2.4569 - val_accuracy: 0.1429\n",
      "Epoch 326/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4631 - accuracy: 0.7143 - val_loss: 2.4227 - val_accuracy: 0.1429\n",
      "Epoch 327/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4646 - accuracy: 0.6786 - val_loss: 2.3825 - val_accuracy: 0.4286\n",
      "Epoch 328/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4656 - accuracy: 0.6786 - val_loss: 2.4177 - val_accuracy: 0.1429\n",
      "Epoch 329/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4647 - accuracy: 0.7143 - val_loss: 2.4493 - val_accuracy: 0.1429\n",
      "Epoch 330/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4630 - accuracy: 0.7143 - val_loss: 2.4976 - val_accuracy: 0.1429\n",
      "Epoch 331/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4626 - accuracy: 0.7143 - val_loss: 2.5544 - val_accuracy: 0.1429\n",
      "Epoch 332/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.6047 - val_accuracy: 0.1429\n",
      "Epoch 333/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4675 - accuracy: 0.7143 - val_loss: 2.5952 - val_accuracy: 0.1429\n",
      "Epoch 334/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4659 - accuracy: 0.7143 - val_loss: 2.6193 - val_accuracy: 0.1429\n",
      "Epoch 335/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.5444 - val_accuracy: 0.1429\n",
      "Epoch 336/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 2.4852 - val_accuracy: 0.1429\n",
      "Epoch 337/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4673 - accuracy: 0.6429 - val_loss: 2.5208 - val_accuracy: 0.1429\n",
      "Epoch 338/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4609 - accuracy: 0.7143 - val_loss: 2.6926 - val_accuracy: 0.1429\n",
      "Epoch 339/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4654 - accuracy: 0.7143 - val_loss: 2.8417 - val_accuracy: 0.1429\n",
      "Epoch 340/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4803 - accuracy: 0.7143 - val_loss: 2.8072 - val_accuracy: 0.1429\n",
      "Epoch 341/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4734 - accuracy: 0.7143 - val_loss: 2.6079 - val_accuracy: 0.1429\n",
      "Epoch 342/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4666 - accuracy: 0.7143 - val_loss: 2.4518 - val_accuracy: 0.4286\n",
      "Epoch 343/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4666 - accuracy: 0.6786 - val_loss: 2.4435 - val_accuracy: 0.4286\n",
      "Epoch 344/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4650 - accuracy: 0.6429 - val_loss: 2.5429 - val_accuracy: 0.1429\n",
      "Epoch 345/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4665 - accuracy: 0.7143 - val_loss: 2.6548 - val_accuracy: 0.1429\n",
      "Epoch 346/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4690 - accuracy: 0.7143 - val_loss: 2.6152 - val_accuracy: 0.1429\n",
      "Epoch 347/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4645 - accuracy: 0.7143 - val_loss: 2.4503 - val_accuracy: 0.4286\n",
      "Epoch 348/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4650 - accuracy: 0.6786 - val_loss: 2.3907 - val_accuracy: 0.4286\n",
      "Epoch 349/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4757 - accuracy: 0.6786 - val_loss: 2.4763 - val_accuracy: 0.1429\n",
      "Epoch 350/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4549 - accuracy: 0.7143 - val_loss: 2.7859 - val_accuracy: 0.1429\n",
      "Epoch 351/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4734 - accuracy: 0.7143 - val_loss: 3.0279 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5077 - accuracy: 0.6786 - val_loss: 2.9771 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4956 - accuracy: 0.6786 - val_loss: 2.6680 - val_accuracy: 0.1429\n",
      "Epoch 354/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4468 - accuracy: 0.7143 - val_loss: 2.1607 - val_accuracy: 0.4286\n",
      "Epoch 355/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4736 - accuracy: 0.7143 - val_loss: 1.7629 - val_accuracy: 0.5714\n",
      "Epoch 356/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5535 - accuracy: 0.6429 - val_loss: 1.6889 - val_accuracy: 0.5714\n",
      "Epoch 357/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5551 - accuracy: 0.6429 - val_loss: 1.9214 - val_accuracy: 0.5714\n",
      "Epoch 358/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5065 - accuracy: 0.6071 - val_loss: 2.3534 - val_accuracy: 0.1429\n",
      "Epoch 359/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4761 - accuracy: 0.7143 - val_loss: 2.6158 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4802 - accuracy: 0.6786 - val_loss: 2.6551 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4892 - accuracy: 0.6786 - val_loss: 2.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4836 - accuracy: 0.6786 - val_loss: 2.3924 - val_accuracy: 0.1429\n",
      "Epoch 363/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 2.1916 - val_accuracy: 0.1429\n",
      "Epoch 364/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4728 - accuracy: 0.7143 - val_loss: 2.0665 - val_accuracy: 0.4286\n",
      "Epoch 365/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4749 - accuracy: 0.5357 - val_loss: 2.0703 - val_accuracy: 0.4286\n",
      "Epoch 366/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4710 - accuracy: 0.6786 - val_loss: 2.0611 - val_accuracy: 0.4286\n",
      "Epoch 367/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4736 - accuracy: 0.6786 - val_loss: 2.1296 - val_accuracy: 0.4286\n",
      "Epoch 368/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4676 - accuracy: 0.6786 - val_loss: 2.2416 - val_accuracy: 0.1429\n",
      "Epoch 369/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4616 - accuracy: 0.7143 - val_loss: 2.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4740 - accuracy: 0.6786 - val_loss: 2.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4800 - accuracy: 0.6786 - val_loss: 2.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4775 - accuracy: 0.6786 - val_loss: 2.4415 - val_accuracy: 0.1429\n",
      "Epoch 373/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4772 - accuracy: 0.7143 - val_loss: 2.3698 - val_accuracy: 0.1429\n",
      "Epoch 374/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.3608 - val_accuracy: 0.1429\n",
      "Epoch 375/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4674 - accuracy: 0.7143 - val_loss: 2.2754 - val_accuracy: 0.1429\n",
      "Epoch 376/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4678 - accuracy: 0.7143 - val_loss: 2.2057 - val_accuracy: 0.1429\n",
      "Epoch 377/430\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.4615 - accuracy: 0.7143 - val_loss: 2.0504 - val_accuracy: 0.4286\n",
      "Epoch 378/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4812 - accuracy: 0.6786 - val_loss: 1.9713 - val_accuracy: 0.4286\n",
      "Epoch 379/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4822 - accuracy: 0.6786 - val_loss: 2.0967 - val_accuracy: 0.4286\n",
      "Epoch 380/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4669 - accuracy: 0.6786 - val_loss: 2.3218 - val_accuracy: 0.1429\n",
      "Epoch 381/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4789 - accuracy: 0.7143 - val_loss: 2.5305 - val_accuracy: 0.1429\n",
      "Epoch 382/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4722 - accuracy: 0.7143 - val_loss: 2.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4758 - accuracy: 0.6429 - val_loss: 2.5030 - val_accuracy: 0.1429\n",
      "Epoch 384/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4697 - accuracy: 0.7143 - val_loss: 2.4892 - val_accuracy: 0.1429\n",
      "Epoch 385/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4676 - accuracy: 0.7143 - val_loss: 2.3909 - val_accuracy: 0.1429\n",
      "Epoch 386/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4637 - accuracy: 0.7143 - val_loss: 2.2903 - val_accuracy: 0.1429\n",
      "Epoch 387/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4708 - accuracy: 0.6071 - val_loss: 2.2297 - val_accuracy: 0.4286\n",
      "Epoch 388/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4668 - accuracy: 0.6786 - val_loss: 2.2974 - val_accuracy: 0.1429\n",
      "Epoch 389/430\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4692 - accuracy: 0.7143 - val_loss: 2.3841 - val_accuracy: 0.1429\n",
      "Epoch 390/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4666 - accuracy: 0.7143 - val_loss: 2.4175 - val_accuracy: 0.1429\n",
      "Epoch 391/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4687 - accuracy: 0.7500 - val_loss: 2.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4692 - accuracy: 0.7143 - val_loss: 2.4392 - val_accuracy: 0.1429\n",
      "Epoch 393/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4702 - accuracy: 0.6429 - val_loss: 2.3862 - val_accuracy: 0.1429\n",
      "Epoch 394/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4617 - accuracy: 0.7143 - val_loss: 2.2160 - val_accuracy: 0.4286\n",
      "Epoch 395/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4860 - accuracy: 0.6786 - val_loss: 2.1500 - val_accuracy: 0.4286\n",
      "Epoch 396/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4776 - accuracy: 0.6429 - val_loss: 2.2885 - val_accuracy: 0.1429\n",
      "Epoch 397/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 2.3640 - val_accuracy: 0.1429\n",
      "Epoch 398/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4678 - accuracy: 0.7143 - val_loss: 2.4131 - val_accuracy: 0.1429\n",
      "Epoch 399/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4639 - accuracy: 0.7143 - val_loss: 2.3657 - val_accuracy: 0.1429\n",
      "Epoch 400/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4611 - accuracy: 0.7143 - val_loss: 2.2604 - val_accuracy: 0.1429\n",
      "Epoch 401/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4777 - accuracy: 0.6071 - val_loss: 2.2263 - val_accuracy: 0.4286\n",
      "Epoch 402/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4717 - accuracy: 0.6429 - val_loss: 2.3618 - val_accuracy: 0.1429\n",
      "Epoch 403/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4632 - accuracy: 0.7143 - val_loss: 2.4352 - val_accuracy: 0.1429\n",
      "Epoch 404/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4692 - accuracy: 0.7143 - val_loss: 2.5281 - val_accuracy: 0.1429\n",
      "Epoch 405/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4718 - accuracy: 0.7143 - val_loss: 2.6902 - val_accuracy: 0.1429\n",
      "Epoch 406/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4836 - accuracy: 0.7143 - val_loss: 2.5844 - val_accuracy: 0.1429\n",
      "Epoch 407/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4669 - accuracy: 0.7143 - val_loss: 2.3054 - val_accuracy: 0.1429\n",
      "Epoch 408/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4593 - accuracy: 0.7143 - val_loss: 2.0992 - val_accuracy: 0.4286\n",
      "Epoch 409/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4874 - accuracy: 0.6786 - val_loss: 1.9744 - val_accuracy: 0.4286\n",
      "Epoch 410/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4966 - accuracy: 0.6786 - val_loss: 2.0875 - val_accuracy: 0.4286\n",
      "Epoch 411/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4874 - accuracy: 0.6786 - val_loss: 2.2967 - val_accuracy: 0.1429\n",
      "Epoch 412/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4640 - accuracy: 0.7143 - val_loss: 2.4550 - val_accuracy: 0.1429\n",
      "Epoch 413/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4677 - accuracy: 0.7143 - val_loss: 2.5715 - val_accuracy: 0.1429\n",
      "Epoch 414/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.5541 - val_accuracy: 0.1429\n",
      "Epoch 415/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4670 - accuracy: 0.7143 - val_loss: 2.5016 - val_accuracy: 0.1429\n",
      "Epoch 416/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4656 - accuracy: 0.7143 - val_loss: 2.4154 - val_accuracy: 0.1429\n",
      "Epoch 417/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4630 - accuracy: 0.7143 - val_loss: 2.3482 - val_accuracy: 0.1429\n",
      "Epoch 418/430\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4631 - accuracy: 0.7143 - val_loss: 2.2800 - val_accuracy: 0.4286\n",
      "Epoch 419/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4691 - accuracy: 0.6786 - val_loss: 2.2509 - val_accuracy: 0.4286\n",
      "Epoch 420/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4645 - accuracy: 0.7857 - val_loss: 2.3673 - val_accuracy: 0.1429\n",
      "Epoch 421/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4569 - accuracy: 0.7143 - val_loss: 2.5791 - val_accuracy: 0.1429\n",
      "Epoch 422/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4721 - accuracy: 0.7143 - val_loss: 2.7736 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4961 - accuracy: 0.6786 - val_loss: 2.8022 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4979 - accuracy: 0.6786 - val_loss: 2.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4883 - accuracy: 0.6786 - val_loss: 2.5733 - val_accuracy: 0.1429\n",
      "Epoch 426/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4680 - accuracy: 0.7143 - val_loss: 2.3187 - val_accuracy: 0.1429\n",
      "Epoch 427/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4663 - accuracy: 0.7143 - val_loss: 2.1411 - val_accuracy: 0.4286\n",
      "Epoch 428/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4729 - accuracy: 0.6786 - val_loss: 2.1072 - val_accuracy: 0.4286\n",
      "Epoch 429/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4768 - accuracy: 0.6786 - val_loss: 2.1520 - val_accuracy: 0.4286\n",
      "Epoch 430/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4716 - accuracy: 0.6786 - val_loss: 2.3072 - val_accuracy: 0.1429\n",
      "INFO:tensorflow:Assets written to: ram://9b649201-afac-4ba8-9c4b-acd7af8a1632/assets\n",
      "Epoch 1/430\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.6820 - accuracy: 0.6071 - val_loss: 0.9861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6522 - accuracy: 0.6429 - val_loss: 1.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6310 - accuracy: 0.6429 - val_loss: 1.0444 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6149 - accuracy: 0.6429 - val_loss: 1.0252 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5900 - accuracy: 0.7143 - val_loss: 1.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6073 - accuracy: 0.6429 - val_loss: 1.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5836 - accuracy: 0.6429 - val_loss: 1.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5893 - accuracy: 0.6429 - val_loss: 1.3167 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5924 - accuracy: 0.6429 - val_loss: 1.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/430\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5888 - accuracy: 0.6429 - val_loss: 1.2155 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 1.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5693 - accuracy: 0.7500 - val_loss: 1.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5762 - accuracy: 0.7143 - val_loss: 1.5504 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6019 - accuracy: 0.7143 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6287 - accuracy: 0.6786 - val_loss: 1.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/430\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5854 - accuracy: 0.7143 - val_loss: 1.1572 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5730 - accuracy: 0.6786 - val_loss: 1.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5693 - accuracy: 0.6786 - val_loss: 1.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5862 - accuracy: 0.6786 - val_loss: 1.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5557 - accuracy: 0.6786 - val_loss: 1.2455 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5780 - accuracy: 0.6429 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5773 - accuracy: 0.6429 - val_loss: 1.2685 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5505 - accuracy: 0.6429 - val_loss: 1.0977 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5500 - accuracy: 0.6786 - val_loss: 0.9666 - val_accuracy: 0.7143\n",
      "Epoch 25/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5586 - accuracy: 0.6071 - val_loss: 1.0161 - val_accuracy: 0.7143\n",
      "Epoch 26/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5776 - accuracy: 0.6071 - val_loss: 1.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6688 - accuracy: 0.6071 - val_loss: 1.2738 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7943 - accuracy: 0.6429 - val_loss: 1.4222 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8407 - accuracy: 0.5000 - val_loss: 1.1986 - val_accuracy: 0.2857\n",
      "Epoch 30/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7513 - accuracy: 0.5000 - val_loss: 1.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7064 - accuracy: 0.5357 - val_loss: 1.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6769 - accuracy: 0.5714 - val_loss: 1.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6479 - accuracy: 0.6071 - val_loss: 1.2328 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6398 - accuracy: 0.6429 - val_loss: 1.3365 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6451 - accuracy: 0.6429 - val_loss: 1.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6778 - accuracy: 0.6429 - val_loss: 1.2596 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6416 - accuracy: 0.6429 - val_loss: 1.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6159 - accuracy: 0.6429 - val_loss: 1.1996 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/430\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6459 - accuracy: 0.5714 - val_loss: 1.0923 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6415 - accuracy: 0.6429 - val_loss: 0.9846 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6416 - accuracy: 0.6429 - val_loss: 1.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6225 - accuracy: 0.6429 - val_loss: 1.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6254 - accuracy: 0.6429 - val_loss: 1.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6460 - accuracy: 0.6429 - val_loss: 1.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6198 - accuracy: 0.6429 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6107 - accuracy: 0.6429 - val_loss: 1.0476 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6217 - accuracy: 0.6429 - val_loss: 1.0209 - val_accuracy: 0.1429\n",
      "Epoch 48/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6336 - accuracy: 0.6071 - val_loss: 1.0060 - val_accuracy: 0.1429\n",
      "Epoch 49/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6302 - accuracy: 0.6071 - val_loss: 1.1879 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6340 - accuracy: 0.6429 - val_loss: 1.3647 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6546 - accuracy: 0.6429 - val_loss: 1.3161 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6390 - accuracy: 0.6429 - val_loss: 1.3310 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6359 - accuracy: 0.6429 - val_loss: 1.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/430\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6181 - accuracy: 0.6429 - val_loss: 0.9650 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6299 - accuracy: 0.6429 - val_loss: 0.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6397 - accuracy: 0.6071 - val_loss: 0.8177 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6434 - accuracy: 0.5714 - val_loss: 0.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6185 - accuracy: 0.6429 - val_loss: 1.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6017 - accuracy: 0.6429 - val_loss: 1.3675 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6274 - accuracy: 0.6429 - val_loss: 1.4940 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6142 - accuracy: 0.6429 - val_loss: 1.6081 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7047 - accuracy: 0.6429 - val_loss: 1.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6612 - accuracy: 0.6429 - val_loss: 0.8733 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6379 - accuracy: 0.6429 - val_loss: 0.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6570 - accuracy: 0.6429 - val_loss: 0.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6714 - accuracy: 0.6071 - val_loss: 0.7888 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/430\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6545 - accuracy: 0.6429 - val_loss: 0.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6413 - accuracy: 0.6429 - val_loss: 1.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6470 - accuracy: 0.6429 - val_loss: 1.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6499 - accuracy: 0.6429 - val_loss: 1.1461 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6390 - accuracy: 0.6429 - val_loss: 1.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6493 - accuracy: 0.6429 - val_loss: 0.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6359 - accuracy: 0.6429 - val_loss: 1.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7205 - accuracy: 0.6429 - val_loss: 1.2034 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6850 - accuracy: 0.6429 - val_loss: 1.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6480 - accuracy: 0.6429 - val_loss: 0.7965 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6781 - accuracy: 0.6429 - val_loss: 0.7480 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6890 - accuracy: 0.6429 - val_loss: 0.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6575 - accuracy: 0.6429 - val_loss: 0.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6469 - accuracy: 0.6429 - val_loss: 1.0496 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6390 - accuracy: 0.6429 - val_loss: 1.1683 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6448 - accuracy: 0.6429 - val_loss: 1.2540 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6492 - accuracy: 0.6429 - val_loss: 1.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6461 - accuracy: 0.6429 - val_loss: 1.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6435 - accuracy: 0.6429 - val_loss: 1.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6389 - accuracy: 0.6429 - val_loss: 1.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6396 - accuracy: 0.6429 - val_loss: 0.9892 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6400 - accuracy: 0.6429 - val_loss: 1.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6408 - accuracy: 0.6429 - val_loss: 1.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6377 - accuracy: 0.6429 - val_loss: 1.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6387 - accuracy: 0.6429 - val_loss: 1.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6375 - accuracy: 0.6429 - val_loss: 0.9877 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6523 - accuracy: 0.6429 - val_loss: 0.9866 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6343 - accuracy: 0.6429 - val_loss: 1.1602 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6354 - accuracy: 0.6429 - val_loss: 1.3346 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6572 - accuracy: 0.6429 - val_loss: 1.3678 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6509 - accuracy: 0.6429 - val_loss: 1.1904 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 1.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6509 - accuracy: 0.6429 - val_loss: 0.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6455 - accuracy: 0.6429 - val_loss: 0.9843 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6383 - accuracy: 0.6429 - val_loss: 1.0575 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6321 - accuracy: 0.6429 - val_loss: 1.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 1.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6481 - accuracy: 0.6429 - val_loss: 1.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6544 - accuracy: 0.6429 - val_loss: 1.3124 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6470 - accuracy: 0.6429 - val_loss: 1.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 1.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 0.9542 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6442 - accuracy: 0.6429 - val_loss: 0.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6411 - accuracy: 0.6429 - val_loss: 1.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6319 - accuracy: 0.6429 - val_loss: 1.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/430\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6399 - accuracy: 0.6429 - val_loss: 1.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6409 - accuracy: 0.6429 - val_loss: 1.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6394 - accuracy: 0.6429 - val_loss: 1.0868 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6308 - accuracy: 0.6429 - val_loss: 1.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.9717 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6364 - accuracy: 0.6429 - val_loss: 1.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6299 - accuracy: 0.6429 - val_loss: 1.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6383 - accuracy: 0.6429 - val_loss: 1.2972 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6408 - accuracy: 0.6429 - val_loss: 1.2875 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6396 - accuracy: 0.6429 - val_loss: 1.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6329 - accuracy: 0.6429 - val_loss: 1.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6407 - accuracy: 0.6429 - val_loss: 1.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6340 - accuracy: 0.6429 - val_loss: 1.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6305 - accuracy: 0.6429 - val_loss: 1.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6299 - accuracy: 0.6429 - val_loss: 1.1068 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6290 - accuracy: 0.6429 - val_loss: 1.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/430\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6285 - accuracy: 0.6429 - val_loss: 1.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6291 - accuracy: 0.6429 - val_loss: 1.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6358 - accuracy: 0.6429 - val_loss: 1.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6391 - accuracy: 0.6429 - val_loss: 1.0990 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6325 - accuracy: 0.6429 - val_loss: 1.1572 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6273 - accuracy: 0.6429 - val_loss: 1.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6286 - accuracy: 0.6429 - val_loss: 1.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6269 - accuracy: 0.6429 - val_loss: 1.0301 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6303 - accuracy: 0.6429 - val_loss: 0.9475 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6427 - accuracy: 0.6429 - val_loss: 0.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6475 - accuracy: 0.6429 - val_loss: 0.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6405 - accuracy: 0.6429 - val_loss: 1.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6552 - accuracy: 0.6429 - val_loss: 1.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6333 - accuracy: 0.6429 - val_loss: 1.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6341 - accuracy: 0.6429 - val_loss: 1.2818 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6295 - accuracy: 0.6429 - val_loss: 1.2908 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6389 - accuracy: 0.6429 - val_loss: 1.2479 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.0606 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6359 - accuracy: 0.6429 - val_loss: 0.9932 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6344 - accuracy: 0.6429 - val_loss: 1.0777 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6300 - accuracy: 0.6429 - val_loss: 1.3616 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6370 - accuracy: 0.6429 - val_loss: 1.3345 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/430\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6322 - accuracy: 0.6429 - val_loss: 1.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6428 - accuracy: 0.6429 - val_loss: 1.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6261 - accuracy: 0.6429 - val_loss: 1.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6251 - accuracy: 0.6429 - val_loss: 1.3057 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6291 - accuracy: 0.6429 - val_loss: 1.3664 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6359 - accuracy: 0.6429 - val_loss: 1.3286 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6414 - accuracy: 0.6429 - val_loss: 1.2011 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6346 - accuracy: 0.6429 - val_loss: 1.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6238 - accuracy: 0.6429 - val_loss: 1.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6312 - accuracy: 0.6429 - val_loss: 1.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6399 - accuracy: 0.6429 - val_loss: 1.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6384 - accuracy: 0.6429 - val_loss: 1.3852 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6308 - accuracy: 0.6429 - val_loss: 1.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/430\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6319 - accuracy: 0.6429 - val_loss: 0.9906 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6372 - accuracy: 0.6429 - val_loss: 0.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6431 - accuracy: 0.6429 - val_loss: 1.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6336 - accuracy: 0.6429 - val_loss: 1.1845 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6226 - accuracy: 0.6429 - val_loss: 1.3402 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6321 - accuracy: 0.6429 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6415 - accuracy: 0.6429 - val_loss: 1.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6236 - accuracy: 0.6429 - val_loss: 1.1117 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6294 - accuracy: 0.6429 - val_loss: 0.9391 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/430\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6490 - accuracy: 0.6429 - val_loss: 0.9317 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6399 - accuracy: 0.6429 - val_loss: 1.0932 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6289 - accuracy: 0.6429 - val_loss: 1.3195 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6277 - accuracy: 0.6429 - val_loss: 1.4578 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6422 - accuracy: 0.6429 - val_loss: 1.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6415 - accuracy: 0.6429 - val_loss: 1.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6295 - accuracy: 0.6429 - val_loss: 1.1852 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6259 - accuracy: 0.6429 - val_loss: 1.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6445 - accuracy: 0.6429 - val_loss: 1.0274 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6280 - accuracy: 0.6429 - val_loss: 1.1837 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6321 - accuracy: 0.6429 - val_loss: 1.3469 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6308 - accuracy: 0.6429 - val_loss: 1.3878 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6406 - accuracy: 0.6429 - val_loss: 1.4066 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6356 - accuracy: 0.6429 - val_loss: 1.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6432 - accuracy: 0.6429 - val_loss: 1.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6339 - accuracy: 0.6429 - val_loss: 1.2486 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/430\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6258 - accuracy: 0.6429 - val_loss: 1.0913 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6301 - accuracy: 0.6429 - val_loss: 1.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6358 - accuracy: 0.6429 - val_loss: 1.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6382 - accuracy: 0.6429 - val_loss: 1.0298 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6347 - accuracy: 0.6429 - val_loss: 1.1550 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6237 - accuracy: 0.6429 - val_loss: 1.2526 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6310 - accuracy: 0.6429 - val_loss: 1.3241 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/430\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6280 - accuracy: 0.6429 - val_loss: 1.2815 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6277 - accuracy: 0.6429 - val_loss: 1.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6243 - accuracy: 0.6429 - val_loss: 1.1801 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6246 - accuracy: 0.6429 - val_loss: 1.1534 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6254 - accuracy: 0.6429 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6254 - accuracy: 0.6429 - val_loss: 1.1275 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6281 - accuracy: 0.6429 - val_loss: 1.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6212 - accuracy: 0.6429 - val_loss: 1.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6275 - accuracy: 0.6429 - val_loss: 1.4603 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6380 - accuracy: 0.6429 - val_loss: 1.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6364 - accuracy: 0.6429 - val_loss: 1.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/430\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6244 - accuracy: 0.6429 - val_loss: 1.1913 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 0.9965 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6441 - accuracy: 0.6429 - val_loss: 0.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6428 - accuracy: 0.6429 - val_loss: 1.0507 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6252 - accuracy: 0.6429 - val_loss: 1.2370 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6190 - accuracy: 0.6429 - val_loss: 1.5118 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6654 - accuracy: 0.6429 - val_loss: 1.6184 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6552 - accuracy: 0.6429 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 1.1832 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6155 - accuracy: 0.6429 - val_loss: 0.9377 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6487 - accuracy: 0.5714 - val_loss: 0.7924 - val_accuracy: 0.8571\n",
      "Epoch 219/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6744 - accuracy: 0.4286 - val_loss: 0.8008 - val_accuracy: 0.8571\n",
      "Epoch 220/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6707 - accuracy: 0.4286 - val_loss: 0.8970 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6600 - accuracy: 0.6429 - val_loss: 1.1217 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6333 - accuracy: 0.6429 - val_loss: 1.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6296 - accuracy: 0.6429 - val_loss: 1.3172 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6307 - accuracy: 0.6429 - val_loss: 1.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6299 - accuracy: 0.6429 - val_loss: 1.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6235 - accuracy: 0.6429 - val_loss: 1.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6313 - accuracy: 0.6429 - val_loss: 1.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6345 - accuracy: 0.6429 - val_loss: 0.9985 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6342 - accuracy: 0.6429 - val_loss: 1.0575 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6297 - accuracy: 0.6429 - val_loss: 1.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6262 - accuracy: 0.6429 - val_loss: 1.2615 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6265 - accuracy: 0.6429 - val_loss: 1.3255 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6286 - accuracy: 0.6429 - val_loss: 1.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6388 - accuracy: 0.6429 - val_loss: 1.3758 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6312 - accuracy: 0.6429 - val_loss: 1.2950 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6294 - accuracy: 0.6429 - val_loss: 1.1779 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6269 - accuracy: 0.6429 - val_loss: 1.1192 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6275 - accuracy: 0.6429 - val_loss: 1.1261 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.1927 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6246 - accuracy: 0.6429 - val_loss: 1.2807 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/430\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6287 - accuracy: 0.6429 - val_loss: 1.3189 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6272 - accuracy: 0.6429 - val_loss: 1.2788 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6246 - accuracy: 0.6429 - val_loss: 1.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6350 - accuracy: 0.6429 - val_loss: 1.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6252 - accuracy: 0.6429 - val_loss: 1.1949 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.3335 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6282 - accuracy: 0.6429 - val_loss: 1.3639 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6294 - accuracy: 0.6429 - val_loss: 1.3355 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/430\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6244 - accuracy: 0.6429 - val_loss: 1.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.1704 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6242 - accuracy: 0.6429 - val_loss: 1.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 1.1247 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6252 - accuracy: 0.6429 - val_loss: 1.0483 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6327 - accuracy: 0.6429 - val_loss: 1.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6420 - accuracy: 0.6429 - val_loss: 1.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6312 - accuracy: 0.6429 - val_loss: 1.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6207 - accuracy: 0.6429 - val_loss: 1.3896 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.5097 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6436 - accuracy: 0.6429 - val_loss: 1.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6364 - accuracy: 0.6429 - val_loss: 1.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6218 - accuracy: 0.6429 - val_loss: 1.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6304 - accuracy: 0.6429 - val_loss: 1.0316 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6358 - accuracy: 0.6429 - val_loss: 1.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.4013 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6323 - accuracy: 0.6429 - val_loss: 1.4940 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6409 - accuracy: 0.6429 - val_loss: 1.4848 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6378 - accuracy: 0.6429 - val_loss: 1.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/430\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6365 - accuracy: 0.6429 - val_loss: 1.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6221 - accuracy: 0.6429 - val_loss: 1.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6206 - accuracy: 0.6429 - val_loss: 1.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 0.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6515 - accuracy: 0.6071 - val_loss: 0.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6478 - accuracy: 0.6429 - val_loss: 1.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6343 - accuracy: 0.6429 - val_loss: 1.1971 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6352 - accuracy: 0.6429 - val_loss: 1.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6286 - accuracy: 0.6429 - val_loss: 1.3371 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6251 - accuracy: 0.6429 - val_loss: 1.2606 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/430\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6291 - accuracy: 0.6429 - val_loss: 1.1747 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6273 - accuracy: 0.6429 - val_loss: 1.1755 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6228 - accuracy: 0.6429 - val_loss: 1.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6256 - accuracy: 0.6429 - val_loss: 1.3279 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6260 - accuracy: 0.6429 - val_loss: 1.3450 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6271 - accuracy: 0.6429 - val_loss: 1.3113 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6245 - accuracy: 0.6429 - val_loss: 1.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6264 - accuracy: 0.6429 - val_loss: 1.1688 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6244 - accuracy: 0.6429 - val_loss: 1.1779 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6244 - accuracy: 0.6429 - val_loss: 1.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6266 - accuracy: 0.6429 - val_loss: 1.3155 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6260 - accuracy: 0.6429 - val_loss: 1.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6264 - accuracy: 0.6429 - val_loss: 1.4075 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/430\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6295 - accuracy: 0.6429 - val_loss: 1.3929 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6277 - accuracy: 0.6429 - val_loss: 1.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.2466 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6230 - accuracy: 0.6429 - val_loss: 1.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6292 - accuracy: 0.6429 - val_loss: 1.0929 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6293 - accuracy: 0.6429 - val_loss: 1.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6287 - accuracy: 0.6429 - val_loss: 1.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6272 - accuracy: 0.6429 - val_loss: 1.1980 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6231 - accuracy: 0.6429 - val_loss: 1.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6224 - accuracy: 0.6429 - val_loss: 1.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6242 - accuracy: 0.6429 - val_loss: 1.3588 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6253 - accuracy: 0.6429 - val_loss: 1.3510 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6244 - accuracy: 0.6429 - val_loss: 1.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6247 - accuracy: 0.6429 - val_loss: 1.2910 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6297 - accuracy: 0.6429 - val_loss: 1.2959 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6260 - accuracy: 0.6429 - val_loss: 1.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6248 - accuracy: 0.6429 - val_loss: 1.3509 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6249 - accuracy: 0.6429 - val_loss: 1.3058 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6262 - accuracy: 0.6429 - val_loss: 1.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 1.1428 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6263 - accuracy: 0.6429 - val_loss: 1.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6319 - accuracy: 0.6429 - val_loss: 1.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6279 - accuracy: 0.6429 - val_loss: 1.2019 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6211 - accuracy: 0.6429 - val_loss: 1.3253 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6336 - accuracy: 0.6429 - val_loss: 1.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6259 - accuracy: 0.6429 - val_loss: 1.3542 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6228 - accuracy: 0.6429 - val_loss: 1.2806 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6215 - accuracy: 0.6429 - val_loss: 1.2095 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6261 - accuracy: 0.6429 - val_loss: 1.1778 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6245 - accuracy: 0.6429 - val_loss: 1.2169 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/430\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6231 - accuracy: 0.6429 - val_loss: 1.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/430\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6217 - accuracy: 0.6429 - val_loss: 1.2978 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6254 - accuracy: 0.6429 - val_loss: 1.3322 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6224 - accuracy: 0.6429 - val_loss: 1.2970 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6238 - accuracy: 0.6429 - val_loss: 1.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6220 - accuracy: 0.6429 - val_loss: 1.3080 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6212 - accuracy: 0.6429 - val_loss: 1.3702 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6238 - accuracy: 0.6429 - val_loss: 1.4147 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 1.4018 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6245 - accuracy: 0.6429 - val_loss: 1.3482 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6224 - accuracy: 0.6429 - val_loss: 1.2852 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6217 - accuracy: 0.6429 - val_loss: 1.2398 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6276 - accuracy: 0.6429 - val_loss: 1.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6268 - accuracy: 0.6429 - val_loss: 1.3253 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6272 - accuracy: 0.6429 - val_loss: 1.3606 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6338 - accuracy: 0.6429 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6269 - accuracy: 0.6429 - val_loss: 1.3318 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6261 - accuracy: 0.6429 - val_loss: 1.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/430\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6247 - accuracy: 0.6429 - val_loss: 1.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6327 - accuracy: 0.6429 - val_loss: 1.0654 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6354 - accuracy: 0.6429 - val_loss: 1.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6432 - accuracy: 0.6429 - val_loss: 1.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6288 - accuracy: 0.6429 - val_loss: 1.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6286 - accuracy: 0.6429 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6329 - accuracy: 0.6429 - val_loss: 1.4818 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6302 - accuracy: 0.6429 - val_loss: 1.3998 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6248 - accuracy: 0.6429 - val_loss: 1.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6196 - accuracy: 0.6429 - val_loss: 1.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6225 - accuracy: 0.6429 - val_loss: 1.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6386 - accuracy: 0.6429 - val_loss: 1.0282 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6382 - accuracy: 0.6429 - val_loss: 1.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6366 - accuracy: 0.6429 - val_loss: 1.1847 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6236 - accuracy: 0.6429 - val_loss: 1.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6228 - accuracy: 0.6429 - val_loss: 1.2811 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/430\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6245 - accuracy: 0.6429 - val_loss: 1.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6222 - accuracy: 0.6429 - val_loss: 1.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6208 - accuracy: 0.6429 - val_loss: 1.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/430\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6233 - accuracy: 0.6429 - val_loss: 1.1168 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6285 - accuracy: 0.6429 - val_loss: 1.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6326 - accuracy: 0.6429 - val_loss: 1.0435 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6375 - accuracy: 0.6429 - val_loss: 1.0457 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 1.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6293 - accuracy: 0.6429 - val_loss: 1.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6195 - accuracy: 0.6429 - val_loss: 1.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6296 - accuracy: 0.6429 - val_loss: 1.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6338 - accuracy: 0.6429 - val_loss: 1.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6283 - accuracy: 0.6429 - val_loss: 1.3520 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6253 - accuracy: 0.6429 - val_loss: 1.2275 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6272 - accuracy: 0.6429 - val_loss: 1.3133 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6222 - accuracy: 0.6429 - val_loss: 1.3348 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/430\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6243 - accuracy: 0.6429 - val_loss: 1.3511 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6226 - accuracy: 0.6429 - val_loss: 1.4012 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6284 - accuracy: 0.6429 - val_loss: 1.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6279 - accuracy: 0.6429 - val_loss: 1.3453 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6223 - accuracy: 0.6429 - val_loss: 1.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6277 - accuracy: 0.6429 - val_loss: 1.2376 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6231 - accuracy: 0.6429 - val_loss: 1.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6227 - accuracy: 0.6429 - val_loss: 1.2284 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6250 - accuracy: 0.6429 - val_loss: 1.2043 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6240 - accuracy: 0.6429 - val_loss: 1.2573 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6216 - accuracy: 0.6429 - val_loss: 1.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6242 - accuracy: 0.6429 - val_loss: 1.4259 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6267 - accuracy: 0.6429 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6249 - accuracy: 0.6429 - val_loss: 1.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6215 - accuracy: 0.6429 - val_loss: 1.2696 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6206 - accuracy: 0.6429 - val_loss: 1.2020 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6229 - accuracy: 0.6429 - val_loss: 1.1442 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6307 - accuracy: 0.6429 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6281 - accuracy: 0.6429 - val_loss: 1.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6276 - accuracy: 0.6429 - val_loss: 1.3770 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6217 - accuracy: 0.6429 - val_loss: 1.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6280 - accuracy: 0.6429 - val_loss: 1.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6389 - accuracy: 0.6429 - val_loss: 1.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6504 - accuracy: 0.6429 - val_loss: 1.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6480 - accuracy: 0.6429 - val_loss: 1.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6269 - accuracy: 0.6429 - val_loss: 1.3385 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6215 - accuracy: 0.6429 - val_loss: 1.2356 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6248 - accuracy: 0.6429 - val_loss: 1.1677 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6252 - accuracy: 0.6429 - val_loss: 1.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6247 - accuracy: 0.6429 - val_loss: 1.2155 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/430\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6255 - accuracy: 0.6429 - val_loss: 1.2958 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6228 - accuracy: 0.6429 - val_loss: 1.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6271 - accuracy: 0.6429 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6271 - accuracy: 0.6429 - val_loss: 1.4037 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6287 - accuracy: 0.6429 - val_loss: 1.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6193 - accuracy: 0.6429 - val_loss: 1.2105 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6207 - accuracy: 0.6429 - val_loss: 1.0815 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6344 - accuracy: 0.6429 - val_loss: 1.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6420 - accuracy: 0.6429 - val_loss: 1.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6373 - accuracy: 0.6429 - val_loss: 1.1730 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6239 - accuracy: 0.6429 - val_loss: 1.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6200 - accuracy: 0.6429 - val_loss: 1.3794 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6233 - accuracy: 0.6429 - val_loss: 1.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6346 - accuracy: 0.6429 - val_loss: 1.5025 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/430\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6335 - accuracy: 0.6429 - val_loss: 1.4075 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6254 - accuracy: 0.6429 - val_loss: 1.2383 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6199 - accuracy: 0.6429 - val_loss: 1.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6338 - accuracy: 0.6429 - val_loss: 1.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 1.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6314 - accuracy: 0.6429 - val_loss: 1.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6259 - accuracy: 0.6429 - val_loss: 1.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6200 - accuracy: 0.6429 - val_loss: 1.3422 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ram://fb2146a0-16b3-4fb3-a097-dbb54c13c32c/assets\n",
      "Epoch 1/430\n",
      "2/2 [==============================] - 1s 194ms/step - loss: 0.7199 - accuracy: 0.5714 - val_loss: 1.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6680 - accuracy: 0.6429 - val_loss: 1.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6790 - accuracy: 0.6429 - val_loss: 1.2938 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/430\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6710 - accuracy: 0.6429 - val_loss: 1.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/430\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6423 - accuracy: 0.6429 - val_loss: 1.1729 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6378 - accuracy: 0.6429 - val_loss: 1.2877 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6684 - accuracy: 0.6429 - val_loss: 1.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6452 - accuracy: 0.6429 - val_loss: 1.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6436 - accuracy: 0.6429 - val_loss: 1.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6458 - accuracy: 0.6429 - val_loss: 1.1740 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6381 - accuracy: 0.6429 - val_loss: 1.1686 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6298 - accuracy: 0.6429 - val_loss: 1.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6268 - accuracy: 0.6429 - val_loss: 1.0860 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6306 - accuracy: 0.6429 - val_loss: 1.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6265 - accuracy: 0.6429 - val_loss: 1.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6295 - accuracy: 0.6429 - val_loss: 1.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6353 - accuracy: 0.6429 - val_loss: 1.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6344 - accuracy: 0.6429 - val_loss: 1.3938 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6433 - accuracy: 0.6429 - val_loss: 1.3106 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/430\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6271 - accuracy: 0.6429 - val_loss: 1.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6460 - accuracy: 0.6429 - val_loss: 1.3244 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6484 - accuracy: 0.6429 - val_loss: 1.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6397 - accuracy: 0.6429 - val_loss: 0.9284 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6437 - accuracy: 0.6786 - val_loss: 0.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6474 - accuracy: 0.6786 - val_loss: 0.9444 - val_accuracy: 0.1429\n",
      "Epoch 26/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6447 - accuracy: 0.6429 - val_loss: 1.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6240 - accuracy: 0.6429 - val_loss: 1.1586 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6183 - accuracy: 0.6429 - val_loss: 1.3393 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6291 - accuracy: 0.6429 - val_loss: 1.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6347 - accuracy: 0.6429 - val_loss: 1.4112 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/430\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6235 - accuracy: 0.6429 - val_loss: 1.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6178 - accuracy: 0.6429 - val_loss: 1.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6081 - accuracy: 0.6429 - val_loss: 1.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6128 - accuracy: 0.6429 - val_loss: 1.1740 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6039 - accuracy: 0.6429 - val_loss: 1.3351 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6004 - accuracy: 0.6429 - val_loss: 1.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/430\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6175 - accuracy: 0.6429 - val_loss: 1.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6055 - accuracy: 0.6429 - val_loss: 1.3696 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5988 - accuracy: 0.6429 - val_loss: 1.1361 - val_accuracy: 0.1429\n",
      "Epoch 40/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6328 - accuracy: 0.5357 - val_loss: 1.1076 - val_accuracy: 0.7143\n",
      "Epoch 41/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6214 - accuracy: 0.5357 - val_loss: 1.2994 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5997 - accuracy: 0.6429 - val_loss: 1.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6023 - accuracy: 0.6429 - val_loss: 1.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6110 - accuracy: 0.6429 - val_loss: 1.6509 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6056 - accuracy: 0.6429 - val_loss: 1.6100 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6027 - accuracy: 0.6429 - val_loss: 1.5081 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/430\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6000 - accuracy: 0.6429 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6002 - accuracy: 0.6429 - val_loss: 1.4749 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5928 - accuracy: 0.6429 - val_loss: 1.4058 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5969 - accuracy: 0.6429 - val_loss: 1.3786 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5971 - accuracy: 0.6429 - val_loss: 1.3376 - val_accuracy: 0.1429\n",
      "Epoch 52/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6042 - accuracy: 0.6429 - val_loss: 1.3621 - val_accuracy: 0.1429\n",
      "Epoch 53/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6024 - accuracy: 0.6071 - val_loss: 1.4719 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5908 - accuracy: 0.6429 - val_loss: 1.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5997 - accuracy: 0.6429 - val_loss: 1.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5901 - accuracy: 0.6429 - val_loss: 1.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5890 - accuracy: 0.6429 - val_loss: 1.5038 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5933 - accuracy: 0.6429 - val_loss: 1.4679 - val_accuracy: 0.1429\n",
      "Epoch 59/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5947 - accuracy: 0.6429 - val_loss: 1.4264 - val_accuracy: 0.1429\n",
      "Epoch 60/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6035 - accuracy: 0.6429 - val_loss: 1.4552 - val_accuracy: 0.1429\n",
      "Epoch 61/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6001 - accuracy: 0.6429 - val_loss: 1.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5967 - accuracy: 0.6429 - val_loss: 1.6181 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5925 - accuracy: 0.6429 - val_loss: 1.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5952 - accuracy: 0.6429 - val_loss: 1.6185 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5846 - accuracy: 0.6429 - val_loss: 1.7443 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 1.8765 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5927 - accuracy: 0.6429 - val_loss: 1.9743 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6052 - accuracy: 0.6429 - val_loss: 1.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5930 - accuracy: 0.6429 - val_loss: 1.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.5358 - val_accuracy: 0.1429\n",
      "Epoch 71/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6090 - accuracy: 0.6429 - val_loss: 1.4961 - val_accuracy: 0.1429\n",
      "Epoch 72/430\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6026 - accuracy: 0.6429 - val_loss: 1.6623 - val_accuracy: 0.1429\n",
      "Epoch 73/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 1.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5876 - accuracy: 0.6429 - val_loss: 1.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5980 - accuracy: 0.6429 - val_loss: 1.9729 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6045 - accuracy: 0.6429 - val_loss: 1.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5964 - accuracy: 0.6429 - val_loss: 1.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5893 - accuracy: 0.6429 - val_loss: 1.8003 - val_accuracy: 0.1429\n",
      "Epoch 79/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5897 - accuracy: 0.5714 - val_loss: 1.7161 - val_accuracy: 0.1429\n",
      "Epoch 80/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5863 - accuracy: 0.6429 - val_loss: 1.5701 - val_accuracy: 0.1429\n",
      "Epoch 81/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5982 - accuracy: 0.6429 - val_loss: 1.5673 - val_accuracy: 0.1429\n",
      "Epoch 82/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5939 - accuracy: 0.6429 - val_loss: 1.6879 - val_accuracy: 0.1429\n",
      "Epoch 83/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5884 - accuracy: 0.6429 - val_loss: 1.8189 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5925 - accuracy: 0.6429 - val_loss: 1.8269 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5874 - accuracy: 0.6429 - val_loss: 1.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5896 - accuracy: 0.6429 - val_loss: 1.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5858 - accuracy: 0.6429 - val_loss: 1.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5847 - accuracy: 0.6429 - val_loss: 1.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5956 - accuracy: 0.6429 - val_loss: 1.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5857 - accuracy: 0.6429 - val_loss: 1.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5831 - accuracy: 0.6429 - val_loss: 1.6648 - val_accuracy: 0.1429\n",
      "Epoch 92/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5877 - accuracy: 0.6429 - val_loss: 1.6138 - val_accuracy: 0.1429\n",
      "Epoch 93/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5934 - accuracy: 0.6429 - val_loss: 1.5920 - val_accuracy: 0.1429\n",
      "Epoch 94/430\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6003 - accuracy: 0.6429 - val_loss: 1.6564 - val_accuracy: 0.1429\n",
      "Epoch 95/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5845 - accuracy: 0.6786 - val_loss: 1.8493 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5846 - accuracy: 0.6429 - val_loss: 2.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6055 - accuracy: 0.6429 - val_loss: 2.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6195 - accuracy: 0.6429 - val_loss: 2.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6174 - accuracy: 0.6429 - val_loss: 1.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.7361 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5826 - accuracy: 0.7500 - val_loss: 1.5435 - val_accuracy: 0.7143\n",
      "Epoch 102/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6071 - accuracy: 0.5000 - val_loss: 1.4807 - val_accuracy: 0.7143\n",
      "Epoch 103/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6231 - accuracy: 0.5000 - val_loss: 1.5266 - val_accuracy: 0.7143\n",
      "Epoch 104/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6047 - accuracy: 0.5714 - val_loss: 1.6098 - val_accuracy: 0.1429\n",
      "Epoch 105/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5874 - accuracy: 0.6429 - val_loss: 1.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5778 - accuracy: 0.6429 - val_loss: 1.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6009 - accuracy: 0.6429 - val_loss: 2.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6170 - accuracy: 0.6429 - val_loss: 2.0510 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/430\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6056 - accuracy: 0.6429 - val_loss: 1.8901 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 1.7114 - val_accuracy: 0.1429\n",
      "Epoch 111/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5960 - accuracy: 0.6429 - val_loss: 1.6062 - val_accuracy: 0.1429\n",
      "Epoch 112/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5924 - accuracy: 0.6429 - val_loss: 1.6563 - val_accuracy: 0.1429\n",
      "Epoch 113/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5900 - accuracy: 0.6429 - val_loss: 1.7690 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5835 - accuracy: 0.6429 - val_loss: 1.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5923 - accuracy: 0.6429 - val_loss: 1.8919 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5898 - accuracy: 0.6429 - val_loss: 1.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5859 - accuracy: 0.6429 - val_loss: 1.6670 - val_accuracy: 0.1429\n",
      "Epoch 118/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5899 - accuracy: 0.6429 - val_loss: 1.6142 - val_accuracy: 0.1429\n",
      "Epoch 119/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5956 - accuracy: 0.6429 - val_loss: 1.6359 - val_accuracy: 0.1429\n",
      "Epoch 120/430\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5935 - accuracy: 0.6429 - val_loss: 1.6650 - val_accuracy: 0.1429\n",
      "Epoch 121/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5894 - accuracy: 0.6429 - val_loss: 1.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5861 - accuracy: 0.6429 - val_loss: 1.8509 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5852 - accuracy: 0.6429 - val_loss: 1.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5842 - accuracy: 0.6429 - val_loss: 1.7814 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5826 - accuracy: 0.6429 - val_loss: 1.7418 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5835 - accuracy: 0.6429 - val_loss: 1.6965 - val_accuracy: 0.1429\n",
      "Epoch 127/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5869 - accuracy: 0.6429 - val_loss: 1.6651 - val_accuracy: 0.1429\n",
      "Epoch 128/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5900 - accuracy: 0.6429 - val_loss: 1.6939 - val_accuracy: 0.1429\n",
      "Epoch 129/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5881 - accuracy: 0.6429 - val_loss: 1.7446 - val_accuracy: 0.1429\n",
      "Epoch 130/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5842 - accuracy: 0.6429 - val_loss: 1.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5911 - accuracy: 0.6429 - val_loss: 1.8288 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5816 - accuracy: 0.6429 - val_loss: 1.7587 - val_accuracy: 0.1429\n",
      "Epoch 133/430\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.6955 - val_accuracy: 0.1429\n",
      "Epoch 134/430\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5908 - accuracy: 0.6429 - val_loss: 1.6850 - val_accuracy: 0.1429\n",
      "Epoch 135/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5925 - accuracy: 0.6429 - val_loss: 1.7174 - val_accuracy: 0.1429\n",
      "Epoch 136/430\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5956 - accuracy: 0.6429 - val_loss: 1.8059 - val_accuracy: 0.1429\n",
      "Epoch 137/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.8462 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5832 - accuracy: 0.6429 - val_loss: 2.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5951 - accuracy: 0.6429 - val_loss: 2.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/430\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5960 - accuracy: 0.6429 - val_loss: 2.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6066 - accuracy: 0.6429 - val_loss: 2.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5892 - accuracy: 0.6429 - val_loss: 1.8554 - val_accuracy: 0.1429\n",
      "Epoch 145/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5777 - accuracy: 0.6429 - val_loss: 1.6887 - val_accuracy: 0.1429\n",
      "Epoch 146/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6062 - accuracy: 0.5000 - val_loss: 1.6298 - val_accuracy: 0.7143\n",
      "Epoch 147/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6072 - accuracy: 0.6071 - val_loss: 1.7402 - val_accuracy: 0.1429\n",
      "Epoch 148/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.9450 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5849 - accuracy: 0.6429 - val_loss: 2.2370 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6227 - accuracy: 0.6429 - val_loss: 2.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6314 - accuracy: 0.6429 - val_loss: 2.1087 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5901 - accuracy: 0.6429 - val_loss: 1.7702 - val_accuracy: 0.1429\n",
      "Epoch 153/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5845 - accuracy: 0.6429 - val_loss: 1.5319 - val_accuracy: 0.7143\n",
      "Epoch 154/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6137 - accuracy: 0.5000 - val_loss: 1.4443 - val_accuracy: 0.7143\n",
      "Epoch 155/430\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6357 - accuracy: 0.5000 - val_loss: 1.4781 - val_accuracy: 0.7143\n",
      "Epoch 156/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6142 - accuracy: 0.5357 - val_loss: 1.6488 - val_accuracy: 0.1429\n",
      "Epoch 157/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.8407 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 2.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6136 - accuracy: 0.6429 - val_loss: 2.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6315 - accuracy: 0.6429 - val_loss: 2.0428 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6192 - accuracy: 0.6429 - val_loss: 1.9451 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6065 - accuracy: 0.6429 - val_loss: 1.8215 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/430\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5889 - accuracy: 0.6429 - val_loss: 1.7042 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5870 - accuracy: 0.6429 - val_loss: 1.5818 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5892 - accuracy: 0.6429 - val_loss: 1.5121 - val_accuracy: 0.1429\n",
      "Epoch 166/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6024 - accuracy: 0.6429 - val_loss: 1.4911 - val_accuracy: 0.1429\n",
      "Epoch 167/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6004 - accuracy: 0.6429 - val_loss: 1.5833 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5935 - accuracy: 0.6429 - val_loss: 1.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5918 - accuracy: 0.6429 - val_loss: 1.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5920 - accuracy: 0.6429 - val_loss: 1.8339 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5872 - accuracy: 0.6429 - val_loss: 1.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5875 - accuracy: 0.6429 - val_loss: 1.6542 - val_accuracy: 0.1429\n",
      "Epoch 173/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5875 - accuracy: 0.6429 - val_loss: 1.6179 - val_accuracy: 0.1429\n",
      "Epoch 174/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5886 - accuracy: 0.6429 - val_loss: 1.6347 - val_accuracy: 0.1429\n",
      "Epoch 175/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5879 - accuracy: 0.6429 - val_loss: 1.6677 - val_accuracy: 0.1429\n",
      "Epoch 176/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5864 - accuracy: 0.6429 - val_loss: 1.7083 - val_accuracy: 0.1429\n",
      "Epoch 177/430\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5837 - accuracy: 0.6429 - val_loss: 1.7754 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5843 - accuracy: 0.6429 - val_loss: 1.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5860 - accuracy: 0.6429 - val_loss: 1.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5915 - accuracy: 0.6429 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5888 - accuracy: 0.6429 - val_loss: 1.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5872 - accuracy: 0.6429 - val_loss: 1.7788 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5831 - accuracy: 0.6429 - val_loss: 1.7497 - val_accuracy: 0.1429\n",
      "Epoch 184/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5826 - accuracy: 0.6429 - val_loss: 1.7033 - val_accuracy: 0.1429\n",
      "Epoch 185/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5864 - accuracy: 0.6429 - val_loss: 1.6723 - val_accuracy: 0.1429\n",
      "Epoch 186/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5911 - accuracy: 0.6429 - val_loss: 1.6828 - val_accuracy: 0.1429\n",
      "Epoch 187/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5892 - accuracy: 0.6429 - val_loss: 1.7045 - val_accuracy: 0.1429\n",
      "Epoch 188/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5898 - accuracy: 0.6429 - val_loss: 1.7617 - val_accuracy: 0.1429\n",
      "Epoch 189/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5876 - accuracy: 0.6429 - val_loss: 1.8316 - val_accuracy: 0.1429\n",
      "Epoch 190/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5905 - accuracy: 0.5714 - val_loss: 1.9651 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5865 - accuracy: 0.6429 - val_loss: 1.9947 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5897 - accuracy: 0.6429 - val_loss: 1.9756 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5840 - accuracy: 0.6429 - val_loss: 1.8737 - val_accuracy: 0.1429\n",
      "Epoch 194/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5797 - accuracy: 0.6429 - val_loss: 1.7507 - val_accuracy: 0.1429\n",
      "Epoch 195/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5876 - accuracy: 0.6429 - val_loss: 1.6735 - val_accuracy: 0.1429\n",
      "Epoch 196/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5971 - accuracy: 0.6429 - val_loss: 1.6709 - val_accuracy: 0.1429\n",
      "Epoch 197/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5965 - accuracy: 0.6429 - val_loss: 1.6993 - val_accuracy: 0.1429\n",
      "Epoch 198/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6072 - accuracy: 0.6429 - val_loss: 1.7623 - val_accuracy: 0.1429\n",
      "Epoch 199/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 1.7559 - val_accuracy: 0.1429\n",
      "Epoch 200/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5874 - accuracy: 0.6429 - val_loss: 1.7644 - val_accuracy: 0.1429\n",
      "Epoch 201/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5860 - accuracy: 0.6429 - val_loss: 1.8271 - val_accuracy: 0.1429\n",
      "Epoch 202/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5855 - accuracy: 0.6071 - val_loss: 1.8902 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5818 - accuracy: 0.6429 - val_loss: 1.9078 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/430\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5816 - accuracy: 0.6429 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5845 - accuracy: 0.6429 - val_loss: 1.9351 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 2.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5861 - accuracy: 0.6429 - val_loss: 2.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5866 - accuracy: 0.6429 - val_loss: 1.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5825 - accuracy: 0.6429 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.8180 - val_accuracy: 0.1429\n",
      "Epoch 211/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5895 - accuracy: 0.6429 - val_loss: 1.7859 - val_accuracy: 0.1429\n",
      "Epoch 212/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5924 - accuracy: 0.6429 - val_loss: 1.8290 - val_accuracy: 0.1429\n",
      "Epoch 213/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5851 - accuracy: 0.6429 - val_loss: 1.8512 - val_accuracy: 0.1429\n",
      "Epoch 214/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5852 - accuracy: 0.6786 - val_loss: 1.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5833 - accuracy: 0.6429 - val_loss: 1.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5873 - accuracy: 0.5357 - val_loss: 1.8911 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5833 - accuracy: 0.6429 - val_loss: 1.9736 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5822 - accuracy: 0.6429 - val_loss: 2.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/430\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 2.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5844 - accuracy: 0.6429 - val_loss: 1.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5843 - accuracy: 0.6429 - val_loss: 1.9798 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5811 - accuracy: 0.6429 - val_loss: 1.9090 - val_accuracy: 0.1429\n",
      "Epoch 223/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.8841 - val_accuracy: 0.1429\n",
      "Epoch 224/430\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5832 - accuracy: 0.6429 - val_loss: 1.9370 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 2.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5831 - accuracy: 0.6429 - val_loss: 2.0472 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/430\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5865 - accuracy: 0.6429 - val_loss: 2.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 2.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5838 - accuracy: 0.6071 - val_loss: 1.9217 - val_accuracy: 0.1429\n",
      "Epoch 230/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5817 - accuracy: 0.6429 - val_loss: 1.8995 - val_accuracy: 0.1429\n",
      "Epoch 231/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5846 - accuracy: 0.6429 - val_loss: 1.9147 - val_accuracy: 0.1429\n",
      "Epoch 232/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5836 - accuracy: 0.6071 - val_loss: 1.9859 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5804 - accuracy: 0.6429 - val_loss: 2.0389 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 2.0956 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5855 - accuracy: 0.6429 - val_loss: 2.0639 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5820 - accuracy: 0.6429 - val_loss: 1.9661 - val_accuracy: 0.1429\n",
      "Epoch 237/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5812 - accuracy: 0.6429 - val_loss: 1.9116 - val_accuracy: 0.1429\n",
      "Epoch 238/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5881 - accuracy: 0.6429 - val_loss: 1.8833 - val_accuracy: 0.1429\n",
      "Epoch 239/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5883 - accuracy: 0.6429 - val_loss: 1.8342 - val_accuracy: 0.1429\n",
      "Epoch 240/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5938 - accuracy: 0.6429 - val_loss: 1.9006 - val_accuracy: 0.1429\n",
      "Epoch 241/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5799 - accuracy: 0.6429 - val_loss: 2.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5832 - accuracy: 0.6429 - val_loss: 2.2260 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5968 - accuracy: 0.6429 - val_loss: 2.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5975 - accuracy: 0.6429 - val_loss: 2.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5860 - accuracy: 0.6429 - val_loss: 1.9890 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5768 - accuracy: 0.6071 - val_loss: 1.8566 - val_accuracy: 0.1429\n",
      "Epoch 247/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5855 - accuracy: 0.6429 - val_loss: 1.7558 - val_accuracy: 0.1429\n",
      "Epoch 248/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6150 - accuracy: 0.3929 - val_loss: 1.7609 - val_accuracy: 0.1429\n",
      "Epoch 249/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5989 - accuracy: 0.6429 - val_loss: 1.9213 - val_accuracy: 0.1429\n",
      "Epoch 250/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5835 - accuracy: 0.6786 - val_loss: 2.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5851 - accuracy: 0.6429 - val_loss: 2.1408 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6049 - accuracy: 0.6429 - val_loss: 2.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5817 - accuracy: 0.7143 - val_loss: 1.7413 - val_accuracy: 0.1429\n",
      "Epoch 255/430\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6002 - accuracy: 0.5714 - val_loss: 1.6815 - val_accuracy: 0.7143\n",
      "Epoch 256/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6092 - accuracy: 0.5000 - val_loss: 1.7493 - val_accuracy: 0.1429\n",
      "Epoch 257/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5849 - accuracy: 0.6429 - val_loss: 1.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5861 - accuracy: 0.6429 - val_loss: 2.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6026 - accuracy: 0.6429 - val_loss: 2.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6103 - accuracy: 0.6429 - val_loss: 2.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5906 - accuracy: 0.6429 - val_loss: 1.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5811 - accuracy: 0.6429 - val_loss: 1.7090 - val_accuracy: 0.1429\n",
      "Epoch 263/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5927 - accuracy: 0.6429 - val_loss: 1.6030 - val_accuracy: 0.7143\n",
      "Epoch 264/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6080 - accuracy: 0.5000 - val_loss: 1.5964 - val_accuracy: 0.7143\n",
      "Epoch 265/430\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6062 - accuracy: 0.5000 - val_loss: 1.6765 - val_accuracy: 0.1429\n",
      "Epoch 266/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5915 - accuracy: 0.6429 - val_loss: 1.7976 - val_accuracy: 0.1429\n",
      "Epoch 267/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5791 - accuracy: 0.7143 - val_loss: 1.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5837 - accuracy: 0.6429 - val_loss: 2.0465 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6042 - accuracy: 0.6429 - val_loss: 2.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6020 - accuracy: 0.6429 - val_loss: 2.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5909 - accuracy: 0.6429 - val_loss: 1.8748 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5880 - accuracy: 0.6429 - val_loss: 1.7682 - val_accuracy: 0.1429\n",
      "Epoch 273/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5878 - accuracy: 0.6429 - val_loss: 1.7369 - val_accuracy: 0.1429\n",
      "Epoch 274/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 1.7754 - val_accuracy: 0.1429\n",
      "Epoch 275/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5858 - accuracy: 0.6071 - val_loss: 1.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5870 - accuracy: 0.6429 - val_loss: 1.8547 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5834 - accuracy: 0.6429 - val_loss: 1.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/430\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.8063 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5849 - accuracy: 0.6786 - val_loss: 1.7958 - val_accuracy: 0.1429\n",
      "Epoch 280/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5832 - accuracy: 0.6429 - val_loss: 1.8382 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.9247 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5826 - accuracy: 0.6429 - val_loss: 1.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.8546 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5818 - accuracy: 0.6429 - val_loss: 1.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5819 - accuracy: 0.6429 - val_loss: 1.8626 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5823 - accuracy: 0.6429 - val_loss: 1.8699 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5822 - accuracy: 0.6429 - val_loss: 1.8955 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5812 - accuracy: 0.6429 - val_loss: 1.9320 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5823 - accuracy: 0.6429 - val_loss: 1.9566 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5817 - accuracy: 0.6429 - val_loss: 1.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5834 - accuracy: 0.6429 - val_loss: 1.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5797 - accuracy: 0.6429 - val_loss: 1.8767 - val_accuracy: 0.1429\n",
      "Epoch 297/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5844 - accuracy: 0.6429 - val_loss: 1.8116 - val_accuracy: 0.1429\n",
      "Epoch 298/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5920 - accuracy: 0.6429 - val_loss: 1.7959 - val_accuracy: 0.1429\n",
      "Epoch 299/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5922 - accuracy: 0.6429 - val_loss: 1.7721 - val_accuracy: 0.1429\n",
      "Epoch 300/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5939 - accuracy: 0.6429 - val_loss: 1.8313 - val_accuracy: 0.1429\n",
      "Epoch 301/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 1.9444 - val_accuracy: 0.1429\n",
      "Epoch 302/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5814 - accuracy: 0.6429 - val_loss: 2.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 2.1245 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/430\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5885 - accuracy: 0.6429 - val_loss: 2.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5852 - accuracy: 0.6429 - val_loss: 2.0195 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5794 - accuracy: 0.6429 - val_loss: 1.9297 - val_accuracy: 0.1429\n",
      "Epoch 307/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5809 - accuracy: 0.6429 - val_loss: 1.8447 - val_accuracy: 0.1429\n",
      "Epoch 308/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5886 - accuracy: 0.6429 - val_loss: 1.8091 - val_accuracy: 0.1429\n",
      "Epoch 309/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5933 - accuracy: 0.6429 - val_loss: 1.8351 - val_accuracy: 0.1429\n",
      "Epoch 310/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5921 - accuracy: 0.6429 - val_loss: 1.8708 - val_accuracy: 0.1429\n",
      "Epoch 311/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5856 - accuracy: 0.6429 - val_loss: 1.9067 - val_accuracy: 0.1429\n",
      "Epoch 312/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.9907 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/430\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5809 - accuracy: 0.6429 - val_loss: 2.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 2.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5856 - accuracy: 0.6429 - val_loss: 2.0862 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 2.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5763 - accuracy: 0.6071 - val_loss: 1.8636 - val_accuracy: 0.1429\n",
      "Epoch 318/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5883 - accuracy: 0.6429 - val_loss: 1.7655 - val_accuracy: 0.1429\n",
      "Epoch 319/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6022 - accuracy: 0.6071 - val_loss: 1.7617 - val_accuracy: 0.7143\n",
      "Epoch 320/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6028 - accuracy: 0.4643 - val_loss: 1.8309 - val_accuracy: 0.1429\n",
      "Epoch 321/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6014 - accuracy: 0.6429 - val_loss: 1.8994 - val_accuracy: 0.1429\n",
      "Epoch 322/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5878 - accuracy: 0.6429 - val_loss: 1.9373 - val_accuracy: 0.1429\n",
      "Epoch 323/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5838 - accuracy: 0.6071 - val_loss: 2.0504 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 2.0944 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/430\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.5853 - accuracy: 0.6429 - val_loss: 2.0509 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5869 - accuracy: 0.6429 - val_loss: 1.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5820 - accuracy: 0.6429 - val_loss: 1.9317 - val_accuracy: 0.1429\n",
      "Epoch 328/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5830 - accuracy: 0.6429 - val_loss: 1.8706 - val_accuracy: 0.1429\n",
      "Epoch 329/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5869 - accuracy: 0.6429 - val_loss: 1.8784 - val_accuracy: 0.1429\n",
      "Epoch 330/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5823 - accuracy: 0.6429 - val_loss: 1.9601 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5775 - accuracy: 0.6429 - val_loss: 2.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5829 - accuracy: 0.6429 - val_loss: 2.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5978 - accuracy: 0.6429 - val_loss: 2.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5983 - accuracy: 0.6429 - val_loss: 2.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5880 - accuracy: 0.6429 - val_loss: 2.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5788 - accuracy: 0.6429 - val_loss: 1.8955 - val_accuracy: 0.1429\n",
      "Epoch 337/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5815 - accuracy: 0.6429 - val_loss: 1.8014 - val_accuracy: 0.1429\n",
      "Epoch 338/430\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5905 - accuracy: 0.6429 - val_loss: 1.7528 - val_accuracy: 0.1429\n",
      "Epoch 339/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5991 - accuracy: 0.6429 - val_loss: 1.7289 - val_accuracy: 0.7143\n",
      "Epoch 340/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6053 - accuracy: 0.4286 - val_loss: 1.7271 - val_accuracy: 0.7143\n",
      "Epoch 341/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6059 - accuracy: 0.5000 - val_loss: 1.7612 - val_accuracy: 0.1429\n",
      "Epoch 342/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5894 - accuracy: 0.6429 - val_loss: 1.9078 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5865 - accuracy: 0.6429 - val_loss: 2.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5902 - accuracy: 0.6429 - val_loss: 2.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6061 - accuracy: 0.6429 - val_loss: 2.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6230 - accuracy: 0.6429 - val_loss: 2.2004 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5999 - accuracy: 0.6429 - val_loss: 1.9794 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5827 - accuracy: 0.6429 - val_loss: 1.8063 - val_accuracy: 0.1429\n",
      "Epoch 349/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5868 - accuracy: 0.6429 - val_loss: 1.7078 - val_accuracy: 0.1429\n",
      "Epoch 350/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5999 - accuracy: 0.6429 - val_loss: 1.6887 - val_accuracy: 0.1429\n",
      "Epoch 351/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5994 - accuracy: 0.6429 - val_loss: 1.7685 - val_accuracy: 0.1429\n",
      "Epoch 352/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6070 - accuracy: 0.6071 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5814 - accuracy: 0.6429 - val_loss: 1.9836 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5892 - accuracy: 0.6429 - val_loss: 2.0191 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5898 - accuracy: 0.6429 - val_loss: 1.9750 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.8792 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5876 - accuracy: 0.5357 - val_loss: 1.7923 - val_accuracy: 0.1429\n",
      "Epoch 358/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.7713 - val_accuracy: 0.1429\n",
      "Epoch 359/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5856 - accuracy: 0.6429 - val_loss: 1.7800 - val_accuracy: 0.1429\n",
      "Epoch 360/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5849 - accuracy: 0.6429 - val_loss: 1.8128 - val_accuracy: 0.1429\n",
      "Epoch 361/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5820 - accuracy: 0.6429 - val_loss: 1.8794 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5813 - accuracy: 0.6429 - val_loss: 1.9484 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/430\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5878 - accuracy: 0.6429 - val_loss: 1.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5857 - accuracy: 0.6429 - val_loss: 1.9520 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5840 - accuracy: 0.6429 - val_loss: 1.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5820 - accuracy: 0.6429 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5817 - accuracy: 0.6429 - val_loss: 1.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5816 - accuracy: 0.6429 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5831 - accuracy: 0.6429 - val_loss: 1.9371 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5825 - accuracy: 0.6429 - val_loss: 1.9766 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5826 - accuracy: 0.6429 - val_loss: 1.9749 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5811 - accuracy: 0.6429 - val_loss: 1.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5806 - accuracy: 0.6429 - val_loss: 1.8925 - val_accuracy: 0.1429\n",
      "Epoch 375/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5831 - accuracy: 0.6429 - val_loss: 1.8714 - val_accuracy: 0.1429\n",
      "Epoch 376/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5886 - accuracy: 0.6429 - val_loss: 1.8715 - val_accuracy: 0.1429\n",
      "Epoch 377/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5842 - accuracy: 0.6429 - val_loss: 1.8357 - val_accuracy: 0.1429\n",
      "Epoch 378/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5895 - accuracy: 0.6429 - val_loss: 1.8556 - val_accuracy: 0.1429\n",
      "Epoch 379/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.9472 - val_accuracy: 0.1429\n",
      "Epoch 380/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5845 - accuracy: 0.6786 - val_loss: 2.0292 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5818 - accuracy: 0.6429 - val_loss: 2.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5837 - accuracy: 0.6429 - val_loss: 2.0976 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5863 - accuracy: 0.6429 - val_loss: 2.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5839 - accuracy: 0.6429 - val_loss: 1.9903 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5812 - accuracy: 0.5714 - val_loss: 1.9362 - val_accuracy: 0.1429\n",
      "Epoch 386/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5818 - accuracy: 0.6429 - val_loss: 1.9119 - val_accuracy: 0.1429\n",
      "Epoch 387/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5826 - accuracy: 0.6429 - val_loss: 1.9164 - val_accuracy: 0.1429\n",
      "Epoch 388/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 1.9212 - val_accuracy: 0.1429\n",
      "Epoch 389/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5828 - accuracy: 0.6429 - val_loss: 1.8961 - val_accuracy: 0.1429\n",
      "Epoch 390/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5846 - accuracy: 0.6429 - val_loss: 1.9101 - val_accuracy: 0.1429\n",
      "Epoch 391/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5834 - accuracy: 0.6429 - val_loss: 1.9727 - val_accuracy: 0.1429\n",
      "Epoch 392/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5765 - accuracy: 0.7143 - val_loss: 2.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5879 - accuracy: 0.6429 - val_loss: 2.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5946 - accuracy: 0.6429 - val_loss: 2.2285 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5958 - accuracy: 0.6429 - val_loss: 2.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5895 - accuracy: 0.6429 - val_loss: 2.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5777 - accuracy: 0.6429 - val_loss: 1.9550 - val_accuracy: 0.1429\n",
      "Epoch 398/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5781 - accuracy: 0.6429 - val_loss: 1.8089 - val_accuracy: 0.1429\n",
      "Epoch 399/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5992 - accuracy: 0.5714 - val_loss: 1.7377 - val_accuracy: 0.7143\n",
      "Epoch 400/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6097 - accuracy: 0.5000 - val_loss: 1.7730 - val_accuracy: 0.1429\n",
      "Epoch 401/430\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6059 - accuracy: 0.6429 - val_loss: 1.8794 - val_accuracy: 0.1429\n",
      "Epoch 402/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5817 - accuracy: 0.6429 - val_loss: 1.9853 - val_accuracy: 0.1429\n",
      "Epoch 403/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5771 - accuracy: 0.6429 - val_loss: 2.1394 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5907 - accuracy: 0.6429 - val_loss: 2.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6073 - accuracy: 0.6429 - val_loss: 2.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5994 - accuracy: 0.6429 - val_loss: 2.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5912 - accuracy: 0.6429 - val_loss: 1.9539 - val_accuracy: 0.1429\n",
      "Epoch 408/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5790 - accuracy: 0.6429 - val_loss: 1.8568 - val_accuracy: 0.1429\n",
      "Epoch 409/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5836 - accuracy: 0.6429 - val_loss: 1.7488 - val_accuracy: 0.1429\n",
      "Epoch 410/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5958 - accuracy: 0.6429 - val_loss: 1.7015 - val_accuracy: 0.1429\n",
      "Epoch 411/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6054 - accuracy: 0.6429 - val_loss: 1.7005 - val_accuracy: 0.1429\n",
      "Epoch 412/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6043 - accuracy: 0.6429 - val_loss: 1.7444 - val_accuracy: 0.1429\n",
      "Epoch 413/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5958 - accuracy: 0.6429 - val_loss: 1.8263 - val_accuracy: 0.1429\n",
      "Epoch 414/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5841 - accuracy: 0.6429 - val_loss: 1.9241 - val_accuracy: 0.1429\n",
      "Epoch 415/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5826 - accuracy: 0.7143 - val_loss: 2.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5820 - accuracy: 0.6429 - val_loss: 2.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 2.1061 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5913 - accuracy: 0.6429 - val_loss: 2.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5894 - accuracy: 0.6429 - val_loss: 2.0347 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5848 - accuracy: 0.6429 - val_loss: 1.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5819 - accuracy: 0.6429 - val_loss: 1.9596 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/430\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5811 - accuracy: 0.6429 - val_loss: 1.9323 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5810 - accuracy: 0.6429 - val_loss: 1.9184 - val_accuracy: 0.1429\n",
      "Epoch 424/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5814 - accuracy: 0.6429 - val_loss: 1.9195 - val_accuracy: 0.1429\n",
      "Epoch 425/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5818 - accuracy: 0.6429 - val_loss: 1.9307 - val_accuracy: 0.1429\n",
      "Epoch 426/430\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5826 - accuracy: 0.5714 - val_loss: 1.9255 - val_accuracy: 0.1429\n",
      "Epoch 427/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5867 - accuracy: 0.6429 - val_loss: 1.9140 - val_accuracy: 0.1429\n",
      "Epoch 428/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5844 - accuracy: 0.6429 - val_loss: 1.9605 - val_accuracy: 0.1429\n",
      "Epoch 429/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5806 - accuracy: 0.6429 - val_loss: 1.9783 - val_accuracy: 0.1429\n",
      "Epoch 430/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5814 - accuracy: 0.6429 - val_loss: 1.9852 - val_accuracy: 0.1429\n",
      "INFO:tensorflow:Assets written to: ram://d6db89d3-47fa-4a48-959a-976023bafbfa/assets\n",
      "Epoch 1/430\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.7453 - accuracy: 0.4286 - val_loss: 0.9032 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6845 - accuracy: 0.6071 - val_loss: 1.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6866 - accuracy: 0.6071 - val_loss: 1.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6609 - accuracy: 0.6071 - val_loss: 0.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6440 - accuracy: 0.6071 - val_loss: 0.7763 - val_accuracy: 0.2500\n",
      "Epoch 6/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6630 - accuracy: 0.5714 - val_loss: 0.7079 - val_accuracy: 0.7500\n",
      "Epoch 7/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6660 - accuracy: 0.7143 - val_loss: 0.7662 - val_accuracy: 0.3750\n",
      "Epoch 8/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6555 - accuracy: 0.5357 - val_loss: 0.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6420 - accuracy: 0.6071 - val_loss: 0.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6297 - accuracy: 0.6071 - val_loss: 0.9674 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6262 - accuracy: 0.6071 - val_loss: 0.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6263 - accuracy: 0.6071 - val_loss: 0.9308 - val_accuracy: 0.1250\n",
      "Epoch 13/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6161 - accuracy: 0.6429 - val_loss: 0.9543 - val_accuracy: 0.1250\n",
      "Epoch 14/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6085 - accuracy: 0.6429 - val_loss: 0.9387 - val_accuracy: 0.1250\n",
      "Epoch 15/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6016 - accuracy: 0.6429 - val_loss: 0.9420 - val_accuracy: 0.1250\n",
      "Epoch 16/430\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5968 - accuracy: 0.6429 - val_loss: 0.9532 - val_accuracy: 0.1250\n",
      "Epoch 17/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5973 - accuracy: 0.6429 - val_loss: 0.9217 - val_accuracy: 0.3750\n",
      "Epoch 18/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5903 - accuracy: 0.6429 - val_loss: 0.8491 - val_accuracy: 0.6250\n",
      "Epoch 19/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5841 - accuracy: 0.6786 - val_loss: 0.8689 - val_accuracy: 0.6250\n",
      "Epoch 20/430\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5758 - accuracy: 0.6786 - val_loss: 0.9594 - val_accuracy: 0.6250\n",
      "Epoch 21/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5757 - accuracy: 0.6071 - val_loss: 1.0265 - val_accuracy: 0.1250\n",
      "Epoch 22/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5685 - accuracy: 0.6071 - val_loss: 0.9798 - val_accuracy: 0.6250\n",
      "Epoch 23/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5565 - accuracy: 0.6786 - val_loss: 0.8848 - val_accuracy: 0.6250\n",
      "Epoch 24/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5661 - accuracy: 0.6786 - val_loss: 0.8248 - val_accuracy: 0.7500\n",
      "Epoch 25/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5741 - accuracy: 0.6429 - val_loss: 0.9215 - val_accuracy: 0.7500\n",
      "Epoch 26/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5607 - accuracy: 0.5714 - val_loss: 1.1030 - val_accuracy: 0.2500\n",
      "Epoch 27/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5499 - accuracy: 0.6429 - val_loss: 1.1888 - val_accuracy: 0.2500\n",
      "Epoch 28/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5466 - accuracy: 0.6429 - val_loss: 1.1463 - val_accuracy: 0.2500\n",
      "Epoch 29/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5406 - accuracy: 0.6786 - val_loss: 1.0295 - val_accuracy: 0.6250\n",
      "Epoch 30/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5402 - accuracy: 0.6786 - val_loss: 0.9167 - val_accuracy: 0.6250\n",
      "Epoch 31/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5438 - accuracy: 0.6786 - val_loss: 0.9396 - val_accuracy: 0.6250\n",
      "Epoch 32/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5376 - accuracy: 0.6786 - val_loss: 1.0239 - val_accuracy: 0.6250\n",
      "Epoch 33/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5306 - accuracy: 0.7143 - val_loss: 1.1770 - val_accuracy: 0.6250\n",
      "Epoch 34/430\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.5331 - accuracy: 0.7143 - val_loss: 1.2085 - val_accuracy: 0.6250\n",
      "Epoch 35/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5312 - accuracy: 0.7143 - val_loss: 1.1775 - val_accuracy: 0.6250\n",
      "Epoch 36/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5204 - accuracy: 0.7143 - val_loss: 1.1231 - val_accuracy: 0.6250\n",
      "Epoch 37/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5176 - accuracy: 0.6786 - val_loss: 1.0532 - val_accuracy: 0.7500\n",
      "Epoch 38/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5234 - accuracy: 0.6429 - val_loss: 1.1519 - val_accuracy: 0.6250\n",
      "Epoch 39/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5243 - accuracy: 0.6786 - val_loss: 1.2671 - val_accuracy: 0.6250\n",
      "Epoch 40/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5166 - accuracy: 0.6429 - val_loss: 1.3141 - val_accuracy: 0.6250\n",
      "Epoch 41/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 1.4664 - val_accuracy: 0.2500\n",
      "Epoch 42/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5179 - accuracy: 0.6786 - val_loss: 1.4244 - val_accuracy: 0.2500\n",
      "Epoch 43/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5092 - accuracy: 0.6786 - val_loss: 1.2646 - val_accuracy: 0.7500\n",
      "Epoch 44/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5184 - accuracy: 0.6786 - val_loss: 1.1831 - val_accuracy: 0.7500\n",
      "Epoch 45/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5291 - accuracy: 0.6429 - val_loss: 1.1306 - val_accuracy: 0.7500\n",
      "Epoch 46/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5186 - accuracy: 0.6429 - val_loss: 1.3331 - val_accuracy: 0.6250\n",
      "Epoch 47/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5229 - accuracy: 0.6786 - val_loss: 1.5726 - val_accuracy: 0.2500\n",
      "Epoch 48/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5250 - accuracy: 0.6786 - val_loss: 1.4236 - val_accuracy: 0.6250\n",
      "Epoch 49/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4998 - accuracy: 0.7143 - val_loss: 1.2532 - val_accuracy: 0.6250\n",
      "Epoch 50/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5027 - accuracy: 0.6786 - val_loss: 1.1926 - val_accuracy: 0.7500\n",
      "Epoch 51/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4998 - accuracy: 0.6786 - val_loss: 1.3194 - val_accuracy: 0.6250\n",
      "Epoch 52/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4939 - accuracy: 0.7143 - val_loss: 1.4978 - val_accuracy: 0.2500\n",
      "Epoch 53/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5051 - accuracy: 0.6429 - val_loss: 1.5111 - val_accuracy: 0.2500\n",
      "Epoch 54/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5013 - accuracy: 0.6786 - val_loss: 1.4869 - val_accuracy: 0.6250\n",
      "Epoch 55/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4943 - accuracy: 0.7143 - val_loss: 1.3442 - val_accuracy: 0.6250\n",
      "Epoch 56/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4886 - accuracy: 0.7143 - val_loss: 1.1908 - val_accuracy: 0.7500\n",
      "Epoch 57/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5073 - accuracy: 0.6786 - val_loss: 1.2501 - val_accuracy: 0.7500\n",
      "Epoch 58/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4840 - accuracy: 0.7500 - val_loss: 1.5060 - val_accuracy: 0.6250\n",
      "Epoch 59/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5480 - accuracy: 0.6071 - val_loss: 1.5609 - val_accuracy: 0.2500\n",
      "Epoch 60/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4770 - accuracy: 0.7143 - val_loss: 1.2194 - val_accuracy: 0.7500\n",
      "Epoch 61/430\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4830 - accuracy: 0.6786 - val_loss: 1.0212 - val_accuracy: 0.7500\n",
      "Epoch 62/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5952 - accuracy: 0.6429 - val_loss: 1.0210 - val_accuracy: 0.7500\n",
      "Epoch 63/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5658 - accuracy: 0.6429 - val_loss: 1.2930 - val_accuracy: 0.7500\n",
      "Epoch 64/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5262 - accuracy: 0.5714 - val_loss: 1.7732 - val_accuracy: 0.2500\n",
      "Epoch 65/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5483 - accuracy: 0.6786 - val_loss: 1.7812 - val_accuracy: 0.1250\n",
      "Epoch 66/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5415 - accuracy: 0.6786 - val_loss: 1.4392 - val_accuracy: 0.6250\n",
      "Epoch 67/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4892 - accuracy: 0.7143 - val_loss: 1.1765 - val_accuracy: 0.7500\n",
      "Epoch 68/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5059 - accuracy: 0.6786 - val_loss: 1.0918 - val_accuracy: 0.7500\n",
      "Epoch 69/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5229 - accuracy: 0.6786 - val_loss: 1.1546 - val_accuracy: 0.7500\n",
      "Epoch 70/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5084 - accuracy: 0.6071 - val_loss: 1.3330 - val_accuracy: 0.6250\n",
      "Epoch 71/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4792 - accuracy: 0.7143 - val_loss: 1.4898 - val_accuracy: 0.5000\n",
      "Epoch 72/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4958 - accuracy: 0.6786 - val_loss: 1.5973 - val_accuracy: 0.2500\n",
      "Epoch 73/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5123 - accuracy: 0.6786 - val_loss: 1.5314 - val_accuracy: 0.2500\n",
      "Epoch 74/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4999 - accuracy: 0.6429 - val_loss: 1.3600 - val_accuracy: 0.6250\n",
      "Epoch 75/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4822 - accuracy: 0.7143 - val_loss: 1.2544 - val_accuracy: 0.7500\n",
      "Epoch 76/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4940 - accuracy: 0.6786 - val_loss: 1.2374 - val_accuracy: 0.7500\n",
      "Epoch 77/430\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4883 - accuracy: 0.6786 - val_loss: 1.3216 - val_accuracy: 0.6250\n",
      "Epoch 78/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4807 - accuracy: 0.7143 - val_loss: 1.3879 - val_accuracy: 0.6250\n",
      "Epoch 79/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4826 - accuracy: 0.7143 - val_loss: 1.4041 - val_accuracy: 0.6250\n",
      "Epoch 80/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4868 - accuracy: 0.7143 - val_loss: 1.4302 - val_accuracy: 0.6250\n",
      "Epoch 81/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4830 - accuracy: 0.7143 - val_loss: 1.5018 - val_accuracy: 0.6250\n",
      "Epoch 82/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4861 - accuracy: 0.7143 - val_loss: 1.5573 - val_accuracy: 0.5000\n",
      "Epoch 83/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4903 - accuracy: 0.6786 - val_loss: 1.5463 - val_accuracy: 0.5000\n",
      "Epoch 84/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4788 - accuracy: 0.6786 - val_loss: 1.4387 - val_accuracy: 0.6250\n",
      "Epoch 85/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4878 - accuracy: 0.7143 - val_loss: 1.3444 - val_accuracy: 0.7500\n",
      "Epoch 86/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4795 - accuracy: 0.6786 - val_loss: 1.4069 - val_accuracy: 0.7500\n",
      "Epoch 87/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4744 - accuracy: 0.6786 - val_loss: 1.5184 - val_accuracy: 0.5000\n",
      "Epoch 88/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4751 - accuracy: 0.6786 - val_loss: 1.6203 - val_accuracy: 0.5000\n",
      "Epoch 89/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4801 - accuracy: 0.6786 - val_loss: 1.5941 - val_accuracy: 0.5000\n",
      "Epoch 90/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4757 - accuracy: 0.6786 - val_loss: 1.4986 - val_accuracy: 0.6250\n",
      "Epoch 91/430\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4693 - accuracy: 0.7143 - val_loss: 1.4090 - val_accuracy: 0.6250\n",
      "Epoch 92/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4693 - accuracy: 0.7500 - val_loss: 1.3210 - val_accuracy: 0.7500\n",
      "Epoch 93/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4915 - accuracy: 0.6786 - val_loss: 1.3614 - val_accuracy: 0.7500\n",
      "Epoch 94/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4664 - accuracy: 0.6786 - val_loss: 1.6051 - val_accuracy: 0.6250\n",
      "Epoch 95/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4936 - accuracy: 0.6429 - val_loss: 1.8448 - val_accuracy: 0.2500\n",
      "Epoch 96/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5177 - accuracy: 0.6786 - val_loss: 1.7025 - val_accuracy: 0.5000\n",
      "Epoch 97/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4801 - accuracy: 0.6786 - val_loss: 1.5269 - val_accuracy: 0.6250\n",
      "Epoch 98/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4603 - accuracy: 0.7143 - val_loss: 1.3627 - val_accuracy: 0.7500\n",
      "Epoch 99/430\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4785 - accuracy: 0.6786 - val_loss: 1.3012 - val_accuracy: 0.7500\n",
      "Epoch 100/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4822 - accuracy: 0.6786 - val_loss: 1.3985 - val_accuracy: 0.6250\n",
      "Epoch 101/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4679 - accuracy: 0.7143 - val_loss: 1.6083 - val_accuracy: 0.6250\n",
      "Epoch 102/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5039 - accuracy: 0.7143 - val_loss: 1.6560 - val_accuracy: 0.6250\n",
      "Epoch 103/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4929 - accuracy: 0.7143 - val_loss: 1.4712 - val_accuracy: 0.6250\n",
      "Epoch 104/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4772 - accuracy: 0.7143 - val_loss: 1.3533 - val_accuracy: 0.7500\n",
      "Epoch 105/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4883 - accuracy: 0.5714 - val_loss: 1.3453 - val_accuracy: 0.7500\n",
      "Epoch 106/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4964 - accuracy: 0.6786 - val_loss: 1.3477 - val_accuracy: 0.7500\n",
      "Epoch 107/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4893 - accuracy: 0.6786 - val_loss: 1.5293 - val_accuracy: 0.6250\n",
      "Epoch 108/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4678 - accuracy: 0.6786 - val_loss: 1.6807 - val_accuracy: 0.5000\n",
      "Epoch 109/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4749 - accuracy: 0.6786 - val_loss: 1.6826 - val_accuracy: 0.5000\n",
      "Epoch 110/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4941 - accuracy: 0.6429 - val_loss: 1.6094 - val_accuracy: 0.6250\n",
      "Epoch 111/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4654 - accuracy: 0.7500 - val_loss: 1.6571 - val_accuracy: 0.5000\n",
      "Epoch 112/430\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4681 - accuracy: 0.6786 - val_loss: 1.6498 - val_accuracy: 0.5000\n",
      "Epoch 113/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4705 - accuracy: 0.6071 - val_loss: 1.5890 - val_accuracy: 0.6250\n",
      "Epoch 114/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 1.5802 - val_accuracy: 0.6250\n",
      "Epoch 115/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 1.6264 - val_accuracy: 0.6250\n",
      "Epoch 116/430\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4688 - accuracy: 0.7143 - val_loss: 1.6675 - val_accuracy: 0.5000\n",
      "Epoch 117/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4658 - accuracy: 0.7143 - val_loss: 1.6069 - val_accuracy: 0.6250\n",
      "Epoch 118/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4613 - accuracy: 0.7143 - val_loss: 1.5440 - val_accuracy: 0.7500\n",
      "Epoch 119/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4638 - accuracy: 0.6786 - val_loss: 1.4875 - val_accuracy: 0.7500\n",
      "Epoch 120/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4679 - accuracy: 0.6429 - val_loss: 1.5082 - val_accuracy: 0.6250\n",
      "Epoch 121/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4744 - accuracy: 0.7143 - val_loss: 1.4767 - val_accuracy: 0.6250\n",
      "Epoch 122/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4624 - accuracy: 0.7143 - val_loss: 1.3749 - val_accuracy: 0.7500\n",
      "Epoch 123/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4829 - accuracy: 0.6786 - val_loss: 1.3587 - val_accuracy: 0.7500\n",
      "Epoch 124/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4892 - accuracy: 0.6429 - val_loss: 1.4449 - val_accuracy: 0.6250\n",
      "Epoch 125/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4654 - accuracy: 0.7143 - val_loss: 1.5941 - val_accuracy: 0.6250\n",
      "Epoch 126/430\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4679 - accuracy: 0.7143 - val_loss: 1.7519 - val_accuracy: 0.6250\n",
      "Epoch 127/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4707 - accuracy: 0.6786 - val_loss: 1.7198 - val_accuracy: 0.6250\n",
      "Epoch 128/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4610 - accuracy: 0.7143 - val_loss: 1.6200 - val_accuracy: 0.6250\n",
      "Epoch 129/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4618 - accuracy: 0.7143 - val_loss: 1.5879 - val_accuracy: 0.7500\n",
      "Epoch 130/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4593 - accuracy: 0.6786 - val_loss: 1.6849 - val_accuracy: 0.6250\n",
      "Epoch 131/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4558 - accuracy: 0.7143 - val_loss: 1.8364 - val_accuracy: 0.5000\n",
      "Epoch 132/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4826 - accuracy: 0.6786 - val_loss: 1.8679 - val_accuracy: 0.5000\n",
      "Epoch 133/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4708 - accuracy: 0.6786 - val_loss: 1.6696 - val_accuracy: 0.7500\n",
      "Epoch 134/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4548 - accuracy: 0.6786 - val_loss: 1.5475 - val_accuracy: 0.7500\n",
      "Epoch 135/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4976 - accuracy: 0.6786 - val_loss: 1.5555 - val_accuracy: 0.7500\n",
      "Epoch 136/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4562 - accuracy: 0.6786 - val_loss: 1.7780 - val_accuracy: 0.6250\n",
      "Epoch 137/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4723 - accuracy: 0.6786 - val_loss: 1.9339 - val_accuracy: 0.5000\n",
      "Epoch 138/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5070 - accuracy: 0.6786 - val_loss: 1.7028 - val_accuracy: 0.6250\n",
      "Epoch 139/430\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4490 - accuracy: 0.7143 - val_loss: 1.3845 - val_accuracy: 0.7500\n",
      "Epoch 140/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5277 - accuracy: 0.6786 - val_loss: 1.2870 - val_accuracy: 0.7500\n",
      "Epoch 141/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5318 - accuracy: 0.6786 - val_loss: 1.4461 - val_accuracy: 0.7500\n",
      "Epoch 142/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4783 - accuracy: 0.6786 - val_loss: 1.7338 - val_accuracy: 0.6250\n",
      "Epoch 143/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4753 - accuracy: 0.6786 - val_loss: 1.8657 - val_accuracy: 0.5000\n",
      "Epoch 144/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4951 - accuracy: 0.6786 - val_loss: 1.7245 - val_accuracy: 0.6250\n",
      "Epoch 145/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4743 - accuracy: 0.7143 - val_loss: 1.4982 - val_accuracy: 0.7500\n",
      "Epoch 146/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4640 - accuracy: 0.6786 - val_loss: 1.4234 - val_accuracy: 0.7500\n",
      "Epoch 147/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4844 - accuracy: 0.6786 - val_loss: 1.4383 - val_accuracy: 0.7500\n",
      "Epoch 148/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4745 - accuracy: 0.6786 - val_loss: 1.6168 - val_accuracy: 0.6250\n",
      "Epoch 149/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4490 - accuracy: 0.7500 - val_loss: 1.9556 - val_accuracy: 0.2500\n",
      "Epoch 150/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5267 - accuracy: 0.6786 - val_loss: 2.0363 - val_accuracy: 0.2500\n",
      "Epoch 151/430\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.5190 - accuracy: 0.6786 - val_loss: 1.7195 - val_accuracy: 0.5000\n",
      "Epoch 152/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4698 - accuracy: 0.7143 - val_loss: 1.4805 - val_accuracy: 0.7500\n",
      "Epoch 153/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4745 - accuracy: 0.6786 - val_loss: 1.3939 - val_accuracy: 0.7500\n",
      "Epoch 154/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4765 - accuracy: 0.6786 - val_loss: 1.4363 - val_accuracy: 0.6250\n",
      "Epoch 155/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4736 - accuracy: 0.7143 - val_loss: 1.4636 - val_accuracy: 0.6250\n",
      "Epoch 156/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4728 - accuracy: 0.7143 - val_loss: 1.4748 - val_accuracy: 0.6250\n",
      "Epoch 157/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4584 - accuracy: 0.7143 - val_loss: 1.6116 - val_accuracy: 0.6250\n",
      "Epoch 158/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4792 - accuracy: 0.7143 - val_loss: 1.6909 - val_accuracy: 0.6250\n",
      "Epoch 159/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4821 - accuracy: 0.7143 - val_loss: 1.5795 - val_accuracy: 0.6250\n",
      "Epoch 160/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4613 - accuracy: 0.7143 - val_loss: 1.4033 - val_accuracy: 0.7500\n",
      "Epoch 161/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4664 - accuracy: 0.6786 - val_loss: 1.3333 - val_accuracy: 0.7500\n",
      "Epoch 162/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4891 - accuracy: 0.6786 - val_loss: 1.3851 - val_accuracy: 0.7500\n",
      "Epoch 163/430\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4741 - accuracy: 0.6786 - val_loss: 1.5633 - val_accuracy: 0.6250\n",
      "Epoch 164/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4506 - accuracy: 0.7143 - val_loss: 1.7912 - val_accuracy: 0.5000\n",
      "Epoch 165/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4837 - accuracy: 0.6786 - val_loss: 1.8969 - val_accuracy: 0.2500\n",
      "Epoch 166/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4983 - accuracy: 0.6786 - val_loss: 1.7533 - val_accuracy: 0.5000\n",
      "Epoch 167/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4807 - accuracy: 0.7143 - val_loss: 1.5331 - val_accuracy: 0.6250\n",
      "Epoch 168/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4577 - accuracy: 0.7857 - val_loss: 1.4223 - val_accuracy: 0.7500\n",
      "Epoch 169/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4681 - accuracy: 0.6786 - val_loss: 1.3802 - val_accuracy: 0.7500\n",
      "Epoch 170/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4789 - accuracy: 0.6786 - val_loss: 1.4203 - val_accuracy: 0.7500\n",
      "Epoch 171/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4730 - accuracy: 0.7500 - val_loss: 1.5412 - val_accuracy: 0.6250\n",
      "Epoch 172/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4687 - accuracy: 0.7143 - val_loss: 1.5985 - val_accuracy: 0.6250\n",
      "Epoch 173/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4584 - accuracy: 0.7143 - val_loss: 1.5697 - val_accuracy: 0.6250\n",
      "Epoch 174/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4564 - accuracy: 0.7143 - val_loss: 1.5244 - val_accuracy: 0.6250\n",
      "Epoch 175/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4572 - accuracy: 0.7143 - val_loss: 1.4679 - val_accuracy: 0.7500\n",
      "Epoch 176/430\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4638 - accuracy: 0.6786 - val_loss: 1.4827 - val_accuracy: 0.6250\n",
      "Epoch 177/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4581 - accuracy: 0.7143 - val_loss: 1.5868 - val_accuracy: 0.6250\n",
      "Epoch 178/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4552 - accuracy: 0.7143 - val_loss: 1.6938 - val_accuracy: 0.6250\n",
      "Epoch 179/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4641 - accuracy: 0.7143 - val_loss: 1.7086 - val_accuracy: 0.6250\n",
      "Epoch 180/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4574 - accuracy: 0.7143 - val_loss: 1.6200 - val_accuracy: 0.6250\n",
      "Epoch 181/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4514 - accuracy: 0.7500 - val_loss: 1.5478 - val_accuracy: 0.7500\n",
      "Epoch 182/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4637 - accuracy: 0.6786 - val_loss: 1.5095 - val_accuracy: 0.7500\n",
      "Epoch 183/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4774 - accuracy: 0.6786 - val_loss: 1.4959 - val_accuracy: 0.7500\n",
      "Epoch 184/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4817 - accuracy: 0.6786 - val_loss: 1.5644 - val_accuracy: 0.7500\n",
      "Epoch 185/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4786 - accuracy: 0.5714 - val_loss: 1.6599 - val_accuracy: 0.6250\n",
      "Epoch 186/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4549 - accuracy: 0.7143 - val_loss: 1.6695 - val_accuracy: 0.6250\n",
      "Epoch 187/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4595 - accuracy: 0.7143 - val_loss: 1.6588 - val_accuracy: 0.6250\n",
      "Epoch 188/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4632 - accuracy: 0.7143 - val_loss: 1.7006 - val_accuracy: 0.6250\n",
      "Epoch 189/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4740 - accuracy: 0.7143 - val_loss: 1.6846 - val_accuracy: 0.6250\n",
      "Epoch 190/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4647 - accuracy: 0.7143 - val_loss: 1.7348 - val_accuracy: 0.6250\n",
      "Epoch 191/430\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4576 - accuracy: 0.7143 - val_loss: 1.6218 - val_accuracy: 0.6250\n",
      "Epoch 192/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4704 - accuracy: 0.7143 - val_loss: 1.5267 - val_accuracy: 0.6250\n",
      "Epoch 193/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4665 - accuracy: 0.7143 - val_loss: 1.5552 - val_accuracy: 0.6250\n",
      "Epoch 194/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4576 - accuracy: 0.7143 - val_loss: 1.5487 - val_accuracy: 0.6250\n",
      "Epoch 195/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4591 - accuracy: 0.7143 - val_loss: 1.5884 - val_accuracy: 0.6250\n",
      "Epoch 196/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4626 - accuracy: 0.7143 - val_loss: 1.6701 - val_accuracy: 0.6250\n",
      "Epoch 197/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4545 - accuracy: 0.7143 - val_loss: 1.6632 - val_accuracy: 0.6250\n",
      "Epoch 198/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4533 - accuracy: 0.7143 - val_loss: 1.6238 - val_accuracy: 0.6250\n",
      "Epoch 199/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4524 - accuracy: 0.7143 - val_loss: 1.5552 - val_accuracy: 0.7500\n",
      "Epoch 200/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4678 - accuracy: 0.6786 - val_loss: 1.5401 - val_accuracy: 0.7500\n",
      "Epoch 201/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4738 - accuracy: 0.6429 - val_loss: 1.6425 - val_accuracy: 0.6250\n",
      "Epoch 202/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4523 - accuracy: 0.7143 - val_loss: 1.6904 - val_accuracy: 0.6250\n",
      "Epoch 203/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4537 - accuracy: 0.7143 - val_loss: 1.7427 - val_accuracy: 0.6250\n",
      "Epoch 204/430\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4544 - accuracy: 0.7143 - val_loss: 1.7586 - val_accuracy: 0.6250\n",
      "Epoch 205/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4598 - accuracy: 0.6071 - val_loss: 1.7098 - val_accuracy: 0.7500\n",
      "Epoch 206/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4542 - accuracy: 0.6429 - val_loss: 1.7269 - val_accuracy: 0.6250\n",
      "Epoch 207/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4556 - accuracy: 0.7143 - val_loss: 1.7426 - val_accuracy: 0.6250\n",
      "Epoch 208/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4554 - accuracy: 0.6429 - val_loss: 1.7148 - val_accuracy: 0.6250\n",
      "Epoch 209/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4531 - accuracy: 0.7143 - val_loss: 1.7529 - val_accuracy: 0.6250\n",
      "Epoch 210/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4520 - accuracy: 0.7143 - val_loss: 1.7383 - val_accuracy: 0.6250\n",
      "Epoch 211/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4632 - accuracy: 0.7143 - val_loss: 1.7132 - val_accuracy: 0.6250\n",
      "Epoch 212/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4492 - accuracy: 0.7143 - val_loss: 1.8064 - val_accuracy: 0.6250\n",
      "Epoch 213/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4560 - accuracy: 0.7143 - val_loss: 1.8209 - val_accuracy: 0.6250\n",
      "Epoch 214/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4604 - accuracy: 0.7143 - val_loss: 1.7516 - val_accuracy: 0.6250\n",
      "Epoch 215/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4561 - accuracy: 0.7143 - val_loss: 1.7663 - val_accuracy: 0.6250\n",
      "Epoch 216/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4591 - accuracy: 0.7143 - val_loss: 1.8234 - val_accuracy: 0.6250\n",
      "Epoch 217/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4522 - accuracy: 0.7143 - val_loss: 1.7186 - val_accuracy: 0.6250\n",
      "Epoch 218/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4519 - accuracy: 0.6786 - val_loss: 1.5959 - val_accuracy: 0.7500\n",
      "Epoch 219/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4801 - accuracy: 0.6786 - val_loss: 1.6300 - val_accuracy: 0.7500\n",
      "Epoch 220/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4469 - accuracy: 0.7143 - val_loss: 1.8785 - val_accuracy: 0.5000\n",
      "Epoch 221/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4550 - accuracy: 0.6786 - val_loss: 2.1577 - val_accuracy: 0.2500\n",
      "Epoch 222/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5279 - accuracy: 0.6786 - val_loss: 2.0385 - val_accuracy: 0.5000\n",
      "Epoch 223/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4912 - accuracy: 0.6786 - val_loss: 1.7223 - val_accuracy: 0.7500\n",
      "Epoch 224/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4558 - accuracy: 0.6786 - val_loss: 1.5956 - val_accuracy: 0.7500\n",
      "Epoch 225/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4763 - accuracy: 0.6786 - val_loss: 1.6151 - val_accuracy: 0.7500\n",
      "Epoch 226/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4738 - accuracy: 0.6786 - val_loss: 1.7148 - val_accuracy: 0.7500\n",
      "Epoch 227/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4530 - accuracy: 0.6786 - val_loss: 1.8520 - val_accuracy: 0.5000\n",
      "Epoch 228/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4531 - accuracy: 0.6786 - val_loss: 2.0010 - val_accuracy: 0.5000\n",
      "Epoch 229/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4759 - accuracy: 0.6786 - val_loss: 2.0657 - val_accuracy: 0.5000\n",
      "Epoch 230/430\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4982 - accuracy: 0.6786 - val_loss: 1.9468 - val_accuracy: 0.5000\n",
      "Epoch 231/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4788 - accuracy: 0.6071 - val_loss: 1.6473 - val_accuracy: 0.7500\n",
      "Epoch 232/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4528 - accuracy: 0.6786 - val_loss: 1.5249 - val_accuracy: 0.7500\n",
      "Epoch 233/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4919 - accuracy: 0.6786 - val_loss: 1.5228 - val_accuracy: 0.7500\n",
      "Epoch 234/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4581 - accuracy: 0.7857 - val_loss: 1.7302 - val_accuracy: 0.6250\n",
      "Epoch 235/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4730 - accuracy: 0.7143 - val_loss: 1.9136 - val_accuracy: 0.5000\n",
      "Epoch 236/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4971 - accuracy: 0.6786 - val_loss: 1.8079 - val_accuracy: 0.6250\n",
      "Epoch 237/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4514 - accuracy: 0.7143 - val_loss: 1.5392 - val_accuracy: 0.7500\n",
      "Epoch 238/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4654 - accuracy: 0.6786 - val_loss: 1.3756 - val_accuracy: 0.7500\n",
      "Epoch 239/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5132 - accuracy: 0.6786 - val_loss: 1.3907 - val_accuracy: 0.7500\n",
      "Epoch 240/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5107 - accuracy: 0.6786 - val_loss: 1.5340 - val_accuracy: 0.7500\n",
      "Epoch 241/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4549 - accuracy: 0.6786 - val_loss: 1.7054 - val_accuracy: 0.6250\n",
      "Epoch 242/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4661 - accuracy: 0.7143 - val_loss: 1.8714 - val_accuracy: 0.5000\n",
      "Epoch 243/430\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4714 - accuracy: 0.6786 - val_loss: 1.8387 - val_accuracy: 0.5000\n",
      "Epoch 244/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4616 - accuracy: 0.6786 - val_loss: 1.7185 - val_accuracy: 0.6250\n",
      "Epoch 245/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4673 - accuracy: 0.6071 - val_loss: 1.6023 - val_accuracy: 0.7500\n",
      "Epoch 246/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4555 - accuracy: 0.6786 - val_loss: 1.6119 - val_accuracy: 0.6250\n",
      "Epoch 247/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4490 - accuracy: 0.7143 - val_loss: 1.6909 - val_accuracy: 0.6250\n",
      "Epoch 248/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4516 - accuracy: 0.7143 - val_loss: 1.7837 - val_accuracy: 0.6250\n",
      "Epoch 249/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4702 - accuracy: 0.7143 - val_loss: 1.8004 - val_accuracy: 0.5000\n",
      "Epoch 250/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4674 - accuracy: 0.6429 - val_loss: 1.6843 - val_accuracy: 0.6250\n",
      "Epoch 251/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4494 - accuracy: 0.7143 - val_loss: 1.5743 - val_accuracy: 0.6250\n",
      "Epoch 252/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4560 - accuracy: 0.7143 - val_loss: 1.5334 - val_accuracy: 0.7500\n",
      "Epoch 253/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4657 - accuracy: 0.6786 - val_loss: 1.6083 - val_accuracy: 0.7500\n",
      "Epoch 254/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4542 - accuracy: 0.6786 - val_loss: 1.7820 - val_accuracy: 0.5000\n",
      "Epoch 255/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4570 - accuracy: 0.6786 - val_loss: 1.9521 - val_accuracy: 0.5000\n",
      "Epoch 256/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4796 - accuracy: 0.6786 - val_loss: 1.9614 - val_accuracy: 0.5000\n",
      "Epoch 257/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4775 - accuracy: 0.6786 - val_loss: 1.8239 - val_accuracy: 0.5000\n",
      "Epoch 258/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4689 - accuracy: 0.7143 - val_loss: 1.6892 - val_accuracy: 0.7500\n",
      "Epoch 259/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4647 - accuracy: 0.6786 - val_loss: 1.6566 - val_accuracy: 0.7500\n",
      "Epoch 260/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4627 - accuracy: 0.6786 - val_loss: 1.6671 - val_accuracy: 0.7500\n",
      "Epoch 261/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4507 - accuracy: 0.6786 - val_loss: 1.6530 - val_accuracy: 0.6250\n",
      "Epoch 262/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4570 - accuracy: 0.7143 - val_loss: 1.6375 - val_accuracy: 0.6250\n",
      "Epoch 263/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4620 - accuracy: 0.7143 - val_loss: 1.5542 - val_accuracy: 0.6250\n",
      "Epoch 264/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4672 - accuracy: 0.7143 - val_loss: 1.5429 - val_accuracy: 0.6250\n",
      "Epoch 265/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4565 - accuracy: 0.7143 - val_loss: 1.6531 - val_accuracy: 0.6250\n",
      "Epoch 266/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4553 - accuracy: 0.7143 - val_loss: 1.7342 - val_accuracy: 0.6250\n",
      "Epoch 267/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4580 - accuracy: 0.7143 - val_loss: 1.7332 - val_accuracy: 0.6250\n",
      "Epoch 268/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4542 - accuracy: 0.7143 - val_loss: 1.7132 - val_accuracy: 0.6250\n",
      "Epoch 269/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4531 - accuracy: 0.7143 - val_loss: 1.6579 - val_accuracy: 0.7500\n",
      "Epoch 270/430\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.4453 - accuracy: 0.6786 - val_loss: 1.5331 - val_accuracy: 0.7500\n",
      "Epoch 271/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4895 - accuracy: 0.6786 - val_loss: 1.4740 - val_accuracy: 0.7500\n",
      "Epoch 272/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4939 - accuracy: 0.6786 - val_loss: 1.5728 - val_accuracy: 0.7500\n",
      "Epoch 273/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4525 - accuracy: 0.7143 - val_loss: 1.7511 - val_accuracy: 0.6250\n",
      "Epoch 274/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4556 - accuracy: 0.6786 - val_loss: 1.9109 - val_accuracy: 0.5000\n",
      "Epoch 275/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4811 - accuracy: 0.6786 - val_loss: 1.8559 - val_accuracy: 0.5000\n",
      "Epoch 276/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4701 - accuracy: 0.7143 - val_loss: 1.6269 - val_accuracy: 0.6250\n",
      "Epoch 277/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4455 - accuracy: 0.7143 - val_loss: 1.3897 - val_accuracy: 0.7500\n",
      "Epoch 278/430\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5042 - accuracy: 0.6786 - val_loss: 1.3076 - val_accuracy: 0.7500\n",
      "Epoch 279/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5163 - accuracy: 0.6786 - val_loss: 1.4202 - val_accuracy: 0.7500\n",
      "Epoch 280/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4693 - accuracy: 0.7143 - val_loss: 1.5862 - val_accuracy: 0.6250\n",
      "Epoch 281/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4489 - accuracy: 0.7143 - val_loss: 1.7737 - val_accuracy: 0.6250\n",
      "Epoch 282/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4612 - accuracy: 0.7857 - val_loss: 1.9211 - val_accuracy: 0.5000\n",
      "Epoch 283/430\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5042 - accuracy: 0.6786 - val_loss: 1.9275 - val_accuracy: 0.5000\n",
      "Epoch 284/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4897 - accuracy: 0.6786 - val_loss: 1.6947 - val_accuracy: 0.6250\n",
      "Epoch 285/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4497 - accuracy: 0.7143 - val_loss: 1.5576 - val_accuracy: 0.7500\n",
      "Epoch 286/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4601 - accuracy: 0.6786 - val_loss: 1.4927 - val_accuracy: 0.7500\n",
      "Epoch 287/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4706 - accuracy: 0.6786 - val_loss: 1.4965 - val_accuracy: 0.7500\n",
      "Epoch 288/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4633 - accuracy: 0.6786 - val_loss: 1.5186 - val_accuracy: 0.7500\n",
      "Epoch 289/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4668 - accuracy: 0.6429 - val_loss: 1.5557 - val_accuracy: 0.6250\n",
      "Epoch 290/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4540 - accuracy: 0.7143 - val_loss: 1.5252 - val_accuracy: 0.6250\n",
      "Epoch 291/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4554 - accuracy: 0.7143 - val_loss: 1.4893 - val_accuracy: 0.6250\n",
      "Epoch 292/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4583 - accuracy: 0.7143 - val_loss: 1.5007 - val_accuracy: 0.6250\n",
      "Epoch 293/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4571 - accuracy: 0.7143 - val_loss: 1.5608 - val_accuracy: 0.6250\n",
      "Epoch 294/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4571 - accuracy: 0.7143 - val_loss: 1.6123 - val_accuracy: 0.6250\n",
      "Epoch 295/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4518 - accuracy: 0.7143 - val_loss: 1.6199 - val_accuracy: 0.6250\n",
      "Epoch 296/430\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.4514 - accuracy: 0.7143 - val_loss: 1.6648 - val_accuracy: 0.6250\n",
      "Epoch 297/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4620 - accuracy: 0.7143 - val_loss: 1.7161 - val_accuracy: 0.6250\n",
      "Epoch 298/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4516 - accuracy: 0.7143 - val_loss: 1.6387 - val_accuracy: 0.6250\n",
      "Epoch 299/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4465 - accuracy: 0.7143 - val_loss: 1.5674 - val_accuracy: 0.7500\n",
      "Epoch 300/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4548 - accuracy: 0.6786 - val_loss: 1.5191 - val_accuracy: 0.7500\n",
      "Epoch 301/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4748 - accuracy: 0.6786 - val_loss: 1.5187 - val_accuracy: 0.7500\n",
      "Epoch 302/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4745 - accuracy: 0.6786 - val_loss: 1.6305 - val_accuracy: 0.7500\n",
      "Epoch 303/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4664 - accuracy: 0.6429 - val_loss: 1.8016 - val_accuracy: 0.5000\n",
      "Epoch 304/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4539 - accuracy: 0.6786 - val_loss: 1.8576 - val_accuracy: 0.5000\n",
      "Epoch 305/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4648 - accuracy: 0.6786 - val_loss: 1.8390 - val_accuracy: 0.5000\n",
      "Epoch 306/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4641 - accuracy: 0.6786 - val_loss: 1.7820 - val_accuracy: 0.5000\n",
      "Epoch 307/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4531 - accuracy: 0.6786 - val_loss: 1.7597 - val_accuracy: 0.6250\n",
      "Epoch 308/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4519 - accuracy: 0.7143 - val_loss: 1.7371 - val_accuracy: 0.6250\n",
      "Epoch 309/430\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4513 - accuracy: 0.7143 - val_loss: 1.7102 - val_accuracy: 0.6250\n",
      "Epoch 310/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4528 - accuracy: 0.7143 - val_loss: 1.6531 - val_accuracy: 0.6250\n",
      "Epoch 311/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4510 - accuracy: 0.7143 - val_loss: 1.6552 - val_accuracy: 0.6250\n",
      "Epoch 312/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4521 - accuracy: 0.7143 - val_loss: 1.6676 - val_accuracy: 0.6250\n",
      "Epoch 313/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4536 - accuracy: 0.7143 - val_loss: 1.7455 - val_accuracy: 0.6250\n",
      "Epoch 314/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4503 - accuracy: 0.7143 - val_loss: 1.8950 - val_accuracy: 0.5000\n",
      "Epoch 315/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4672 - accuracy: 0.6786 - val_loss: 1.8842 - val_accuracy: 0.5000\n",
      "Epoch 316/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4586 - accuracy: 0.6786 - val_loss: 1.7233 - val_accuracy: 0.7500\n",
      "Epoch 317/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4596 - accuracy: 0.6786 - val_loss: 1.6107 - val_accuracy: 0.7500\n",
      "Epoch 318/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4591 - accuracy: 0.6786 - val_loss: 1.6157 - val_accuracy: 0.7500\n",
      "Epoch 319/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4550 - accuracy: 0.6786 - val_loss: 1.6539 - val_accuracy: 0.6250\n",
      "Epoch 320/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4468 - accuracy: 0.7143 - val_loss: 1.7627 - val_accuracy: 0.6250\n",
      "Epoch 321/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4646 - accuracy: 0.6786 - val_loss: 1.8200 - val_accuracy: 0.6250\n",
      "Epoch 322/430\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4569 - accuracy: 0.7143 - val_loss: 1.7364 - val_accuracy: 0.6250\n",
      "Epoch 323/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4490 - accuracy: 0.7143 - val_loss: 1.7005 - val_accuracy: 0.6250\n",
      "Epoch 324/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4530 - accuracy: 0.6429 - val_loss: 1.7029 - val_accuracy: 0.6250\n",
      "Epoch 325/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4485 - accuracy: 0.7143 - val_loss: 1.7703 - val_accuracy: 0.6250\n",
      "Epoch 326/430\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4510 - accuracy: 0.7143 - val_loss: 1.7910 - val_accuracy: 0.6250\n",
      "Epoch 327/430\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4518 - accuracy: 0.7143 - val_loss: 1.7492 - val_accuracy: 0.6250\n",
      "Epoch 328/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4508 - accuracy: 0.7143 - val_loss: 1.7575 - val_accuracy: 0.6250\n",
      "Epoch 329/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4525 - accuracy: 0.7143 - val_loss: 1.7888 - val_accuracy: 0.6250\n",
      "Epoch 330/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4494 - accuracy: 0.7143 - val_loss: 1.7228 - val_accuracy: 0.6250\n",
      "Epoch 331/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4456 - accuracy: 0.7143 - val_loss: 1.6336 - val_accuracy: 0.6250\n",
      "Epoch 332/430\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4514 - accuracy: 0.7143 - val_loss: 1.5738 - val_accuracy: 0.7500\n",
      "Epoch 333/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4608 - accuracy: 0.6071 - val_loss: 1.5584 - val_accuracy: 0.7500\n",
      "Epoch 334/430\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4745 - accuracy: 0.6786 - val_loss: 1.6346 - val_accuracy: 0.6250\n",
      "Epoch 335/430\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4415 - accuracy: 0.7143 - val_loss: 1.9011 - val_accuracy: 0.5000\n",
      "Epoch 336/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4594 - accuracy: 0.6786 - val_loss: 2.1190 - val_accuracy: 0.5000\n",
      "Epoch 337/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5090 - accuracy: 0.6786 - val_loss: 2.0714 - val_accuracy: 0.5000\n",
      "Epoch 338/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4856 - accuracy: 0.6786 - val_loss: 1.8243 - val_accuracy: 0.5000\n",
      "Epoch 339/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4557 - accuracy: 0.6429 - val_loss: 1.6394 - val_accuracy: 0.7500\n",
      "Epoch 340/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4607 - accuracy: 0.6786 - val_loss: 1.5830 - val_accuracy: 0.7500\n",
      "Epoch 341/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4778 - accuracy: 0.6786 - val_loss: 1.5889 - val_accuracy: 0.7500\n",
      "Epoch 342/430\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4656 - accuracy: 0.6786 - val_loss: 1.7185 - val_accuracy: 0.7500\n",
      "Epoch 343/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4509 - accuracy: 0.6786 - val_loss: 1.8922 - val_accuracy: 0.5000\n",
      "Epoch 344/430\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4575 - accuracy: 0.6786 - val_loss: 1.9505 - val_accuracy: 0.5000\n",
      "Epoch 345/430\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4747 - accuracy: 0.6786 - val_loss: 1.8624 - val_accuracy: 0.5000\n",
      "Epoch 346/430\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4756 - accuracy: 0.6429 - val_loss: 1.6967 - val_accuracy: 0.6250\n",
      "Epoch 347/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4610 - accuracy: 0.7143 - val_loss: 1.6734 - val_accuracy: 0.6250\n",
      "Epoch 348/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4463 - accuracy: 0.7143 - val_loss: 1.7662 - val_accuracy: 0.6250\n",
      "Epoch 349/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4651 - accuracy: 0.6786 - val_loss: 1.8014 - val_accuracy: 0.6250\n",
      "Epoch 350/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4507 - accuracy: 0.7143 - val_loss: 1.6744 - val_accuracy: 0.6250\n",
      "Epoch 351/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4419 - accuracy: 0.7143 - val_loss: 1.5243 - val_accuracy: 0.7500\n",
      "Epoch 352/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4620 - accuracy: 0.6786 - val_loss: 1.3990 - val_accuracy: 0.7500\n",
      "Epoch 353/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5104 - accuracy: 0.6786 - val_loss: 1.3753 - val_accuracy: 0.7500\n",
      "Epoch 354/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5183 - accuracy: 0.6786 - val_loss: 1.4596 - val_accuracy: 0.7500\n",
      "Epoch 355/430\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4737 - accuracy: 0.6786 - val_loss: 1.6549 - val_accuracy: 0.6250\n",
      "Epoch 356/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4655 - accuracy: 0.7143 - val_loss: 1.8967 - val_accuracy: 0.5000\n",
      "Epoch 357/430\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4835 - accuracy: 0.6786 - val_loss: 1.9154 - val_accuracy: 0.5000\n",
      "Epoch 358/430\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4707 - accuracy: 0.6786 - val_loss: 1.7211 - val_accuracy: 0.6250\n",
      "Epoch 359/430\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4562 - accuracy: 0.7143 - val_loss: 1.5707 - val_accuracy: 0.7500\n",
      "Epoch 360/430\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4756 - accuracy: 0.6786 - val_loss: 1.5730 - val_accuracy: 0.7500\n",
      "Epoch 361/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4484 - accuracy: 0.7143 - val_loss: 1.7357 - val_accuracy: 0.6250\n",
      "Epoch 362/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4428 - accuracy: 0.7500 - val_loss: 1.9318 - val_accuracy: 0.5000\n",
      "Epoch 363/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4834 - accuracy: 0.6786 - val_loss: 2.0133 - val_accuracy: 0.5000\n",
      "Epoch 364/430\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4926 - accuracy: 0.6786 - val_loss: 1.8489 - val_accuracy: 0.5000\n",
      "Epoch 365/430\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4567 - accuracy: 0.6786 - val_loss: 1.6570 - val_accuracy: 0.6250\n",
      "Epoch 366/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4483 - accuracy: 0.7143 - val_loss: 1.5052 - val_accuracy: 0.7500\n",
      "Epoch 367/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4693 - accuracy: 0.6786 - val_loss: 1.4632 - val_accuracy: 0.7500\n",
      "Epoch 368/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4707 - accuracy: 0.6786 - val_loss: 1.5340 - val_accuracy: 0.7500\n",
      "Epoch 369/430\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4542 - accuracy: 0.6786 - val_loss: 1.6424 - val_accuracy: 0.6250\n",
      "Epoch 370/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4530 - accuracy: 0.7143 - val_loss: 1.7311 - val_accuracy: 0.6250\n",
      "Epoch 371/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4596 - accuracy: 0.7143 - val_loss: 1.7165 - val_accuracy: 0.6250\n",
      "Epoch 372/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4479 - accuracy: 0.7143 - val_loss: 1.5967 - val_accuracy: 0.6250\n",
      "Epoch 373/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4447 - accuracy: 0.7500 - val_loss: 1.4832 - val_accuracy: 0.7500\n",
      "Epoch 374/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4689 - accuracy: 0.6786 - val_loss: 1.4393 - val_accuracy: 0.7500\n",
      "Epoch 375/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4931 - accuracy: 0.6786 - val_loss: 1.4745 - val_accuracy: 0.7500\n",
      "Epoch 376/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4718 - accuracy: 0.6786 - val_loss: 1.6522 - val_accuracy: 0.7500\n",
      "Epoch 377/430\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.4741 - accuracy: 0.5714 - val_loss: 1.8521 - val_accuracy: 0.5000\n",
      "Epoch 378/430\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4646 - accuracy: 0.6786 - val_loss: 1.9045 - val_accuracy: 0.5000\n",
      "Epoch 379/430\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4707 - accuracy: 0.6786 - val_loss: 1.8740 - val_accuracy: 0.5000\n",
      "Epoch 380/430\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4581 - accuracy: 0.6786 - val_loss: 1.7037 - val_accuracy: 0.6250\n",
      "Epoch 381/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4478 - accuracy: 0.7143 - val_loss: 1.5253 - val_accuracy: 0.7500\n",
      "Epoch 382/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4650 - accuracy: 0.6786 - val_loss: 1.4448 - val_accuracy: 0.7500\n",
      "Epoch 383/430\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4695 - accuracy: 0.6786 - val_loss: 1.4911 - val_accuracy: 0.7500\n",
      "Epoch 384/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4625 - accuracy: 0.6429 - val_loss: 1.6193 - val_accuracy: 0.6250\n",
      "Epoch 385/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4538 - accuracy: 0.7143 - val_loss: 1.6925 - val_accuracy: 0.6250\n",
      "Epoch 386/430\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4550 - accuracy: 0.7143 - val_loss: 1.6938 - val_accuracy: 0.6250\n",
      "Epoch 387/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4606 - accuracy: 0.7143 - val_loss: 1.6554 - val_accuracy: 0.6250\n",
      "Epoch 388/430\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4570 - accuracy: 0.7143 - val_loss: 1.5412 - val_accuracy: 0.6250\n",
      "Epoch 389/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4510 - accuracy: 0.7143 - val_loss: 1.5210 - val_accuracy: 0.7500\n",
      "Epoch 390/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4549 - accuracy: 0.6786 - val_loss: 1.5475 - val_accuracy: 0.7500\n",
      "Epoch 391/430\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4544 - accuracy: 0.6786 - val_loss: 1.6102 - val_accuracy: 0.6250\n",
      "Epoch 392/430\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4501 - accuracy: 0.7143 - val_loss: 1.6994 - val_accuracy: 0.6250\n",
      "Epoch 393/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4499 - accuracy: 0.6786 - val_loss: 1.8214 - val_accuracy: 0.5000\n",
      "Epoch 394/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4649 - accuracy: 0.6786 - val_loss: 1.8141 - val_accuracy: 0.5000\n",
      "Epoch 395/430\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4617 - accuracy: 0.7143 - val_loss: 1.6976 - val_accuracy: 0.6250\n",
      "Epoch 396/430\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4559 - accuracy: 0.7143 - val_loss: 1.5730 - val_accuracy: 0.6250\n",
      "Epoch 397/430\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4547 - accuracy: 0.7143 - val_loss: 1.5437 - val_accuracy: 0.6250\n",
      "Epoch 398/430\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4523 - accuracy: 0.7143 - val_loss: 1.5932 - val_accuracy: 0.6250\n",
      "Epoch 399/430\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4464 - accuracy: 0.7143 - val_loss: 1.6963 - val_accuracy: 0.6250\n",
      "Epoch 400/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4465 - accuracy: 0.7143 - val_loss: 1.8261 - val_accuracy: 0.5000\n",
      "Epoch 401/430\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4650 - accuracy: 0.6786 - val_loss: 1.8812 - val_accuracy: 0.5000\n",
      "Epoch 402/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4693 - accuracy: 0.6786 - val_loss: 1.8197 - val_accuracy: 0.5000\n",
      "Epoch 403/430\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4576 - accuracy: 0.6786 - val_loss: 1.6928 - val_accuracy: 0.6250\n",
      "Epoch 404/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4479 - accuracy: 0.6786 - val_loss: 1.6054 - val_accuracy: 0.7500\n",
      "Epoch 405/430\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4551 - accuracy: 0.6786 - val_loss: 1.5436 - val_accuracy: 0.7500\n",
      "Epoch 406/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4632 - accuracy: 0.6786 - val_loss: 1.5781 - val_accuracy: 0.7500\n",
      "Epoch 407/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4558 - accuracy: 0.6071 - val_loss: 1.6868 - val_accuracy: 0.6250\n",
      "Epoch 408/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4498 - accuracy: 0.7143 - val_loss: 1.7517 - val_accuracy: 0.6250\n",
      "Epoch 409/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4491 - accuracy: 0.7143 - val_loss: 1.7530 - val_accuracy: 0.6250\n",
      "Epoch 410/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4514 - accuracy: 0.6429 - val_loss: 1.7341 - val_accuracy: 0.6250\n",
      "Epoch 411/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4641 - accuracy: 0.6429 - val_loss: 1.6905 - val_accuracy: 0.6250\n",
      "Epoch 412/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4482 - accuracy: 0.7143 - val_loss: 1.7598 - val_accuracy: 0.6250\n",
      "Epoch 413/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4530 - accuracy: 0.6786 - val_loss: 1.7775 - val_accuracy: 0.5000\n",
      "Epoch 414/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4491 - accuracy: 0.6786 - val_loss: 1.7146 - val_accuracy: 0.6250\n",
      "Epoch 415/430\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4516 - accuracy: 0.6429 - val_loss: 1.6768 - val_accuracy: 0.6250\n",
      "Epoch 416/430\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4473 - accuracy: 0.7143 - val_loss: 1.7043 - val_accuracy: 0.6250\n",
      "Epoch 417/430\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4596 - accuracy: 0.7143 - val_loss: 1.7176 - val_accuracy: 0.6250\n",
      "Epoch 418/430\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4492 - accuracy: 0.7143 - val_loss: 1.6155 - val_accuracy: 0.6250\n",
      "Epoch 419/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4444 - accuracy: 0.7143 - val_loss: 1.5061 - val_accuracy: 0.7500\n",
      "Epoch 420/430\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4759 - accuracy: 0.6786 - val_loss: 1.4675 - val_accuracy: 0.7500\n",
      "Epoch 421/430\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4848 - accuracy: 0.6786 - val_loss: 1.5620 - val_accuracy: 0.7500\n",
      "Epoch 422/430\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4600 - accuracy: 0.6786 - val_loss: 1.6782 - val_accuracy: 0.6250\n",
      "Epoch 423/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4467 - accuracy: 0.7143 - val_loss: 1.7968 - val_accuracy: 0.6250\n",
      "Epoch 424/430\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4584 - accuracy: 0.8214 - val_loss: 1.8859 - val_accuracy: 0.5000\n",
      "Epoch 425/430\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4604 - accuracy: 0.6786 - val_loss: 1.9065 - val_accuracy: 0.5000\n",
      "Epoch 426/430\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4625 - accuracy: 0.6786 - val_loss: 1.8884 - val_accuracy: 0.5000\n",
      "Epoch 427/430\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4628 - accuracy: 0.6786 - val_loss: 1.8485 - val_accuracy: 0.5000\n",
      "Epoch 428/430\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4573 - accuracy: 0.6786 - val_loss: 1.8041 - val_accuracy: 0.5000\n",
      "Epoch 429/430\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4478 - accuracy: 0.6786 - val_loss: 1.6627 - val_accuracy: 0.7500\n",
      "Epoch 430/430\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4591 - accuracy: 0.6786 - val_loss: 1.5883 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ram://f9c5d2ba-b5f3-4887-bb96-1df7997387ad/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# Train Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "history = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_train = np.argmax(x_train, axis=1) \n",
    "\n",
    "for i, (train, val) in enumerate(cv.split(y_train, x_train)):\n",
    "\n",
    "    X_train, X_val = y[train], y[val]\n",
    "    y_train, y_val = x[train], x[val]\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "    \n",
    "    classifier = classifier_modeling()\n",
    "\n",
    "    # Fit model\n",
    "    classifier.fit(X_train, y_train, validation_split=0.2, epochs=430, batch_size=20)\n",
    "\n",
    "    # Save model\n",
    "    with open('model\\\\ann_wofill', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "\n",
    "    # Predict\n",
    "    predict = classifier.predict(X_val)\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "\n",
    "    viz = RocCurveDisplay.from_predictions(y_val, predict, name='ROC fold {}'.format(i),\n",
    "                           alpha=0.3, lw=1, ax=ax)                     \n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "# mean line\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"r\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "\n",
    "# std\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"yellow\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(\n",
    "    'graph\\\\ann_wofill_graph.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test)\n",
    "# print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.64      0.60      0.61        11\n",
      "weighted avg       0.70      0.73      0.71        11\n",
      "\n",
      "Sensitivity :  0.5\n",
      "Specificity :  0.7777777777777778\n",
      "accuracy : 0.7272727272727273\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Report\n",
    "predict = classifier.predict(y_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "# x_test = x_test[:,0]\n",
    "\n",
    "print(predict)\n",
    "print(x_test)\n",
    "\n",
    "print(classification_report(x_test, predict))\n",
    "\n",
    "conf = confusion_matrix(x_test, predict)\n",
    "sensitivity = conf[1, 1]/(conf[0, 1]+conf[1, 1])\n",
    "specificity = conf[0, 0]/(conf[0, 0]+conf[1, 0])\n",
    "\n",
    "print('Sensitivity : ', sensitivity)\n",
    "print('Specificity : ', specificity)\n",
    "# print('Precision: %.3f' % precision_score(y_pred, y_true))\n",
    "# print('F1 Score: %.3f' % f1_score(y_pred, y_true))\n",
    "print(f\"accuracy : {accuracy_score(x_test, predict)}\\n\")\n",
    "\n",
    "# Plot cofusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf.shape[0]):\n",
    "    for j in range(conf.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf[i, j], va='center',\n",
    "                ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix NN(relu)', fontsize=18)\n",
    "plt.savefig(\n",
    "    'matrix\\\\ann_filled_matrix.jpg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae305f4dee197bdc0c916b004f5792eca0da2328f3eb5fe8e31b308819fc7eb2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
